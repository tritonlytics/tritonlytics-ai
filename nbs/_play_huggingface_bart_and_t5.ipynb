{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import *\n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"I like apples because \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(article, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = torch.cat([inputs['input_ids'][0][:1023], inputs['input_ids'][0][-1:]]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I like apples because they taste so good. _______________________.advertisementadvertisementadvertisementadvertisementadvertisement']\n"
     ]
    }
   ],
   "source": [
    "summary_ids = model.generate(part1, num_beams=4, max_length=130, min_length=20, early_stopping=True)\n",
    "print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = 512\n",
    "end = 512 + 511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = torch.cat([inputs['input_ids'][0][:1], inputs['input_ids'][0][-511:]]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I like apples because ____________________ ____________________ ____________________I like apples because ____________________ ____________________ ____________________ ____________________']\n"
     ]
    }
   ],
   "source": [
    "summary_ids = model.generate(part2, num_beams=4, max_length=130, min_length=30, early_stopping=True)\n",
    "print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BART - pretrained using `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef7543e1f8649d88012a022f9bd4db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1621.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920bd12efe7e42258ad969666dae604a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968d05c7c5af4e3faf98158f0f2e9b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a1b5baac1b43b7b42eff380e2c98c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=26.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbc5f6457604fd49beb00075548261e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1222317369.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\n",
    "    'The Finance Coordinator did not back brief his staff following formal EOC coordination meetings.',\n",
    "    'Finance Section personnel had not received any formal Finance Section training prior the exercise.',\n",
    "    'While not specific to the Finance Section, exercise evaluators stated that no guidance was provided pertaining to breaks and lunch.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [\n",
    "    'Exercise evaluators stated they did not observe the Finance Section Coordinator back brief his personnel following EOC coordination meetings. They attributed this deficiency to the understaffing of the Finance Section. Evaluators stated that when the Finance Section Coordinator would return to the Section following the coordination meetings, he would be inundated with questions and tasks that required his immediate attention.',\n",
    "    'Exercise evaluators stated that neither of three Finance Section personnel had been formally trained on how to function within the Finance Section. Evaluators noted that in the absence of training, Finance Section personnel were proactive in their problem solving, but were unsure if their approach was the right one.',\n",
    "    'Exercise evaluators indicated that they did not observe EOC staff provide any guidance on when to take breaks or how to maintain EOC operations while obtaining lunch. Evaluators indicated that when lunch finally arrived, everyone dropped what they were doing and went to lunch.'    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = summarizer(comments, max_length=30, min_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== predicted ===\n",
      " Exercise evaluators stated they did not observe the Finance Section Coordinator back brief his personnel following EOC coordination meetings .\n",
      "=== target ===\n",
      "The Finance Coordinator did not back brief his staff following formal EOC coordination meetings.\n",
      "\n",
      "=== predicted ===\n",
      " Neither of three Finance Section personnel had been formally trained on how to function within the Finance Section .\n",
      "=== target ===\n",
      "Finance Section personnel had not received any formal Finance Section training prior the exercise.\n",
      "\n",
      "=== predicted ===\n",
      "\n",
      "=== target ===\n",
      "While not specific to the Finance Section, exercise evaluators stated that no guidance was provided pertaining to breaks and lunch.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, summary in enumerate(summaries):\n",
    "    txt = summary['summary_text']\n",
    "    sents = [sent.text for sent in spacy_en(txt).sents]\n",
    "    print(f\"=== predicted ===\\n{' '.join(sents[:-1])}\\n=== target ===\\n{targets[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 - pretrained using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exercise evaluators did not observe the Finance Section Coordinator back brief his personnel. they attributed this defic\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "# T5 uses a max_length of 512 so we cut the article to 512 tokens.\n",
    "inputs = tokenizer(\"summarize: \" + comments[0], return_tensors=\"pt\", truncation=True)\n",
    "outputs = model.generate(inputs['input_ids'], max_length=25, min_length=5, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"summarize: \" + c for c in comments], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "outputs = model.generate(inputs['input_ids'], max_length=25, min_length=5, \n",
    "                         length_penalty=4.0, num_beams=4, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== predicted ===\n",
      "exercise evaluators did not observe the Finance Section Coordinator back brief his personnel. they attributed this defic\n",
      "=== target ===\n",
      "The Finance Coordinator did not back brief his staff following formal EOC coordination meetings.\n",
      "\n",
      "=== predicted ===\n",
      "exercise evaluators stated that neither of three Finance Section personnel had been formally trained on how to function.\n",
      "=== target ===\n",
      "Finance Section personnel had not received any formal Finance Section training prior the exercise.\n",
      "\n",
      "=== predicted ===\n",
      "exercise evaluators did not observe EOC staff provide any guidance on when to take breaks or how to maintain E\n",
      "=== target ===\n",
      "While not specific to the Finance Section, exercise evaluators stated that no guidance was provided pertaining to breaks and lunch.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, pred in enumerate(outputs):\n",
    "    txt = tokenizer.decode(pred)\n",
    "    print(f\"=== predicted ===\\n{txt}\\n=== target ===\\n{targets[i]}\\n\")\n",
    "    \n",
    "#     sents = [sent.text for sent in spacy_en(txt).sents]\n",
    "#     print(f\"=== predicted ===\\n{' '.join(sents[:-1])}\\n=== target ===\\n{targets[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
