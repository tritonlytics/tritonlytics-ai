{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tritonlytics MultiTask Classification - Standard Themes Metadata\n",
    "\n",
    "Experiments related to building a LM and multilabel classification model for survey comments captured in the Tritonlytics survey delivery system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *   # Quick accesss to NLP functionality\n",
    "from fastai.callbacks import *\n",
    "\n",
    "import pdb\n",
    "from tritonlytics import Metrics as metrics_util, DataGeneration as dg_util, PandasUtil as pd_util\n",
    "from tritonlytics.evaluation import *\n",
    "from tritonlytics.callbacks import RocAucEvaluation\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "import spacy\n",
    "spacy_en = spacy.load('en')\n",
    "spacy_es = spacy.load('es')\n",
    "\n",
    "# pandas and plotting config\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9,6)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version: 1.0.57\n"
     ]
    }
   ],
   "source": [
    "print(f'fastai version: {__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def convert_to_snakecase(name):\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower().replace('__', '_') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://drive.google.com/file/d/0B1yuv8YaUVlZZ1RzMFJmc1ZsQmM/view : apostrophe lookup dict\n",
    "appos_regex_repl = {\n",
    "    r\"\\baren't\\b\" : \"are not\",\n",
    "    r\"\\bcan't\\b\" : \"cannot\",\n",
    "    r\"\\bcouldn't\\b\" : \"could not\",\n",
    "    r\"\\bdidn't\\b\" : \"did not\",\n",
    "    r\"\\bdoesn't\\b\" : \"does not\",\n",
    "    r\"\\bdon't\\b\" : \"do not\",\n",
    "    r\"\\bhadn't\\b\" : \"had not\",\n",
    "    r\"\\bhasn't\\b\" : \"has not\",\n",
    "    r\"\\bhaven't\\b\" : \"have not\",\n",
    "    r\"\\bhe'd\\b\" : \"he would\",\n",
    "    r\"\\bhe'll\\b\" : \"he will\",\n",
    "    r\"\\bhe's\\b\" : \"he is\",\n",
    "    r\"\\bi'd\\b\" : \"I would\",\n",
    "    r\"\\bi'd\\b\" : \"I had\",\n",
    "    r\"\\bi'll\\b\" : \"I will\",\n",
    "    r\"\\bi'm\\b\" : \"I am\",\n",
    "    r\"\\bisn't\\b\" : \"is not\",\n",
    "    r\"\\bits\\b\" : \"it is\",\n",
    "    r\"\\bit's\\b\" : \"it is\",\n",
    "    r\"\\bit'll\\b\" : \"it will\",\n",
    "    r\"\\bi've\\b\" : \"I have\",\n",
    "    r\"\\blet's\\b\" : \"let us\",\n",
    "    r\"\\bmightn't\\b\" : \"might not\",\n",
    "    r\"\\bmustn't\\b\" : \"must not\",\n",
    "    r\"\\bshan't\\b\" : \"shall not\",\n",
    "    r\"\\bshe'd\\b\" : \"she would\",\n",
    "    r\"\\bshe'll\\b\" : \"she will\",\n",
    "    r\"\\bshe's\\b\" : \"she is\",\n",
    "    r\"\\bshouldn't\\b\" : \"should not\",\n",
    "    r\"\\bthat's\\b\" : \"that is\",\n",
    "    r\"\\bthere's\\b\" : \"there is\",\n",
    "    r\"\\bthey'd\\b\" : \"they would\",\n",
    "    r\"\\bthey'll\\b\" : \"they will\",\n",
    "    r\"\\bthey're\\b\" : \"they are\",\n",
    "    r\"\\bthey've\\b\" : \"they have\",\n",
    "    r\"\\bwe'd\\b\" : \"we would\",\n",
    "    r\"\\bwe're\\b\" : \"we are\",\n",
    "    r\"\\bweren't\\b\" : \"were not\",\n",
    "    r\"\\bwe've\\b\" : \"we have\",\n",
    "    r\"\\bwhat'll\\b\" : \"what will\",\n",
    "    r\"\\bwhat're\\b\" : \"what are\",\n",
    "    r\"\\bwhat's\\b\" : \"what is\",\n",
    "    r\"\\bwhat've\\b\" : \"what have\",\n",
    "    r\"\\bwhere's\\b\" : \"where is\",\n",
    "    r\"\\bwho'd\\b\" : \"who would\",\n",
    "    r\"\\bwho'll\\b\" : \"who will\",\n",
    "    r\"\\bwho're\\b\" : \"who are\",\n",
    "    r\"\\bwho's\\b\" : \"who is\",\n",
    "    r\"\\bwho've\\b\" : \"who have\",\n",
    "    r\"\\bwon't\\b\" : \"will not\",\n",
    "    r\"\\bwouldn't\\b\" : \"would not\",\n",
    "    r\"\\byou'd\\b\" : \"you would\",\n",
    "    r\"\\byou'll\\b\" : \"you will\",\n",
    "    r\"\\byou're\\b\" : \"you are\",\n",
    "    r\"\\byou've\\b\" : \"you have\",\n",
    "    r\"\\b're\\b\" : \" are\",\n",
    "    r\"\\bwasn't\\b\" : \"was not\",\n",
    "    r\"\\bwe'll\\b\" : \"will\",\n",
    "    r\"\\bdidn't\\b\" : \"did not\",\n",
    "    r\"\\btryin'\\b\" : \"trying\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# based on https://www.kaggle.com/prashantkikani/pooled-gru-with-preprocessing\n",
    "emoji_str_repls = {\n",
    "    \"&lt;3\": \" love \",\n",
    "    \":]\" : \" happy \",\n",
    "    \"=)\" : \" happy \",\n",
    "    \"8)\": \" happy \",\n",
    "    \":-)\": \" happy \",\n",
    "    \":)\": \" happy \",\n",
    "    \"(-:\": \" happy \",\n",
    "    \"(:\": \" happy \",\n",
    "    \":&gt;\": \" happy \",\n",
    "    \":')\": \" happy \",\n",
    "    \"(:\" : \" happy \",\n",
    "    \":d\": \" laughing \",\n",
    "    \":dd\": \" laughing \",\n",
    "    \";-)\" : \" wink \",\n",
    "    \";)\": \" wink \",\n",
    "    \":p\": \" playful \",\n",
    "    \":o\" : \" surprise \",\n",
    "    \":-(\": \" sad \",\n",
    "    \":(\": \" sad \",\n",
    "    \"=(\" : \" sad \",\n",
    "    \"):\" : \" sad \",\n",
    "    \":/\": \" skeptical \",\n",
    "    \":s\": \" skeptical \",\n",
    "    \":-s\": \" skeptical \",\n",
    "    \"^^\": \" nervous \",\n",
    "    \"^_^\": \" nervous \",\n",
    "    \"-_-\" : \" shame \",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "spelling_regex_repls = {\n",
    "    # abbreviations\n",
    "    r\"\\bacctg\\b\" : \"acct\",\n",
    "    r\"\\badd'l\\b\" : \"additional\",\n",
    "    r\"\\br\\s\\b\": \"are\",\n",
    "    r\"\\bu\\s\\b\": \"you \",\n",
    "    r\"\\b\\sm\\s\\b \": \"am\",\n",
    "    r\"'cause\\b\" : \"because\",\n",
    "    r\"\\b(ha)+\\b\": \"haha\",\n",
    "    r\"\\b(he)+\\b\": \"haha\",\n",
    "    r\"\\bya+y\\b\": \"yay\",\n",
    "    r\"\\bwa+y\\b\": \"way\",\n",
    "    r\"\\bf'real\\b\" : \"for real\",\n",
    "    r\"\\bgr8\\b\" : \"great\",\n",
    "    r\"\\bintl\\b\" : \"int'l\",\n",
    "    # common misspellings\n",
    "    r\"\\bbailable\\b\" : \"available\",\n",
    "    r\"\\babilty\\b\" : \"ability\",\n",
    "    r\"\\babsolutly\\b\" : \"absolutely\",\n",
    "    r\"\\babsoultely\\b\" : \"absolutely\",\n",
    "    r\"\\bacces\\b\" : \"access\",\n",
    "    r\"\\baccesability\\b\" : \"accessibility\",\n",
    "    r\"\\baccesbility\\b\" : \"accessibility\",\n",
    "    r\"\\baccesibility\\b\" : \"accessibility\",\n",
    "    r\"\\baccessability\\b\" : \"accessibility\",\n",
    "    r\"\\baccessbility\\b\" : \"accessibility\",\n",
    "    r\"\\baccesable\\b\" : \"accessible\",\n",
    "    r\"\\baccesible\\b\" : \"accessible\",\n",
    "    r\"\\baccessable\\b\" : \"accessible\",\n",
    "    r\"\\bacessible\\b\" : \"accessible\",\n",
    "    r\"\\bassessable\\b\" : \"availability\",\n",
    "    r\"\\baccidently\\b\" : \"accidentally\",\n",
    "    r\"\\baccomadate\\b\" : \"accommodate\",\n",
    "    r\"\\baccomdate\\b\" : \"accommodate\",\n",
    "    r\"\\baccomidate\\b\" : \"accommodate\",\n",
    "    r\"\\baccomodate\\b\" : \"accommodate\",\n",
    "    r\"\\baccomadating\\b\" : \"accommodating\",\n",
    "    r\"\\baccomidating\\b\" : \"accommodating\",\n",
    "    r\"\\baccomodating\\b\" : \"accommodating\",\n",
    "    r\"\\baccomadations\\b\" : \"accommodations\",\n",
    "    r\"\\baccomodation\\b\" : \"accommodation\",\n",
    "    r\"\\baccouting\\b\" : \"accounting\",\n",
    "    r\"\\baccross\\b\" : \"across\",\n",
    "    r\"\\badd'l\\b\" : \"additional\",\n",
    "    r\"\\badditonal\\b\" : \"additional\",\n",
    "    r\"\\baddtionally\\b\" : \"additionally\",\n",
    "    r\"\\badminstration\\b\" : \"administration\",\n",
    "    r\"\\badminstrative\\b\" : \"administrative\",\n",
    "    r\"\\badminstrator\\b\" : \"administrator\",\n",
    "    r\"\\badress\\b\" : \"address\",\n",
    "    r\"\\badvancment\\b\" : \"advancement\",\n",
    "    r\"\\badvertized\\b\" : \"advertised\",\n",
    "    r\"\\bafforable\\b\" : \"affordable\",\n",
    "    r\"\\bafordable\\b\" : \"affordable\",\n",
    "    r\"\\bafterall\\b\" : \"after all\",\n",
    "    r\"\\bafterhours\\b\" : \"after hours\",\n",
    "    r\"\\baggresive\\b\" : \"aggressive\",\n",
    "    r\"\\bagressive\\b\" : \"aggressive\",\n",
    "    r\"\\bagressions\\b\" : \"aggressions\",\n",
    "    r\"\\balittle\\b\" : \"a little\",\n",
    "    r\"\\balll\\b\" : \"all\",\n",
    "    r\"\\balloted\\b\" : \"allotted\",\n",
    "    r\"\\ballthough\\b\" : \"although\",\n",
    "    r\"\\balthought\\b\" : \"although\",\n",
    "    r\"\\ballways\\b\" : \"always\",\n",
    "    r\"\\balos\\b\" : \"also\",\n",
    "    r\"\\balot\\b\" : \"a lot\",\n",
    "    r\"\\balotted\\b\" : \"allotted\",\n",
    "    r\"\\bammount\\b\" : \"amount\",\n",
    "    r\"\\bammounts\\b\" : \"amounts\",\n",
    "    r\"\\bamoung\\b\" : \"among\",\n",
    "    r\"\\bamoungst\\b\" : \"amongst\",\n",
    "    r\"\\bannouncment\\b\" : \"announcement\",\n",
    "    r\"\\baparments\\b\" : \"apartments\",\n",
    "    r\"\\bapparrel\\b\" : \"apparel\",\n",
    "    r\"\\bappartment\\b\" : \"apartment\",\n",
    "    r\"\\bappriciate\\b\" : \"appreciate\",\n",
    "    r\"\\bassitance\\b\" : \"assistance\",\n",
    "    r\"\\bassitant\\b\" : \"assistant\",\n",
    "    r\"\\batleast\\b\" : \"at least\",\n",
    "    r\"\\battentative\\b\" : \"attentive\",\n",
    "    r\"\\battrocious\\b\" : \"atrocious\",\n",
    "    r\"\\bavaiable\\b\" : \"available\",\n",
    "    r\"\\bavaible\\b\" : \"available\",\n",
    "    r\"\\bavailabe\\b\" : \"available\",\n",
    "    r\"\\bavailble\\b\" : \"available\",\n",
    "    r\"\\bavailiable\\b\" : \"available\",\n",
    "    r\"\\bavailible\\b\" : \"available\",\n",
    "    r\"\\bavaliable\\b\" : \"available\",\n",
    "    r\"\\bavalible\\b\" : \"available\",\n",
    "    r\"\\bavilable\\b\" : \"available\",\n",
    "    r\"\\bavailiability\\b\" : \"availability\",\n",
    "    r\"\\bavailabiltiy\\b\" : \"availability\",\n",
    "    r\"\\bavailabilty\\b\" : \"availability\",\n",
    "    r\"\\bavailablility\\b\" : \"availability\",\n",
    "    r\"\\bavailablity\\b\" : \"availability\",\n",
    "    r\"\\bavailibility\\b\" : \"availability\",\n",
    "    r\"\\bavaliability\\b\" : \"availability\",\n",
    "    r\"\\bavaliablity\\b\" : \"availability\",\n",
    "    r\"\\bavalibility\\b\" : \"availability\",\n",
    "    r\"\\bactivies\\b\" : \"activities\",\n",
    "    r\"\\bactivites\\b\" : \"activities\",\n",
    "    r\"\\bactualy\\b\" : \"actually\",\n",
    "    r\"\\bacutally\\b\" : \"actually\",\n",
    "    r\"\\bammenities\\b\" : \"amenities\",\n",
    "    r\"\\bantoher\\b\" : \"another\",\n",
    "    r\"\\bassitant\\b\" : \"assistant\",\n",
    "    r\"\\baswell\\b\" : \"as well\",\n",
    "    r\"\\baweful\\b\" : \"awful\",\n",
    "    r\"\\bawfull\\b\" : \"awful\",\n",
    "    r\"\\bawsome\\b\" : \"awesome\",\n",
    "    r\"\\bbeacuse\\b\" : \"because\",\n",
    "    r\"\\bbearly\\b\" : \"barely\",\n",
    "    r\"\\bbeaurocracy\\b\" : \"bureaucracy\",\n",
    "    r\"\\bbeaurocratic\\b\" : \"bureaucratic\",\n",
    "    r\"\\bbecasue\\b\" : \"because\",\n",
    "    r\"\\bbecuase\\b\" : \"because\",\n",
    "    r\"\\bbecuse\\b\" : \"because\",\n",
    "    r\"\\bbefor\\b\" : \"before\",\n",
    "    r\"\\bbeggining\\b\" : \"beginning\",\n",
    "    r\"\\bbegining\\b\" : \"beginning\",\n",
    "    r\"\\bbeleive\\b\" : \"believe\",\n",
    "    r\"\\bbelive\\b\" : \"believe\",\n",
    "    r\"\\bbenificial\\b\" : \"beneficial\",\n",
    "    r\"\\bbenifit\\b\" : \"benefit\",\n",
    "    r'\\bbugetary\\b' : \"budgetary\",\n",
    "    r'\\bbuiding\\b' : \"building\",\n",
    "    r'\\bbuidling\\b' : \"building\",\n",
    "    r'\\bbuisness\\b' : \"business\",\n",
    "    r'\\bbuliding\\b' : \"building\",\n",
    "    r\"\\bbureacracy\\b\" : \"bureaucracy\",\n",
    "    r\"\\bburitto\\b\" : \"burrito\",\n",
    "    r\"\\bbussiness\\b\" : \"business\",\n",
    "    r\"\\bcalender\\b\" : \"calendar\",\n",
    "    r\"\\bcan;t\\b\" : \"can't\",\n",
    "    r\"\\bcasher\\b\" : \"cashier\",\n",
    "    r'\\bcatagories\\b' : \"categories\",\n",
    "    r'\\bcatagory\\b' : \"category\",\n",
    "    r\"\\bcheapter\\b\" : \"cheaper\",\n",
    "    r\"\\bcheeper\\b\" : \"cheaper\",\n",
    "    r'\\bclasss\\b' : \"clas\",\n",
    "    r'\\bclassses\\b' : \"classes\",\n",
    "    r\"\\bcleaniness\\b\" : \"cleanliness\",\n",
    "    r\"\\bcmapus\\b\" : \"campus\",\n",
    "    r'\\bcofee\\b' : \"coffee\",\n",
    "    r'\\bcoffe\\b' : \"coffee\",\n",
    "    r'\\bcollegue\\b' : \"colleague\",\n",
    "    r'\\bcoment\\b' : \"comment\",\n",
    "    r'\\bcoments\\b' : \"comments\",\n",
    "    r'\\bcomming\\b' : \"coming\",\n",
    "    r'\\bcommittment\\b' : \"commitment\",\n",
    "    r'\\bcommment\\b' : \"comment\",\n",
    "    r'\\bcommuication\\b' : \"communication\",\n",
    "    r'\\bcommunter\\b' : \"commuter\",\n",
    "    r'\\bcommunters\\b' : \"commuters\",\n",
    "    r'\\bcomotion\\b' : \"commotion\",\n",
    "    r'\\bcomparision\\b' : \"comparison\",\n",
    "    r'\\bcompatability\\b' : \"compatibility\",\n",
    "    r'\\bcompatable\\b' : \"compatible\",\n",
    "    r'\\bcompetative\\b' : \"competitive\",\n",
    "    r'\\bcompetetive\\b' : \"competitive\",\n",
    "    r'\\bcompetive\\b' : \"competitive\",\n",
    "    r'\\bcompletly\\b' : \"completely\",\n",
    "    r\"\\bcomraderie\\b\" : \"camaraderie\",\n",
    "    r'\\bcomradery\\b' : \"camaraderie\",\n",
    "    r'\\bcomunication\\b' : \"communication\",\n",
    "    r'\\bcomunity\\b' : \"community\",\n",
    "    r'\\bconcious\\b' : \"conscious\",\n",
    "    r'\\bcondusive\\b' : \"conducive\",\n",
    "    r'\\bconection\\b' : \"connection\",\n",
    "    r\"\\bconfortable\\b\" : \"comfortable\",\n",
    "    r'\\bconsistant\\b' : \"consistent\",\n",
    "    r'\\bconsistantly\\b' : \"consistently\",\n",
    "    r'\\bconsistenly\\b' : \"consistently\",\n",
    "    r'\\bcontinously\\b' : \"continuously\",\n",
    "    r'\\bcontruction\\b' : \"construction\",\n",
    "    r'\\bconveinent\\b' : \"convenient\",\n",
    "    r'\\bconveinient\\b' : \"convenient\",\n",
    "    r'\\bconveniant\\b' : \"convenient\",\n",
    "    r'\\bconveniece\\b' : \"convenience\",\n",
    "    r'\\bconveninent\\b' : \"convenient\",\n",
    "    r'\\bconvienance\\b' : \"convenience\",\n",
    "    r'\\bconvienant\\b' : \"convenient\",\n",
    "    r'\\bconvience\\b' : \"convenience\",\n",
    "    r'\\bconvienence\\b' : \"convenience\",\n",
    "    r'\\bconvienent\\b' : \"convenient\",\n",
    "    r'\\bconvienet\\b' : \"convenient\",\n",
    "    r'\\bconvienience\\b' : \"convenience\",\n",
    "    r'\\bconvienient\\b' : \"convenient\",\n",
    "    r'\\bconvient\\b' : \"convenient\",\n",
    "    r'\\bconviently\\b' : \"conveniently\",\n",
    "    r'\\bconvinence\\b' : \"convenience\",\n",
    "    r'\\bconvinent\\b' : \"convenient\",\n",
    "    r'\\bconvinience\\b' : \"convenience\",\n",
    "    r'\\bconvinient\\b' : \"convenient\",\n",
    "    r'\\bcorteous\\b' : \"courteous\",\n",
    "    r'\\bcostodial\\b' : \"custodial\",\n",
    "    r'\\bcoureous\\b' : \"courteous\",\n",
    "    r'\\bcourtis\\b' : \"courteous\",\n",
    "    r'\\bcouteous\\b' : \"courteous\",\n",
    "    r'\\bcovenient\\b' : \"convenient\",\n",
    "    r'\\bcroweded\\b' : \"crowded\",\n",
    "    r'\\bcurteous\\b' : \"courteous\",\n",
    "    r'\\bcurtesy\\b' : \"courtesy\",\n",
    "    r'\\bcurtious\\b' : \"courteous\",\n",
    "    r\"\\bdeaprtment\\b\" : \"department\",\n",
    "    r\"\\bdecission\\b\" : \"decision\",\n",
    "    r'\\bdefinately\\b' : \"definitely\",\n",
    "    r'\\bdefinetely\\b' : \"definitely\",\n",
    "    r'\\bdefinetly\\b' : \"definitely\",\n",
    "    r'\\bdefinitley\\b' : \"definitely\",\n",
    "    r'\\bdefinitly\\b' : \"definitely\",\n",
    "    r'\\bdelievered\\b' : \"delivered\",\n",
    "    r'\\bdeliverers\\b' : \"deliveries\",\n",
    "    r'\\bdeparment\\b' : \"department\",\n",
    "    r'\\bdeparments\\b' : \"department\",\n",
    "    r'\\bdepartement\\b' : \"department\",\n",
    "    r\"\\bdepartment\\(s\\b\" : \"departments\",\n",
    "    r'\\bdepartmet\\b' : \"department\",\n",
    "    r'\\bdepratment\\b' : \"department\",\n",
    "    r\"\\bdeptartment\\b\" : \"department\",\n",
    "    r'\\bdescrimination\\b' : \"discrimination\",\n",
    "    r'\\bdesireable\\b' : \"desirable\",\n",
    "    r\"\\bdiffernt\\b\" : \"different\",\n",
    "    r\"\\bdiffrent\\b\" : \"different\",\n",
    "    r'\\bdinig\\b' : \"dining\",\n",
    "    r'\\bdirverse\\b' : \"diverse\",\n",
    "    r'\\bdisapointed\\b' : \"disappointed\",\n",
    "    r'\\bdisapointing\\b' : \"disappointing\",\n",
    "    r'\\bdisasterous\\b' : \"disastrous\",\n",
    "    r'\\bdisatisfied\\b' : \"dissatisfied\",\n",
    "    r'\\bdisbursment\\b' : \"disbursement\",\n",
    "    r'\\bdisbursments\\b' : \"disbursements\",\n",
    "    r'\\bdiscretely\\b' : \"discreetly\",\n",
    "    r'\\bdiscusting\\b' : \"disgusting\",\n",
    "    r'\\bdisfunctional\\b' : \"dysfunctional\",\n",
    "    r'\\bdispensors\\b' : \"dispensers\",\n",
    "    r'\\bdispersement\\b' : \"disbursement\",\n",
    "    r'\\bdissapointed\\b' : \"disappointed\",\n",
    "    r'\\bdissapointing\\b' : \"disappointing\",\n",
    "    r'\\bdissapointment\\b' : \"disappointment\",\n",
    "    r'\\bdissappointed\\b' : \"disappointed\",\n",
    "    r'\\bdissappointing\\b' : \"disappointing\",\n",
    "    r'\\bdissatified\\b' : \"dissatisfied\",\n",
    "    r'\\bdiveristy\\b' : \"diversity\",\n",
    "    r'\\bdivison\\b' : \"division\",\n",
    "    r'\\bdivsion\\b' : \"division\",\n",
    "    r\"\\bdoens't\\b\" : \"doesn't\",\n",
    "    r\"\\bdoes't\\b\" : \"doesn't\",\n",
    "    r\"\\bdoesn;t\\b\" : \"doesn't\",\n",
    "    r\"\\bdon;t\\b\" : \"don't\",\n",
    "    r'\\bdonot\\b' : \"do not\",\n",
    "    r\"\\bdosen't\\b\" : \"doesn't\",\n",
    "    r\"\\bdosent\\b\" : \"doesn't\",\n",
    "    r'\\bdumbells\\b' : \"dumbbells\",\n",
    "    r'\\bdurring\\b' : \"during\",\n",
    "    r\"\\beatting\\b\" : \"eating\",\n",
    "    r\"\\beduation\\b\" : \"education\",\n",
    "    r'\\beffeciency\\b' : \"efficiency\",\n",
    "    r'\\beffecient\\b' : \"efficient\",\n",
    "    r'\\befficency\\b' : \"efficiency\",\n",
    "    r'\\befficent\\b' : \"efficient\",\n",
    "    r'\\beffiecient\\b' : \"efficient\",\n",
    "    r'\\beimplying\\b' : \"implying\",\n",
    "    r'\\bembarassed\\b' : \"embarrassed\",\n",
    "    r'\\bembarassing\\b' : \"embarrassing\",\n",
    "    r'\\bembarassment\\b' : \"embarrassment\",\n",
    "    r'\\bemploee\\b' : \"employee\",\n",
    "    r'\\bemploye\\b' : \"employee\",\n",
    "    r'\\bemployee\\(s\\b' : \"employees\",\n",
    "    r'\\bemployeed\\b' : \"employed\",\n",
    "    r'\\bemployement\\b' : \"employment\",\n",
    "    r'\\bemployes\\b' : \"employees\",\n",
    "    r'\\bemployess\\b' : \"employees\",\n",
    "    r'\\bemplyee\\b' : \"employee\",\n",
    "    r'\\bemplyees\\b' : \"employees\",\n",
    "    r'\\bempolyees\\b' : \"employees\",\n",
    "    r'\\bencoutered\\b' : \"encountered\",\n",
    "    r'\\benought\\b' : \"enough\",\n",
    "    r'\\benrollement\\b' : \"enrollment\",\n",
    "    r'\\benviorment\\b' : \"environment\",\n",
    "    r'\\benviornment\\b' : \"environment\",\n",
    "    r'\\benvirnment\\b' : \"environment\",\n",
    "    r'\\benviroment\\b' : \"environment\",\n",
    "    r'\\benvironement\\b' : \"environment\",\n",
    "    r'\\bequiped\\b' : \"equipped\",\n",
    "    r'\\bespcially\\b' : \"especially\",\n",
    "    r'\\bespecailly\\b' : \"especially\",\n",
    "    r'\\bespecialy\\b' : \"especially\",\n",
    "    r'\\bespeically\\b' : \"especially\",\n",
    "    r\"\\besthetically\\b\" : \"aesthetically \",\n",
    "    r\"\\bethinicity\\b\" : \"ethnicity\",\n",
    "    r\"\\bevaulation\\b\" : \"evaluation\",\n",
    "    r\"\\beventhough\\b\" : \"even though\",\n",
    "    r'\\beverday\\b' : \"every day\",\n",
    "    r'\\beverthing\\b' : \"everything\",\n",
    "    r'\\beveryones\\b' : \"everyones\",\n",
    "    r'\\beverythings\\b' : \"everythings\",\n",
    "    r'\\beveryway\\b' : \"every way\",\n",
    "    r'\\beveyone\\b' : \"everyone\",\n",
    "    r'\\beveything\\b' : \"everything\",\n",
    "    r'\\bevrything\\b' : \"everything\",\n",
    "    r'\\bexcelent\\b' : \"excellent\",\n",
    "    r'\\bexcellant\\b' : \"excellent\",\n",
    "    r'\\bexellent\\b' : \"excellent\",\n",
    "    r'\\bexhorbitant\\b' : \"exorbitant\",\n",
    "    r'\\bexistance\\b' : \"existence\",\n",
    "    r'\\bexpecially\\b' : \"especially\",\n",
    "    r'\\bexpensice\\b' : \"expensive\",\n",
    "    r'\\bexpereince\\b' : \"experience\",\n",
    "    r'\\bexperiance\\b' : \"experience\",\n",
    "    r'\\bexperince\\b' : \"experience\",\n",
    "    r'\\bexpierence\\b' : \"experience\",\n",
    "    r'\\bexpirence\\b' : \"experience\",\n",
    "    r'\\bexplaination\\b' : \"explanation\",\n",
    "    r'\\bexremely\\b' : \"extremely\",\n",
    "    r'\\bextemely\\b' : \"extremely\",\n",
    "    r'\\bextention\\b' : \"extension\",\n",
    "    r'\\bextermely\\b' : \"extremely\",\n",
    "    r'\\bextreamly\\b' : \"extremely\",\n",
    "    r'\\bextrememly\\b' : \"extremely\",\n",
    "    r'\\bextremly\\b' : \"extremely\",\n",
    "    r\"\\bfacilites\\b\" : \"facilities\",\n",
    "    r'\\bfacilties\\b' : \"facilities\",\n",
    "    r'\\bfacilty\\b' : \"facility\",\n",
    "    r'\\bfaculity\\b' : \"faculty\",\n",
    "    r'\\bfacutly\\b' : \"faculty\",\n",
    "    r'\\bfiancial\\b' : \"financial\",\n",
    "    r\"\\bfinacial\\b\" : \"financial\",\n",
    "    r\"\\bfirendly\\b\" : \"friendly\",\n",
    "    r'\\bflexability\\b' : \"flexibility\",\n",
    "    r'\\bflexibilty\\b' : \"flexibility\",\n",
    "    r'\\bflexiblity\\b' : \"flexibility\",\n",
    "    r\"\\bflourescent\\b\" : \"fluorescent\",\n",
    "    r'\\bfreindly\\b' : \"friendly\",\n",
    "    r'\\bfreqency\\b' : \"frequency\",\n",
    "    r'\\bfreqent\\b' : \"frequent\",\n",
    "    r'\\bfriednly\\b' : \"friendly\",\n",
    "    r'\\bfrusterating\\b' : \"frustrating\",\n",
    "    r'\\bfrusturating\\b' : \"frustrating\",\n",
    "    r'\\bfustrating\\b' : \"frustrating\",\n",
    "    r'\\bgovenor\\b' : \"governor\",\n",
    "    r\"\\bgraffitti\\b\" : \"graffiti\",\n",
    "    r\"\\bgrafitti\\b\" : \"graffiti\",\n",
    "    r\"\\bgreatful\\b\" : \"grateful\",\n",
    "    r\"\\bguarenteed\\b\" : \"guaranteed\",\n",
    "    r\"\\bguidlines\\b\" : \"guidelines\",\n",
    "    r\"\\bguranteed\\b\" : \"guaranteed\",\n",
    "    r\"\\bhappend\\b\" : \"happened\",\n",
    "    r'\\bharrass\\b' : \"harass\",\n",
    "    r'\\bharrassed\\b' : \"harassed\",\n",
    "    r'\\bharrassing\\b' : \"harassing\",\n",
    "    r'\\bharrassment\\b' : \"harassment\",\n",
    "    r\"\\bhavn't\\b\" : \"haven't\",\n",
    "    r'\\bhealtheir\\b' : \"healthier\",\n",
    "    r'\\bhealthly\\b' : \"healthy\",\n",
    "    r'\\bhealtier\\b' : \"healthier\",\n",
    "    r'\\bhealty\\b' : \"healthy\",\n",
    "    r'\\bheathy\\b' : \"healthy\",\n",
    "    r'\\bheirarchy\\b' : \"hierarchy\",\n",
    "    r'\\bhelful\\b' : \"helpful\",\n",
    "    r'\\bhelpfull\\b' : \"helpful\",\n",
    "    r'\\bhelpul\\b' : \"helpful\",\n",
    "    r'\\bhighschool\\b' : \"high school\",\n",
    "    r'\\bhighschools\\b' : \"high schools\",\n",
    "    r'\\bhorendous\\b' : \"horrendous\",\n",
    "    r'\\bhorible\\b' : \"horrible\",\n",
    "    r'\\bhouseing\\b' : \"housing\",\n",
    "    r'\\bi\"m\\b' : \"i'm\",\n",
    "    r'\\bi\"ve\\b' : \"i've\",\n",
    "    r'\\bimplimented\\b' : \"implemented\",\n",
    "    r'\\bimporve\\b' : \"improve\",\n",
    "    r'\\bimposible\\b' : \"impossible\",\n",
    "    r'\\bimprovment\\b' : \"improvement\",\n",
    "    r'\\bimprovments\\b' : \"improvements\",\n",
    "    r'\\bincompetant\\b' : \"incompetent\",\n",
    "    r'\\binconsistant\\b' : \"inconsistent\",\n",
    "    r'\\binconveinent\\b' : \"nconvenient\",\n",
    "    r'\\binconvience\\b' : \"inconvenience\",\n",
    "    r'\\binconvienent\\b' : \"nconvenient\",\n",
    "    r'\\binconvienient\\b' : \"nconvenient\",\n",
    "    r'\\binconvient\\b' : \"nconvenient\",\n",
    "    r'\\binconvinient\\b' : \"nconvenient\",\n",
    "    r'\\bindentify\\b' : \"identify\",\n",
    "    r'\\bindependant\\b' : \"independent\",\n",
    "    r'\\bindividual\\(s\\b' : \"individuals\",\n",
    "    r'\\binforced\\b' : \"enforced\",\n",
    "    r'\\binformaiton\\b' : \"information\",\n",
    "    r'\\binformtion\\b' : \"information\",\n",
    "    r'\\binfront\\b' : \"in front\",\n",
    "    r'\\binnout\\b' : \"in-n-out\",\n",
    "    r'\\binsentive\\b' : \"incentive\",\n",
    "    r'\\binsufficent\\b' : \"insufficient\",\n",
    "    r'\\binterenet\\b' : \"internet\",\n",
    "    r'\\binterent\\b' : \"internet\",\n",
    "    r'\\bintermural\\b' : \"intramural\",\n",
    "    r'\\bintramurals\\b' : \"intramurals\",\n",
    "    r'\\binvironment\\b' : \"environment\",\n",
    "    r'\\bissue\\(s\\b' : \"issues\",\n",
    "    r'\\bit;s\\b' : \"it's\",\n",
    "    r'\\bitem\\(s\\b' : \"items\",\n",
    "    r\"\\bjob\\(s\\b\" : \"jobs\",\n",
    "    r'\\bknowledable\\b' : \"knowledgeable\",\n",
    "    r'\\bknowledeable\\b' : \"knowledgeable\",\n",
    "    r'\\bknowledegable\\b' : \"knowledgeable\",\n",
    "    r'\\bknowledgable\\b' : \"knowledgeable\",\n",
    "    r'\\bknowledgably\\b' : \"knowledgeably\",\n",
    "    r'\\bknowledgeably\\b' : \"knowledgeably\",\n",
    "    r'\\bknowledgeble\\b' : \"knowledgeable\",\n",
    "    r'\\bknowlegable\\b' : \"knowledgeable\",\n",
    "    r'\\bknowlegeable\\b' : \"knowledgeable\",\n",
    "    r'\\bliek\\b' : \"like\",\n",
    "    r'\\blieke\\b' : \"like\",\n",
    "    r'\\blimted\\b' : \"limited\",\n",
    "    r'\\bmaintainance\\b' : \"maintenance\",\n",
    "    r'\\bmaintaince\\b' : \"maintenance\",\n",
    "    r'\\bmaintainence\\b' : \"maintenance\",\n",
    "    r'\\bmaintanance\\b' : \"maintenance\",\n",
    "    r'\\bmaintance\\b' : \"maintenance\",\n",
    "    r'\\bmaintanence\\b' : \"maintenance\",\n",
    "    r'\\bmaintenace\\b' : \"maintenance\",\n",
    "    r'\\bmaintenances\\b' : \"maintenance\",\n",
    "    r'\\bmaintence\\b' : \"maintenance\",\n",
    "    r'\\bmaintenece\\b' : \"maintenance\",\n",
    "    r'\\bmaintenence\\b' : \"maintenance\",\n",
    "    r'\\bmaitenance\\b' : \"maintenance\",\n",
    "    r'\\bmanager\\(s\\b' : \"managers\",\n",
    "    r'\\bmanagment\\b' : \"management\",\n",
    "    r'\\bmanangement\\b' : \"management\",\n",
    "    r'\\bmangement\\b' : \"management\",\n",
    "    r'\\bmangers\\b' : \"managers\",\n",
    "    r'\\bmanuever\\b' : \"maneuver\",\n",
    "    r'\\bmintues\\b' : \"minutes\",\n",
    "    r'\\bmoblie\\b' : \"mobile\",\n",
    "    r'\\bmulitple\\b' : \"multiple\",\n",
    "    r'\\bn\\?a\\b' : \"n/a\",\n",
    "    r'\\bna\\b' : \"n/a\",\n",
    "    r'\\bneccessary\\b' : \"necessary\",\n",
    "    r'\\bnecesary\\b' : \"necessary\",\n",
    "    r'\\bneedes\\b' : \"needs\",\n",
    "    r'\\bneeed\\b' : \"need\",\n",
    "    r'\\bnonexistant\\b' : \"nonexistent\",\n",
    "    r'\\bnothig\\b' : \"nothing\",\n",
    "    r'\\bnothjng\\b' : \"nothing\",\n",
    "    r'\\bnoticable\\b' : \"noticeable\",\n",
    "    r'\\bobsurd\\b' : \"absurd\",\n",
    "    r'\\bocassional\\b' : \"occasional\",\n",
    "    r'\\boccassion\\b' : \"occasion\",\n",
    "    r'\\boccassional\\b' : \"occasional\",\n",
    "    r'\\boccassionally\\b' : \"occasionally\",\n",
    "    r'\\boccassions\\b' : \"occasions\",\n",
    "    r'\\boccations\\b' : \"occasions\",\n",
    "    r'\\boccurances\\b' : \"occurrences\",\n",
    "    r'\\boccured\\b' : \"occurred\",\n",
    "    r'\\boccuring\\b' : \"occurring\",\n",
    "    r'\\boccurr\\b' : \"occur\",\n",
    "    r'\\bofcourse\\b' : \"of course\",\n",
    "    r'\\bofferred\\b' : \"offered\",\n",
    "    r'\\bopinon\\b' : \"opinion\",\n",
    "    r'\\bopitions\\b' : \"options\",\n",
    "    r'\\boportunities\\b' : \"opportunities\",\n",
    "    r'\\bopperation\\b' : \"operation\",\n",
    "    r'\\boppertunities\\b' : \"opportunities\",\n",
    "    r'\\boppinion\\b' : \"opinion\",\n",
    "    r'\\bopportunites\\b' : \"opportunities\",\n",
    "    r'\\bopportunties\\b' : \"opportunities\",\n",
    "    r'\\boppotunities\\b' : \"opportunities\",\n",
    "    r'\\boppurtunities\\b' : \"opportunities\",\n",
    "    r'\\boppurtunity\\b' : \"opportunity\",\n",
    "    r'\\borgnized\\b' : \"organized\",\n",
    "    r'\\boutragous\\b' : \"outrageous\",\n",
    "    r'\\bpage\\(s\\b' : \"pages\",\n",
    "    r'\\bpakages\\b' : \"packages\",\n",
    "    r'\\bparkibg\\b' : \"parking\",\n",
    "    r'\\bparkig\\b' : \"parking\",\n",
    "    r'\\bparkign\\b' : \"parking\",\n",
    "    r'\\bparkinglots\\b' : \"parking lots\",\n",
    "    r'\\bpartime\\b' : \"part-time\",\n",
    "    r'\\bparttime\\b' : \"part-time\",\n",
    "    r'\\bpatroling\\b' : \"patrolling\",\n",
    "    r'\\bpeopel\\b' : \"people\",\n",
    "    r'\\bpermitt\\b' : \"permit\",\n",
    "    r'\\bperson\\(s\\b' : \"persons\",\n",
    "    r'\\bpersonel\\b' : \"personnel\",\n",
    "    r'\\bpersonell\\b' : \"personnel\",\n",
    "    r'\\bpharamcy\\b' : \"pharmacy\",\n",
    "    r'\\bpleasent\\b' : \"pleasant\",\n",
    "    r'\\bplently\\b' : \"plenty\",\n",
    "    r'\\bplesant\\b' : \"pleasant\",\n",
    "    r'\\bpositon\\b' : \"position\",\n",
    "    r'\\bposses\\b' : \"possess\",\n",
    "    r'\\bpossition\\b' : \"position\",\n",
    "    r'\\bpostion\\b' : \"position\",\n",
    "    r'\\bpostions\\b' : \"positions\",\n",
    "    r'\\bpostition\\b' : \"position\",\n",
    "    r'\\bpostive\\b' : \"positive\",\n",
    "    r'\\bpractioner\\b' : \"practitioner\",\n",
    "    r'\\bpractioners\\b' : \"practitioners\",\n",
    "    r'\\bprefered\\b' : \"preferred\",\n",
    "    r'\\bpreferrably\\b' : \"preferably\",\n",
    "    r'\\bpreform\\b' : \"perform\",\n",
    "    r'\\bpreforming\\b' : \"performing\",\n",
    "    r'\\bpricess\\b' : \"prices\",\n",
    "    r'\\bpriciples\\b' : \"principles\",\n",
    "    r'\\bpricy\\b' : \"pricey\",\n",
    "    r'\\bprking\\b' : \"parking\",\n",
    "    r'\\bproceedures\\b' : \"procedures\",\n",
    "    r'\\bprocurment\\b' : \"procurement\",\n",
    "    r'\\bprofessionaly\\b' : \"professionally\",\n",
    "    r'\\bproffessional\\b' : \"professional\",\n",
    "    r'\\bproffit\\b' : \"profit\",\n",
    "    r'\\bprofitt\\b' : \"profit\",\n",
    "    r'\\bprogam\\b' : \"program\",\n",
    "    r'\\bpromissed\\b' : \"promised\",\n",
    "    r'\\bpublically\\b' : \"publicly\",\n",
    "    r'\\bqucik\\b' : \"quick\",\n",
    "    r'\\bquestion\\(s\\b' : \"questions\",\n",
    "    r'\\bquestionaire\\b' : \"questionnaire\",\n",
    "    r'\\breall\\b' : \"really\",\n",
    "    r'\\brealy\\b' : \"really\",\n",
    "    r'\\breccomend\\b' : \"recommend\",\n",
    "    r'\\breccommend\\b' : \"recommend\",\n",
    "    r'\\breceieve\\b' : \"receive\",\n",
    "    r'\\breciept\\b' : \"receipt\",\n",
    "    r'\\breciepts\\b' : \"receipts\",\n",
    "    r'\\brecieve\\b' : \"receive\",\n",
    "    r'\\brecieved\\b' : \"received\",\n",
    "    r'\\brecieves\\b' : \"receives\",\n",
    "    r'\\brecieving\\b' : \"receiving\",\n",
    "    r'\\brecived\\b' : \"received\",\n",
    "    r'\\brecomend\\b' : \"recommend\",\n",
    "    r'\\brecomended\\b' : \"recommended\",\n",
    "    r'\\brediculous\\b' : \"ridiculous\",\n",
    "    r'\\brediculously\\b' : \"ridiculously\",\n",
    "    r'\\brefered\\b' : \"referred\",\n",
    "    r'\\brefering\\b' : \"referring\",\n",
    "    r'\\bregeants\\b' : \"regents\",\n",
    "    r'\\bregistar\\b' : \"regisrtar\",\n",
    "    r'\\bregistars\\b' : \"regisrtars\",\n",
    "    r'\\bregulary\\b' : \"regularly\",\n",
    "    r'\\breimbursment\\b' : \"reimbursement\",\n",
    "    r'\\breponse\\b' : \"response\",\n",
    "    r'\\breponsive\\b' : \"responsive\",\n",
    "    r'\\brepresentitive\\b' : \"representative\",\n",
    "    r'\\breserach\\b' : \"research\",\n",
    "    r'\\bresonable\\b' : \"reasonable\",\n",
    "    r'\\bresouces\\b' : \"resources\",\n",
    "    r'\\bresourses\\b' : \"resources\",\n",
    "    r'\\bresponsed\\b' : \"responded\",\n",
    "    r'\\bresponsibilites\\b' : \"responsibilites\",\n",
    "    r'\\bresponsiblities\\b' : \"responsibilites\",\n",
    "    r'\\bresponsiblity\\b' : \"responsibility\",\n",
    "    r'\\brestaraunts\\b' : \"restaurants\",\n",
    "    r'\\brestraunts\\b' : \"restaurants\",\n",
    "    r'\\brestuarant\\b' : \"restaurant\",\n",
    "    r'\\brestuarants\\b' : \"restaurants\",\n",
    "    r'\\bresturant\\b' : \"restaurant\",\n",
    "    r'\\bresturants\\b' : \"restaurants\",\n",
    "    r'\\bridiculus\\b' : \"ridiculous\",\n",
    "    r'\\briduculous\\b' : \"ridiculous\",\n",
    "    r'\\broomate\\b' : \"roommate\",\n",
    "    r'\\broomates\\b' : \"roommates\",\n",
    "    r'\\bsaleries\\b' : \"salaries\",\n",
    "    r'\\bsandwhich\\b' : \"sandwich\",\n",
    "    r'\\bsandwhiches\\b' : \"sandwiches\",\n",
    "    r'\\bsandwitches\\b' : \"sandwiches\",\n",
    "    r'\\bsatifaction\\b' : \"satisfaction\",\n",
    "    r'\\bsatified\\b' : \"satisfisatisfieded\",\n",
    "    r'\\bsattelite\\b' : \"satellite\",\n",
    "    r'\\bsceience\\b' : \"science\",\n",
    "    r'\\bschedual\\b' : \"schedule\",\n",
    "    r'\\bseemless\\b' : \"seamless\",\n",
    "    r'\\bselction\\b' : \"selection\",\n",
    "    r'\\bsenority\\b' : \"seniority\",\n",
    "    r'\\bsensative\\b' : \"sensitive\",\n",
    "    r'\\bsensored\\b' : \"censored\",\n",
    "    r'\\bseperate\\b' : \"separate\",\n",
    "    r'\\bseperation\\b' : \"separation\",\n",
    "    r'\\bserivce\\b' : \"service\",\n",
    "    r'\\bserivces\\b' : \"services\",\n",
    "    r'\\bserive\\b' : \"service\",\n",
    "    r'\\bserives\\b' : \"services\",\n",
    "    r'\\bservicesi\\b' : \"services\",\n",
    "    r'\\bservidces\\b' : \"services\",\n",
    "    r'\\bservive\\b' : \"survive\",\n",
    "    r'\\bservives\\b' : \"survives\",\n",
    "    r'\\bseverly\\b' : \"severely\",\n",
    "    r'\\bsevice\\b' : \"service\",\n",
    "    r'\\bsevices\\b' : \"services\",\n",
    "    r'\\bshcool\\b' : \"school\",\n",
    "    r'\\bshoud\\b' : \"should\",\n",
    "    r'\\bshoudl\\b' : \"should\",\n",
    "    r'\\bshutttle\\b' : \"shuttle\",\n",
    "    r'\\bsimiliar\\b' : \"similar\",\n",
    "    r'\\bsomeitmes\\b' : \"sometimes\",\n",
    "    r'\\bsomeone\\(s\\b' : \"someones\",\n",
    "    r'\\bsomeones\\b' : \"someones\",\n",
    "    r'\\bsometiems\\b' : \"sometimes\",\n",
    "    r'\\bsomone\\b' : \"someone\",\n",
    "    r'\\bsomthing\\b' : \"something\",\n",
    "    r'\\bsophmore\\b' : \"sophomore\",\n",
    "    r'\\bspecialy\\b' : \"especially\",\n",
    "    r'\\bstafff\\b' : \"staff\",\n",
    "    r'\\bstatment\\b' : \"statement\",\n",
    "    r'\\bstong\\b' : \"strong\",\n",
    "    r'\\bstongly\\b' : \"strongly\",\n",
    "    r'\\bstoping\\b' : \"stopping\",\n",
    "    r'\\bstrabucks\\b' : \"starbucks\",\n",
    "    r'\\bstressfull\\b' : \"stressful\",\n",
    "    r'\\bstructure\\(s\\b' : \"structures\",\n",
    "    r'\\bstucture\\b' : \"structure\",\n",
    "    r'\\bstuctures\\b' : \"structures\",\n",
    "    r'\\bstuden\\b' : \"student\",\n",
    "    r'\\bstudent\\(s\\b' : \"students\",\n",
    "    r'\\bstudetns\\b' : \"students\",\n",
    "    r'\\bstudnet\\b' : \"student\",\n",
    "    r'\\bstudnets\\b' : \"students\",\n",
    "    r'\\bsucess\\b' : \"success\",\n",
    "    r'\\bsudent\\b' : \"student\",\n",
    "    r'\\bsudents\\b' : \"students\",\n",
    "    r'\\bsuperintendant\\b' : \"superintendent\",\n",
    "    r'\\bsuperviser\\b' : \"supervisor\",\n",
    "    r'\\bsupervisor\\(s\\b' : \"supervisors\",\n",
    "    r'\\bsupervisores\\b' : \"supervisors\",\n",
    "    r'\\bsuport\\b' : \"support\",\n",
    "    r'\\bsupples\\b' : \"supplies\",\n",
    "    r'\\bsuppossed\\b' : \"supposed\",\n",
    "    r'\\bsuprised\\b' : \"surprised\",\n",
    "    r'\\bsuvey\\b' : \"survey\",\n",
    "    r'\\bsytem\\b' : \"system\",\n",
    "    r'\\bthats\\b' : \"that's\",\n",
    "    r\"\\bthe're\\b\" : \"they're\",\n",
    "    r'\\btheives\\b' : \"thieves\",\n",
    "    r'\\bthiefs\\b' : \"thieves\",\n",
    "    r'\\bthreating\\b' : \"threatening\",\n",
    "    r'\\bthroughly\\b' : \"thoroughly\",\n",
    "    r'\\bthrought\\b' : \"throughout\",\n",
    "    r'\\bthroughtout\\b' : \"throughout\",\n",
    "    r'\\btodays\\b' : \"today's\",\n",
    "    r'\\btraing\\b' : \"training\",\n",
    "    r'\\btrainning\\b' : \"training\",\n",
    "    r'\\btranfers\\b' : \"transfers\",\n",
    "    r'\\btransfered\\b' : \"transferred\",\n",
    "    r'\\btransfering\\b' : \"transferring\",\n",
    "    r'\\btransporation\\b' : \"transportation\",\n",
    "    r'\\btransportaion\\b' : \"transportation\",\n",
    "    r'\\btransportations\\b' : \"transportations\",\n",
    "    r'\\btransportion\\b' : \"transportation\",\n",
    "    r'\\btrashbags\\b' : \"trash bags\",\n",
    "    r'\\btrashcans\\b' : \"trash cans\",\n",
    "    r'\\btremedously\\b' : \"tremendously\",\n",
    "    r'\\btshirt\\b' : \"t-shirt\",\n",
    "    r'\\btshirts\\b' : \"t-shirts\",\n",
    "    r'\\btution\\b' : \"tuition\",\n",
    "    r'\\btutition\\b' : \"tuition\",\n",
    "    r'\\bunaccessible\\b' : \"inaccessible\",\n",
    "    r'\\bunconvenient\\b' : \"inconvenient\",\n",
    "    r'\\bunecessary\\b' : \"unnecessary\",\n",
    "    r'\\bunflexible\\b' : \"inflexible\",\n",
    "    r'\\bunforseen\\b' : \"unforeseen\",\n",
    "    r'\\buniverisity\\b' : \"university\",\n",
    "    r'\\buniveristy\\b' : \"university\",\n",
    "    r'\\buniverity\\b' : \"university\",\n",
    "    r'\\bunknowledgeable\\b' : \"unknowledgable\",\n",
    "    r'\\bunneccessary\\b' : \"unnecessary\",\n",
    "    r'\\bunrealiable\\b' : \"unreliable\",\n",
    "    r'\\buntill\\b' : \"until\",\n",
    "    r'\\bunversity\\b' : \"university\",\n",
    "    r'\\buseability\\b' : \"usability\",\n",
    "    r'\\busefull\\b' : \"useful\",\n",
    "    r'\\bususally\\b' : \"usually\",\n",
    "    r'\\bvaccum\\b' : \"vacuum\",\n",
    "    r'\\bvaccuum\\b' : \"vacuum\",\n",
    "    r'\\bvaction\\b' : \"vacation\",\n",
    "    r'\\bvacume\\b' : \"vacuum\",\n",
    "    r'\\bvariaty\\b' : \"variety\",\n",
    "    r'\\bvarities\\b' : \"varieties\",\n",
    "    r'\\bvarity\\b' : \"variety\",\n",
    "    r'\\bvegeterian\\b' : \"vegetarian\",\n",
    "    r'\\bvegitarian\\b' : \"vegetarian\",\n",
    "    r'\\bvegitarians\\b' : \"vegetarians\",\n",
    "    r'\\bvegtables\\b' : \"vegetables\",\n",
    "    r'\\bventillation\\b' : \"ventilation\",\n",
    "    r'\\bveriety\\b' : \"variety\",\n",
    "    r'\\bvisted\\b' : \"visited\",\n",
    "    r'\\bvistor\\b' : \"visitor\",\n",
    "    r'\\bvistors\\b' : \"visitors\",\n",
    "    r'\\bweeekends\\b' : \"weekends\",\n",
    "    r'\\bwierd\\b' : \"weird\",\n",
    "    r'\\bwirless\\b' : \"wireless\",\n",
    "    r'\\bwithdrawl\\b' : \"withdrawal\",\n",
    "    r'\\bwoudl\\b' : \"would\",\n",
    "    r\"\\bwoudn't\\b\" : \"wouldn't\",\n",
    "    r\"\\bthier\\b\" : \"their\",\n",
    "    r\"\\bappartments\\b\" : \"apartments\",\n",
    "    r\"\\bbenifits\\b\" : \"benefits\",\n",
    "    r\"\\bexistant\\b\" : \"existent\",\n",
    "    r\"\\bsaftey\\b\" : \"safety\",\n",
    "    r'\\bdon\"t\\b' : \"don't\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weirdchar_str_repls = {\n",
    "    \"#39;\" : \"'\",   \n",
    "    'amp;' : '&',   \n",
    "    '#146;' : \"'\",   \n",
    "    'nbsp;' : ' ',   \n",
    "    '#36;' : '$',   \n",
    "    '\\\\n' : \"\\n\",   \n",
    "    'quot;' : \"'\",   \n",
    "    '’' : \"'\",   \n",
    "    \"´\" : \"'\",\n",
    "    \"`\" : \"'\",\n",
    "    '`' : \"'\", \n",
    "    '´' : \"'\", \n",
    "    '“' : '\"',   \n",
    "    '”' : '\"',   \n",
    "    '<br />' : \"\\n\",   \n",
    "    '\\\\\"' : '\"',   \n",
    "    '<unk>' : 'u_n',   \n",
    "    ' @.@ ' : '.',   \n",
    "    ' @-@ ' : '-',   \n",
    "    '\\\\' : ' \\\\ ',   \n",
    "    '•' : '-'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# does regex replace making the substitution the same case\n",
    "def re_replace(word, replacement, text):\n",
    "    def func(match):\n",
    "        g = match.group()\n",
    "        if g.islower(): return replacement.lower()\n",
    "        if g.istitle(): return replacement.title()\n",
    "        if g.isupper(): return replacement.upper()\n",
    "        return replacement      \n",
    "    \n",
    "    return re.sub(word, func, text, flags=re.I)\n",
    "\n",
    "# define regex and string replacements\n",
    "re_repls = {}  # e.g., { **spelling_regex_repls } \n",
    "str_repls = {} # e.g., { **weirdchar_str_repls }\n",
    "\n",
    "def make_replacements(t:str) -> str:\n",
    "    # replace based on regexs (keeping case) and then strings\n",
    "    for k, v in re_repls.items(): t = re_replace(k, v, t)\n",
    "    for k, v in str_repls.items(): t = t.replace(k, t)\n",
    "    return t\n",
    "\n",
    "# ensure am|pm is considered it own token (7:00pm > 7:00 pm, 7am-10pm > 7 am - 10 pm))\n",
    "def fix_ampm(t:str) -> str:\n",
    "    re_ampm = re.compile(r'(\\d+)(am|pm|am\\-|pm\\-|a\\.m\\.|p\\.m\\.|a\\.m\\.\\-|p\\.m\\.\\-)')    \n",
    "    return re_ampm.sub(r'\\1 \\2 ', t)\n",
    "\n",
    "# try to handle places where a new sentence doesn't begin with a space (e.g., I like dogs.I like cats)\n",
    "# without breaking apart things like urls and emails\n",
    "def fix_sentence_ends(t:str) -> str:\n",
    "    re_sentend = re.compile(r'(?<!www)\\.((?!com|edu|org|net|m\\b)[a-zA-Z]+)(?!(@|\\.(com|edu|org|net)))\\b') \n",
    "    return re_sentend.sub(r'. \\1 ', t)\n",
    "\n",
    "# separate hyphen|tilde if it is at beginning of letter/digit\n",
    "def fix_hyphenated_words(t:str) -> str:\n",
    "    re_hypword = re.compile(r'\\s(\\-+|~+)([a-zA-Z0-9])')\n",
    "    return re_hypword.sub(r' \\1 \\2', t)\n",
    "\n",
    "\n",
    "# prepend custom tokenization rules to defaults\n",
    "custom_tok_rules = defaults.text_pre_rules + [make_replacements, fix_ampm, fix_sentence_ends, fix_hyphenated_words]\n",
    "\n",
    "# use this customized Tokenizer for qualitative data\n",
    "tokenizer = Tokenizer(pre_rules=custom_tok_rules, special_cases=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# various default, LM, and classification paths\n",
    "PATH = Path('../data')\n",
    "CLEAN_DATA_PATH = Path('../data/clean')\n",
    "\n",
    "LM_PATH = PATH/'lm'\n",
    "CLS_PATH = PATH/'classification'\n",
    "STANDARD_THEME_PATH = CLS_PATH/'standard_themes'\n",
    "STANDARD_THEME_META_PATH = STANDARD_THEME_PATH/'meta'\n",
    "\n",
    "(LM_PATH/'models').mkdir(parents=True, exist_ok=True)\n",
    "(LM_PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "(STANDARD_THEME_META_PATH/'models').mkdir(parents=True, exist_ok=True)\n",
    "(STANDARD_THEME_META_PATH/'tmp').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic columns\n",
    "lm_dtypes = { \n",
    "    'Id': int, 'QuestionAnsID': int, 'AnswerText': str, 'AnswerText_NonEnglish': str, 'Language': str,\n",
    "    \n",
    "    'SurveyID': int, 'SurveyTypeID': int, 'BenchmarkSurveyType': str, 'ClientId': str,'RspID': int,\n",
    "    \n",
    "    'QuestionCategoryAbbr': str, 'QuestionText': str, 'QuestionClass': str, \n",
    "    \n",
    "    'QuestionCategoryID': float, 'QuestionReportAbbr': str, 'QuestionCategoryLabel': str, \n",
    "    'BenchmarkLevel1': str, 'BenchmarkLevel2': str, 'BenchmarkLevel3': str, 'ClientBenchmarkLevel': str,\n",
    "    \n",
    "    'GroupCode': float, 'GroupID': str, \n",
    "    'GroupLevel1Code': float, 'GroupLevel1Name': str,\n",
    "    'GroupLevel2Code': float, 'GroupLevel2Name': str,\n",
    "    'GroupLevel3Code': float, 'GroupLevel3Name': str,\n",
    "    'GroupLevel4Code': float, 'GroupLevel4Name': str,\n",
    "    'GroupLevel5Code': float, 'GroupLevel5Name': str,\n",
    "    'GroupLevel6Code': float, 'GroupLevel6Name': str,\n",
    "    'GroupLevel7Code': float, 'GroupLevel7Name': str,\n",
    "    'GroupLevel8Code': float, 'GroupLevel8Name': str,\n",
    "}\n",
    "\n",
    "lm_dtypes_sc = { convert_to_snakecase(k):v for k,v in lm_dtypes.items() }\n",
    "\n",
    "standard_theme_meta_dtypes = {\n",
    "    'standard_theme_id': int,\n",
    "    'theme': str,\n",
    "    'url_friendly_theme': str,\n",
    "    'theme_display_order': int,\n",
    "    'avg_sentiment': float,\n",
    "    'is_example': int\n",
    "}\n",
    "\n",
    "# date columns\n",
    "date_cols = []\n",
    "    \n",
    "\n",
    "STANDARD_THEME_META_LABELS = list(standard_theme_meta_dtypes.keys())[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pickle.load(open(LM_PATH/'vocab.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39904"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier\n",
    "\n",
    "The classifier is basically a linear layer custom head on top of the LM backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 24000\n",
    "\n",
    "bptt, em_sz, nh, nl = 70, 400, 1150, 3\n",
    "bsz = 80\n",
    "wd = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define what text columns to use (can be multiple)\n",
    "corpus_cols = ['theme', 'answer_text'] \n",
    "\n",
    "# define how to identify the text we are using for the LM\n",
    "corpus_suf = '_multitask' #'_cleaned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(STANDARD_THEME_META_PATH/'train.csv')\n",
    "valid_df = pd.read_csv(STANDARD_THEME_META_PATH/'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any rows whre the \"corpus_cols\" are nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=corpus_cols, inplace=True)\n",
    "valid_df.dropna(subset=corpus_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avg_sentiment', 'is_example']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STANDARD_THEME_META_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(set(train_df.theme.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab.itos += [ item.lower() for item in list(set(train_df.theme.unique())) ]\n",
    "# vocab.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(vocab.itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskFloatList(FloatList):\n",
    "    def __init__(self, items:Iterator, n_classes:int=1, log:bool=False, classes:Collection=None, **kwargs):\n",
    "        super().__init__(items, log, classes, **kwargs)\n",
    "        self.c = n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MSELoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "cls_processor = [\n",
    "    TokenizeProcessor(tokenizer=tokenizer, chunksize=chunksize, mark_fields=True),\n",
    "    NumericalizeProcessor(vocab=vocab)\n",
    "]\n",
    "\n",
    "data_clas = (ItemLists(path=STANDARD_THEME_META_PATH,\n",
    "                     train=TextList.from_df(\n",
    "                         train_df, path=STANDARD_THEME_META_PATH, cols=corpus_cols, processor=cls_processor),\n",
    "                     valid=TextList.from_df(\n",
    "                         valid_df, path=STANDARD_THEME_META_PATH, cols=corpus_cols, processor=cls_processor)\n",
    "                    )\n",
    "             .label_from_df(cols=STANDARD_THEME_META_LABELS, label_cls=partial(MultiTaskFloatList,n_classes=2))\n",
    "             .databunch(bs=bsz)\n",
    "          )\n",
    "\n",
    "data_clas.save(f'data_cls_standard_theme_meta.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = load_data(STANDARD_THEME_META_PATH, f'data_cls_standard_theme_meta.pkl', bs=bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxfld 1 xxmaj supervisor xxmaj effectiveness / xxmaj resolves xxmaj staff xxmaj issues xxfld 2 xxmaj leaders need to be trained to be xxmaj leaders xxrep 4 . xxmaj leaders need to be in their departments to lead not in meetings xxup all day xxrep 4 . xxmaj leaders need to learn how to train and discipline xxrep 4 . xxmaj leaders need to learn how to handle conflict in the work place and discipline those who do n't comply with xxup ucsd and or xxmaj department policies\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(data_clas.train_ds.x[0])\n",
    "print(data_clas.train_ds.y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4619 39904\n",
      "514 39904\n"
     ]
    }
   ],
   "source": [
    "print(len(data_clas.train_ds), len(data_clas.train_ds.vocab.itos))\n",
    "print(len(data_clas.valid_ds), len(data_clas.valid_ds.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(data_clas.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 486])\n",
      "torch.Size([80, 2])\n",
      "torch.Size([80, 486]) torch.cuda.LongTensor torch.Size([80, 2]) torch.cuda.FloatTensor 80\n"
     ]
    }
   ],
   "source": [
    "batch = next(it)\n",
    "print(batch[0].size())\n",
    "print(batch[1].size())\n",
    "print(batch[0].size(), batch[0].type(), batch[1].size(), batch[1].type(), bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xxbos xxfld 1 xxmaj ethical xxmaj conduct / xxmaj perform xxmaj responsibilities / xxmaj spirit of xxmaj cooperation xxfld 2 xxmaj in the xxmaj enterprise xxmaj network and xxmaj telecommunications group of xxup its , the environment continues to be toxic , retaliatory , abusive , and discriminatory as in past years . xxmaj under the direction of xxmaj james xxmaj seddon , supervisor xxmaj malerie xxmaj samadi harasses and talks down to employees . xxmaj manipulates and edits official documentation to make staff look and give lower performance appraisal ratings or retaliate against them . xxmaj also , use the same practice to provide their friends with higher performance ratings and award them with higher merit increases . xxmaj senior management continues to harbor this behavior without any consequence and or accountability . xxmaj james and xxmaj malerie exploit minorities and give preferential treatment to personnel hired by them . xxmaj regularly abuse the power that the xxmaj university of xxmaj california gives them and exercise nepotism because they are both product of such practices . \\\\ r \\n  xxmaj other supervisors like xxmaj ynez xxmaj hicks also participates in the same practices of xxunk , nepotism , and favoritism . \\\\ r \\n  xxmaj it is unacceptable that this behavior and practices continue to be used by management without any accountability . xxmaj principles of the community are ignored continuously daily . xxmaj when this type of situation is brought up to xxmaj human xxmaj resources , they ignore them because no one is enforcing the xxup uc xxmaj principles . xxmaj james xxmaj seddon and xxmaj malerie xxmaj samadi in the xxmaj datacom group do n't care about staff promotion , compensation , and well being . xxmaj they only care about themselves and their friends . xxmaj hiring practices are unfair ; they manipulate the process so they can hire barely qualified personnel into experienced positions . xxmaj existing staff is overworked because newer personnel can not pull their weight , yet xxmaj malerie and xxmaj james make it look like they are in their appraisals . xxmaj they mentally abuse staff and minimize their work performance . xxmaj recently one of the team member past away while working at home . a stroke caused by the stress and the pressure that xxmaj malerie was putting on xxmaj david xxmaj ramirez . xxmaj she used him to get her promotion to supervisor and make her look good in front of others . \\\\ r \\n  xxmaj both xxmaj james and xxmaj malerie are the perfect examples of bad management . xxmaj somehow they continue to occupy their positions , and xxmaj senior xxmaj management does n't do anything about it . \\\\ r \\n  xxmaj the lowest level the xxmaj datacom team has been in years , all because of xxmaj james and xxmaj malerie 's arrogance and lack of ethics .\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([ data_clas.train_ds.vocab.itos[idx] for idx in batch[0][0,:] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxfld 1 xxmaj ethical xxmaj conduct / xxmaj perform xxmaj responsibilities / xxmaj spirit of xxmaj cooperation xxfld 2 xxmaj in the xxmaj enterprise xxmaj network and xxmaj telecommunications group of xxup its , the environment continues to be toxic , retaliatory , abusive , and discriminatory as in past years . xxmaj under the direction of xxmaj james xxmaj seddon , supervisor xxmaj malerie xxmaj samadi harasses and</td>\n",
       "      <td>[1. 1.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxfld 1 xxmaj supervisor xxmaj effectiveness / xxmaj resolves xxmaj staff xxmaj issues xxfld 2 xxmaj in the xxmaj enterprise xxmaj network and xxmaj telecommunications group of xxup its , the environment continues to be toxic , retaliatory , abusive , and discriminatory as in past years . xxmaj under the direction of xxmaj james xxmaj seddon , supervisor xxmaj malerie xxmaj samadi harasses and talks down to employees</td>\n",
       "      <td>[1. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxfld 1 xxmaj fear of xxmaj retaliation , xxmaj negative xxmaj consequences xxfld 2 xxmaj in the xxmaj enterprise xxmaj network and xxmaj telecommunications group of xxup its , the environment continues to be toxic , retaliatory , abusive , and discriminatory as in past years . xxmaj under the direction of xxmaj james xxmaj seddon , supervisor xxmaj malerie xxmaj samadi harasses and talks down to employees .</td>\n",
       "      <td>[1.5 0. ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxfld 1 xxmaj favoritism / xxmaj cliques xxfld 2 xxmaj in the xxmaj enterprise xxmaj network and xxmaj telecommunications group of xxup its , the environment continues to be toxic , retaliatory , abusive , and discriminatory as in past years . xxmaj under the direction of xxmaj james xxmaj seddon , supervisor xxmaj malerie xxmaj samadi harasses and talks down to employees . xxmaj manipulates and edits official</td>\n",
       "      <td>[1. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxfld 1 xxmaj parking / xxmaj transportation xxfld 2 xxmaj insights as alumna / former student of xxup ucsd , working on main campus 3.5 + years , xxmaj mexican - xxmaj american female &amp; varied experience from start - up to non - profit to corporate : \\ r \\n  1 . xxmaj dept / xxmaj culture : xxmaj all , not just leadership / xxup hr-</td>\n",
       "      <td>[2. 0.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure a forward or backwards run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwards = True\n",
    "\n",
    "m_suf = '_multitask' #'_cleaned'\n",
    "m_pre = 'bwd_' if (backwards) else 'fwd_'\n",
    "\n",
    "data_clas = load_data(STANDARD_THEME_META_PATH, f'data_cls_standard_theme_meta.pkl', bs=bsz, backwards=backwards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the classifier (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.171875\n"
     ]
    }
   ],
   "source": [
    "unique_is_example_vals = list(train_df.is_example.value_counts())\n",
    "is_example_pos_weight = (np.max(unique_is_example_vals) / unique_is_example_vals)[1]\n",
    "\n",
    "print(is_example_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitask_config = {\n",
    "    'sentiment':  { \n",
    "        'type': 'regression', 'input_idxs': [0], 'target_idxs': [0], \n",
    "        'y_range': [1., 5.1],\n",
    "        'loss_weight': 1.\n",
    "    },\n",
    "    'is_example': { \n",
    "        'type': 'binaryclass', 'input_idxs': [1], 'target_idxs': [1], \n",
    "        'y_range': None,\n",
    "        'class_weights': torch.tensor([is_example_pos_weight]),\n",
    "        'loss_weight': 0.1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x, raw_outputs, outputs = input\n",
    "        \n",
    "        for k,v in self.config.items():\n",
    "            outv = x[:, v['input_idxs']]\n",
    "            if (v['y_range']): outv = self._constrain_range(outv, v['y_range'])\n",
    "            x[:, v['input_idxs']] = outv\n",
    "            \n",
    "        return x, raw_outputs, outputs\n",
    "    \n",
    "    def _constrain_range(self, x, y_range):\n",
    "        x = torch.sigmoid(x)\n",
    "        x = x * (y_range[1] - y_range[0])\n",
    "        x = x + y_range[0]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiTaskLossFlat(*args, axis:int=-1, config=multitask_config, **kwargs):\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for k,v in config.items():\n",
    "        input_targs = [args[0][:, v['input_idxs']], args[1][:, v['target_idxs']]]\n",
    "        class_weights = v['class_weights'].to(input_targs[0].device) if ('class_weights' in v) else None\n",
    "        \n",
    "        if (v['type'] ==  'regression'): \n",
    "            loss = MSELossFlat(axis=axis, **kwargs)(*input_targs)\n",
    "            \n",
    "        elif (v['type'] ==  'multiclass'): \n",
    "            input_targs[1] = input_targs[1].long()\n",
    "            loss = CrossEntropyFlat(weight=class_weights, axis=axis, **kwargs)(*input_targs)\n",
    "            \n",
    "        elif (v['type'] ==  'binaryclass'): \n",
    "            input_targs[1] = input_targs[1].long()\n",
    "            if (v['y_range']):\n",
    "                loss = BCEFlat(axis=axis, **kwargs)(*input_targs)\n",
    "            else:\n",
    "                loss = BCEWithLogitsFlat(pos_weight=class_weights, axis=axis, **kwargs)(*input_targs)\n",
    "                \n",
    "        elif (v['type'] ==  'multilabel'): \n",
    "            input_targs[1] = input_targs[1].long()\n",
    "            if (v['y_range']):\n",
    "                loss = BCEFlat(axis=axis, **kwargs)(*input_targs)\n",
    "            else:\n",
    "                loss = BCEWithLogitsFlat(pos_weight=class_weights, axis=axis, **kwargs)(*input_targs)\n",
    "                \n",
    "        losses.append(v['loss_weight'] * loss)\n",
    "    \n",
    "    return torch.sum(torch.stack(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup the dropouts for the model - these values have been chosen after experimentation. If you need to update them for custom LMs, you can change the weighting factor (0.7 here) based on the amount of data you have. For more data, you can reduce dropout factor and for small datasets, you can reduce overfitting by choosing a higher dropout factor. *No other dropout value requires tuning*\n",
    "\n",
    "We first tune the last embedding layer so that the missing tokens initialized with mean weights get tuned properly. So we freeze everything except the last layer.\n",
    "\n",
    "We also keep track of the *accuracy* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1\n",
    "start = 0.1\n",
    "\n",
    "def fscore(preds, targs):\n",
    "    return metrics_util.best_fscore(preds, targs, beta, start=start)\n",
    "    \n",
    "def opt_th(preds, targs):\n",
    "    return metrics_util.best_fthresh(preds, targs, beta=beta, start=start)\n",
    "\n",
    "def multilbl_accuracy(preds, targs):\n",
    "    return metrics_util.multi_accuracy(preds, targs, beta=beta, start=start)\n",
    "\n",
    "def is_example_acc(preds, targs):\n",
    "    return accuracy(preds[:, 1:2], targs[:, 1])\n",
    "\n",
    "def sentiment_mse(preds, targs):\n",
    "    return mse(preds[:, 0], targs[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: learn.purge(); learn = None; torch.cuda.empty_cache(); gc.collect();\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, pretrained=False,\n",
    "                                drop_mult=0.5, bptt=bptt, lin_ftrs=[50], ps=[0.1],\n",
    "                                alpha=2., beta=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dict(learn.model.named_modules())\n",
    "# x['1.layers.6'].out_features=3\n",
    "# x['1.layers'].add_module('multitask', MultiTaskClassifier(config=multitask_config))\n",
    "learn.model.add_module('multitask', MultiTaskClassifier(config=multitask_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = list(learn.model.modules())[-2]\n",
    "# x\n",
    "# x.out_features=3\n",
    "# x.add_module('asdfasdf',nn.Linear(3,2,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.clip = 25.\n",
    "learn.loss_func = partial(MultiTaskLossFlat, config=multitask_config)\n",
    "learn.metrics = [is_example_acc, sentiment_mse]\n",
    "\n",
    "learn.model_dir = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_cb = partial(SaveModelCallback, monitor='valid_loss', mode='min', name=f'{m_pre}cls_bestmodel{m_suf}')\n",
    "\n",
    "learn.callback_fns.append(best_model_cb)\n",
    "# learn.callback_fns.append(RocAucEvaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from /lm/models -> class/models (both fwd and bwd weights)\n",
    "! cp {LM_PATH/'models/*_lm_enc.pth'} {STANDARD_THEME_META_PATH/'models/'}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load_encoder(f'{m_pre}lm_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = STANDARD_THEME_META_PATH/f'models/{m_pre}cls_bestmodel{m_suf}*'\n",
    "!rm {best_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-2\n",
    "wd = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(lr/1000, wd=wd)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set learning rates and fit our IMDB LM. We first run one epoch to tune the last layer which contains the embedding weights. This should help the missing tokens in the wikitext103 learn better weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:09 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>is_example_acc</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.982454</td>\n",
       "      <td>0.775768</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>0.649911</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.7757678031921387.\n",
      "CPU times: user 5.72 s, sys: 3.54 s, total: 9.26 s\n",
      "Wall time: 9.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn.fit_one_cycle(1, lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'{m_pre}cls_last_ft{m_suf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will load the best when training ends automaticall ... #learn = learn.load(f'{lm_pre}cls_last_ft{exp_suffix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:10 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>is_example_acc</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.828432</td>\n",
       "      <td>0.654378</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>0.540449</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.6543784141540527.\n"
     ]
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(5e-2/(2.6**4),5e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'{m_pre}cls_last2_ft{m_suf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will load the best when training ends automaticall ... #learn = learn.load(f'{lm_pre}cls_last2_ft{exp_suffix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:14 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>is_example_acc</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.661724</td>\n",
       "      <td>0.597494</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>0.485003</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.5974938273429871.\n"
     ]
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'{m_pre}cls_last3_ft{m_suf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will load the best when training ends automaticall ... \n",
    "# learn = learn.load(f'{lm_pre}cls_last3_ft{exp_suffix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 03:02 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>is_example_acc</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.624796</td>\n",
       "      <td>0.586398</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>0.475809</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.609390</td>\n",
       "      <td>0.589126</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>0.482059</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.589414</td>\n",
       "      <td>0.576777</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>0.467646</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.560704</td>\n",
       "      <td>0.571593</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>0.461598</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.538916</td>\n",
       "      <td>0.572163</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>0.462485</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.519013</td>\n",
       "      <td>0.572294</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>0.454377</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.483885</td>\n",
       "      <td>0.580296</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>0.460641</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.465552</td>\n",
       "      <td>0.597406</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>0.474224</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.458753</td>\n",
       "      <td>0.585930</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>0.465440</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.454602</td>\n",
       "      <td>0.585971</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>0.463412</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.5863980650901794.\n",
      "Better model found at epoch 2 with valid_loss value: 0.5767768621444702.\n",
      "Better model found at epoch 3 with valid_loss value: 0.5715926885604858.\n"
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'{m_pre}cls{m_suf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SequentialRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MultiBatchEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AWD_LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type EmbeddingDropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WeightDropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNNDropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type PoolingLinearClassifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm1d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/wgilliam/anaconda3/envs/tritonlytics-ml/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MultiTaskClassifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "learn.export(file=f'{m_pre}export_clas{m_suf}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use it for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_learn = load_learner(STANDARD_THEME_META_PATH, file=f'{m_pre}export_clas{m_suf}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FloatItem [2.332911 3.71665 ],\n",
       " tensor([2.3329, 3.7167]),\n",
       " tensor([2.3329, 3.7167]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn.predict('EVERYTHING IS GOING SO GREAT! ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review final validation loss for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5715927481651306\n"
     ]
    }
   ],
   "source": [
    "learn = learn.load(f'{m_pre}cls_bestmodel{m_suf}')\n",
    "probs, targs, loss = learn.get_preds(DatasetType.Valid, with_loss=True)\n",
    "\n",
    "print(f'Validation Loss: {loss / len(probs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2693) tensor(3.0864) tensor(0.9563) tensor([1., 0.])\n",
      "tensor(2.4261) tensor(-1.3441) tensor(0.2068) tensor([2., 0.])\n",
      "tensor(2.0391) tensor(-0.3867) tensor(0.4045) tensor([1., 0.])\n",
      "tensor(2.4052) tensor(-1.6456) tensor(0.1617) tensor([2., 0.])\n",
      "tensor(2.6459) tensor(-0.8460) tensor(0.3003) tensor([3., 0.])\n",
      "tensor(1.6674) tensor(0.4598) tensor(0.6130) tensor([1., 1.])\n",
      "tensor(2.0687) tensor(-1.8093) tensor(0.1407) tensor([1., 0.])\n",
      "tensor(2.0802) tensor(-1.3341) tensor(0.2085) tensor([2., 0.])\n",
      "tensor(2.3332) tensor(-1.1854) tensor(0.2341) tensor([3., 0.])\n",
      "tensor(2.2552) tensor(-1.8874) tensor(0.1315) tensor([3., 0.])\n",
      "tensor(1.9742) tensor(-0.5663) tensor(0.3621) tensor([2., 0.])\n",
      "tensor(1.9664) tensor(-0.5865) tensor(0.3574) tensor([2., 0.])\n",
      "tensor(2.2708) tensor(-0.9960) tensor(0.2697) tensor([2., 0.])\n",
      "tensor(2.0157) tensor(-2.1205) tensor(0.1071) tensor([2., 0.])\n",
      "tensor(2.4358) tensor(-0.1824) tensor(0.4545) tensor([3., 0.])\n",
      "tensor(1.8430) tensor(0.2637) tensor(0.5655) tensor([2., 0.])\n",
      "tensor(2.0740) tensor(-1.4401) tensor(0.1915) tensor([3., 0.])\n",
      "tensor(2.7582) tensor(-1.6957) tensor(0.1550) tensor([3., 0.])\n",
      "tensor(1.9719) tensor(-1.5055) tensor(0.1816) tensor([2., 0.])\n",
      "tensor(2.2092) tensor(-0.7529) tensor(0.3202) tensor([4., 0.])\n",
      "tensor(1.4232) tensor(2.3513) tensor(0.9130) tensor([2., 1.])\n",
      "tensor(2.8539) tensor(-1.5603) tensor(0.1736) tensor([5., 0.])\n",
      "tensor(2.0995) tensor(-0.8233) tensor(0.3051) tensor([2., 0.])\n",
      "tensor(2.1437) tensor(-1.1255) tensor(0.2450) tensor([3., 0.])\n",
      "tensor(2.2397) tensor(-1.2515) tensor(0.2224) tensor([3., 0.])\n",
      "tensor(3.0729) tensor(-1.2599) tensor(0.2210) tensor([3., 0.])\n",
      "tensor(2.8969) tensor(-0.9922) tensor(0.2705) tensor([3., 0.])\n",
      "tensor(2.1785) tensor(1.0042) tensor(0.7319) tensor([2., 0.])\n",
      "tensor(3.4520) tensor(-0.1280) tensor(0.4680) tensor([3., 0.])\n",
      "tensor(1.7019) tensor(0.5378) tensor(0.6313) tensor([2., 0.])\n",
      "tensor(2.8817) tensor(-1.5542) tensor(0.1745) tensor([3., 0.])\n",
      "tensor(2.0797) tensor(-0.9997) tensor(0.2690) tensor([3., 0.])\n",
      "tensor(1.9539) tensor(-1.5970) tensor(0.1684) tensor([2., 0.])\n",
      "tensor(1.7104) tensor(0.2327) tensor(0.5579) tensor([1.5000, 0.0000])\n",
      "tensor(1.5622) tensor(-0.3609) tensor(0.4107) tensor([2., 0.])\n",
      "tensor(2.3007) tensor(-1.3082) tensor(0.2128) tensor([3., 0.])\n",
      "tensor(2.1008) tensor(-1.1115) tensor(0.2476) tensor([3., 0.])\n",
      "tensor(2.4463) tensor(-0.7837) tensor(0.3135) tensor([3., 0.])\n",
      "tensor(1.8061) tensor(-0.6062) tensor(0.3529) tensor([1., 0.])\n",
      "tensor(2.8391) tensor(-1.3931) tensor(0.1989) tensor([3., 0.])\n",
      "tensor(1.7429) tensor(0.4835) tensor(0.6186) tensor([1., 0.])\n",
      "tensor(2.1158) tensor(-0.8171) tensor(0.3064) tensor([3., 0.])\n",
      "tensor(1.9097) tensor(-1.3211) tensor(0.2106) tensor([5., 0.])\n",
      "tensor(2.0207) tensor(-1.4064) tensor(0.1968) tensor([1.5000, 0.0000])\n",
      "tensor(2.9668) tensor(-1.0157) tensor(0.2659) tensor([3., 0.])\n",
      "tensor(2.2219) tensor(-0.7460) tensor(0.3217) tensor([3., 0.])\n",
      "tensor(1.4727) tensor(1.3838) tensor(0.7996) tensor([2., 1.])\n",
      "tensor(2.4602) tensor(-1.9501) tensor(0.1245) tensor([3., 0.])\n",
      "tensor(2.9038) tensor(-1.2131) tensor(0.2291) tensor([3., 0.])\n",
      "tensor(1.8518) tensor(-1.2302) tensor(0.2262) tensor([2., 0.])\n",
      "tensor(2.0430) tensor(-2.5724) tensor(0.0709) tensor([2., 0.])\n",
      "tensor(2.1720) tensor(-1.6984) tensor(0.1547) tensor([3., 0.])\n",
      "tensor(2.1393) tensor(-1.3398) tensor(0.2075) tensor([3., 0.])\n",
      "tensor(1.6981) tensor(-0.0754) tensor(0.4812) tensor([1., 0.])\n",
      "tensor(1.2956) tensor(3.2093) tensor(0.9612) tensor([2., 0.])\n",
      "tensor(2.4896) tensor(-0.9841) tensor(0.2721) tensor([3., 0.])\n",
      "tensor(2.0967) tensor(-0.5253) tensor(0.3716) tensor([4., 0.])\n",
      "tensor(1.8450) tensor(-1.2084) tensor(0.2300) tensor([2., 0.])\n",
      "tensor(2.0099) tensor(-1.6978) tensor(0.1548) tensor([2., 0.])\n",
      "tensor(2.1926) tensor(-1.7882) tensor(0.1433) tensor([3., 0.])\n",
      "tensor(3.5344) tensor(-0.1501) tensor(0.4625) tensor([5., 0.])\n",
      "tensor(2.2090) tensor(-1.1095) tensor(0.2480) tensor([2., 0.])\n",
      "tensor(2.4335) tensor(-1.1306) tensor(0.2441) tensor([3., 0.])\n",
      "tensor(1.5678) tensor(3.0503) tensor(0.9548) tensor([2., 0.])\n",
      "tensor(2.0183) tensor(0.9361) tensor(0.7183) tensor([1., 0.])\n",
      "tensor(2.0374) tensor(-1.1258) tensor(0.2449) tensor([2., 0.])\n",
      "tensor(1.7774) tensor(-0.3020) tensor(0.4251) tensor([1., 0.])\n",
      "tensor(1.5301) tensor(3.5087) tensor(0.9709) tensor([2., 0.])\n",
      "tensor(1.7404) tensor(-2.0105) tensor(0.1181) tensor([1., 0.])\n",
      "tensor(1.7484) tensor(-0.0067) tensor(0.4983) tensor([4., 0.])\n",
      "tensor(1.8303) tensor(0.0581) tensor(0.5145) tensor([2., 0.])\n",
      "tensor(1.6178) tensor(-1.0472) tensor(0.2598) tensor([1., 0.])\n",
      "tensor(1.8390) tensor(0.2342) tensor(0.5583) tensor([2., 0.])\n",
      "tensor(2.4421) tensor(0.1313) tensor(0.5328) tensor([2., 0.])\n",
      "tensor(2.2774) tensor(-1.0387) tensor(0.2614) tensor([3., 0.])\n",
      "tensor(1.5584) tensor(-0.8110) tensor(0.3077) tensor([1., 0.])\n",
      "tensor(2.4369) tensor(-1.0852) tensor(0.2525) tensor([4., 0.])\n",
      "tensor(1.9194) tensor(2.4363) tensor(0.9196) tensor([1., 0.])\n",
      "tensor(2.3809) tensor(-1.6133) tensor(0.1661) tensor([1., 0.])\n",
      "tensor(1.7506) tensor(2.2200) tensor(0.9020) tensor([1., 0.])\n",
      "tensor(1.6560) tensor(-0.8968) tensor(0.2897) tensor([1., 0.])\n",
      "tensor(2.2859) tensor(-1.9591) tensor(0.1236) tensor([2., 0.])\n",
      "tensor(2.0884) tensor(-0.9133) tensor(0.2863) tensor([1., 0.])\n",
      "tensor(1.7982) tensor(-2.3493) tensor(0.0871) tensor([2., 0.])\n",
      "tensor(1.7961) tensor(0.0422) tensor(0.5106) tensor([2., 0.])\n",
      "tensor(2.0726) tensor(-0.3244) tensor(0.4196) tensor([1., 0.])\n",
      "tensor(3.0645) tensor(-1.2033) tensor(0.2309) tensor([3., 0.])\n",
      "tensor(1.7483) tensor(-1.3163) tensor(0.2114) tensor([2., 0.])\n",
      "tensor(1.7012) tensor(-1.5552) tensor(0.1743) tensor([2., 0.])\n",
      "tensor(2.8032) tensor(-0.6597) tensor(0.3408) tensor([2., 0.])\n",
      "tensor(1.5880) tensor(-1.5163) tensor(0.1800) tensor([1., 0.])\n",
      "tensor(1.7804) tensor(-0.1598) tensor(0.4601) tensor([2., 0.])\n",
      "tensor(2.0087) tensor(-1.2460) tensor(0.2234) tensor([2., 0.])\n",
      "tensor(2.6755) tensor(-1.1026) tensor(0.2493) tensor([2., 0.])\n",
      "tensor(2.2385) tensor(-0.9956) tensor(0.2698) tensor([3., 0.])\n",
      "tensor(2.6239) tensor(-0.5999) tensor(0.3544) tensor([3., 0.])\n",
      "tensor(2.2239) tensor(-0.4921) tensor(0.3794) tensor([2., 0.])\n",
      "tensor(1.6914) tensor(-0.7562) tensor(0.3195) tensor([2., 0.])\n",
      "tensor(2.2389) tensor(-0.2033) tensor(0.4493) tensor([2., 0.])\n",
      "tensor(2.2876) tensor(-0.3011) tensor(0.4253) tensor([2., 0.])\n",
      "tensor(2.6458) tensor(-0.8075) tensor(0.3084) tensor([3., 0.])\n",
      "tensor(2.0261) tensor(-2.1100) tensor(0.1081) tensor([1., 0.])\n",
      "tensor(2.3960) tensor(-1.4434) tensor(0.1910) tensor([1., 0.])\n",
      "tensor(2.7913) tensor(-0.5922) tensor(0.3561) tensor([3., 0.])\n",
      "tensor(1.9255) tensor(-0.0684) tensor(0.4829) tensor([1., 0.])\n",
      "tensor(1.9129) tensor(-2.6330) tensor(0.0670) tensor([2., 0.])\n",
      "tensor(2.3828) tensor(-1.7797) tensor(0.1443) tensor([3., 0.])\n",
      "tensor(3.5333) tensor(-0.2731) tensor(0.4321) tensor([4., 0.])\n",
      "tensor(2.3337) tensor(-0.5575) tensor(0.3641) tensor([3., 0.])\n",
      "tensor(2.0632) tensor(-2.2325) tensor(0.0969) tensor([3., 0.])\n",
      "tensor(1.9650) tensor(-1.6241) tensor(0.1646) tensor([2., 0.])\n",
      "tensor(2.1009) tensor(-1.6977) tensor(0.1548) tensor([2., 0.])\n",
      "tensor(2.0728) tensor(-2.1772) tensor(0.1018) tensor([1., 0.])\n",
      "tensor(2.3316) tensor(-1.3432) tensor(0.2070) tensor([3., 0.])\n",
      "tensor(2.5347) tensor(-0.7509) tensor(0.3206) tensor([3., 0.])\n",
      "tensor(2.7056) tensor(-1.0910) tensor(0.2514) tensor([2., 0.])\n",
      "tensor(2.2274) tensor(-0.0462) tensor(0.4884) tensor([2., 0.])\n",
      "tensor(2.1805) tensor(-1.6579) tensor(0.1600) tensor([2., 0.])\n",
      "tensor(2.1749) tensor(-0.9471) tensor(0.2795) tensor([2., 0.])\n",
      "tensor(2.3960) tensor(-1.7647) tensor(0.1462) tensor([3., 0.])\n",
      "tensor(2.2952) tensor(-1.9332) tensor(0.1264) tensor([3., 0.])\n",
      "tensor(2.1663) tensor(-0.4452) tensor(0.3905) tensor([2., 0.])\n",
      "tensor(3.9566) tensor(-0.3917) tensor(0.4033) tensor([4., 0.])\n",
      "tensor(2.7046) tensor(-0.7224) tensor(0.3269) tensor([3., 0.])\n",
      "tensor(1.8531) tensor(-0.7617) tensor(0.3183) tensor([2., 0.])\n",
      "tensor(2.6818) tensor(-1.1680) tensor(0.2372) tensor([2., 0.])\n",
      "tensor(2.8482) tensor(-1.3612) tensor(0.2040) tensor([3., 0.])\n",
      "tensor(1.8090) tensor(1.4257) tensor(0.8062) tensor([2., 0.])\n",
      "tensor(1.6970) tensor(-1.7125) tensor(0.1528) tensor([2., 0.])\n",
      "tensor(2.5110) tensor(-1.1299) tensor(0.2442) tensor([3., 0.])\n",
      "tensor(2.5237) tensor(-0.7008) tensor(0.3316) tensor([2., 0.])\n",
      "tensor(3.5463) tensor(-0.4509) tensor(0.3892) tensor([4., 0.])\n",
      "tensor(2.1893) tensor(-0.9827) tensor(0.2724) tensor([2., 0.])\n",
      "tensor(2.5566) tensor(-1.3516) tensor(0.2056) tensor([3., 0.])\n",
      "tensor(2.1409) tensor(0.2937) tensor(0.5729) tensor([3., 0.])\n",
      "tensor(1.9868) tensor(1.1490) tensor(0.7593) tensor([1.5000, 0.0000])\n",
      "tensor(2.1070) tensor(-0.7990) tensor(0.3102) tensor([2., 0.])\n",
      "tensor(2.4449) tensor(-0.8419) tensor(0.3011) tensor([3., 0.])\n",
      "tensor(1.6645) tensor(-0.2171) tensor(0.4459) tensor([3., 0.])\n",
      "tensor(2.1248) tensor(-1.4955) tensor(0.1831) tensor([2., 0.])\n",
      "tensor(2.9154) tensor(-1.3792) tensor(0.2011) tensor([3., 0.])\n",
      "tensor(2.2157) tensor(-1.3385) tensor(0.2078) tensor([2., 0.])\n",
      "tensor(1.8379) tensor(-0.8752) tensor(0.2942) tensor([1., 0.])\n",
      "tensor(2.0966) tensor(0.0064) tensor(0.5016) tensor([2., 0.])\n",
      "tensor(1.7536) tensor(-1.4939) tensor(0.1833) tensor([1.5000, 0.0000])\n",
      "tensor(1.9172) tensor(-1.3664) tensor(0.2032) tensor([1.5000, 0.0000])\n",
      "tensor(3.0450) tensor(-1.5743) tensor(0.1716) tensor([3., 0.])\n",
      "tensor(2.4514) tensor(-0.6160) tensor(0.3507) tensor([2., 0.])\n",
      "tensor(2.1639) tensor(-0.6557) tensor(0.3417) tensor([2., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9854) tensor(-1.3714) tensor(0.2024) tensor([3., 0.])\n",
      "tensor(1.8251) tensor(-1.0172) tensor(0.2656) tensor([2., 0.])\n",
      "tensor(2.2822) tensor(-1.7469) tensor(0.1484) tensor([3., 0.])\n",
      "tensor(2.1671) tensor(-0.9968) tensor(0.2696) tensor([2., 0.])\n",
      "tensor(2.1244) tensor(-0.0216) tensor(0.4946) tensor([2., 0.])\n",
      "tensor(2.8282) tensor(-1.2852) tensor(0.2167) tensor([3., 0.])\n",
      "tensor(1.9838) tensor(-0.3485) tensor(0.4138) tensor([2., 0.])\n",
      "tensor(2.2248) tensor(-0.2442) tensor(0.4393) tensor([3., 0.])\n",
      "tensor(3.2460) tensor(-0.8022) tensor(0.3096) tensor([3., 0.])\n",
      "tensor(2.4944) tensor(-1.2331) tensor(0.2256) tensor([2., 0.])\n",
      "tensor(2.7837) tensor(-1.4499) tensor(0.1900) tensor([3., 0.])\n",
      "tensor(2.3440) tensor(-0.5902) tensor(0.3566) tensor([1.5000, 0.0000])\n",
      "tensor(2.1842) tensor(-0.1894) tensor(0.4528) tensor([3., 0.])\n",
      "tensor(2.0348) tensor(-2.4259) tensor(0.0812) tensor([2., 0.])\n",
      "tensor(1.7202) tensor(-1.4281) tensor(0.1934) tensor([1., 0.])\n",
      "tensor(2.6180) tensor(-1.1958) tensor(0.2322) tensor([3., 0.])\n",
      "tensor(2.3443) tensor(-0.9047) tensor(0.2881) tensor([3., 0.])\n",
      "tensor(1.7421) tensor(0.1123) tensor(0.5280) tensor([2., 0.])\n",
      "tensor(2.2617) tensor(-2.0299) tensor(0.1161) tensor([2., 0.])\n",
      "tensor(2.3800) tensor(-1.5822) tensor(0.1705) tensor([3., 0.])\n",
      "tensor(2.1385) tensor(-1.6937) tensor(0.1553) tensor([1., 0.])\n",
      "tensor(2.5002) tensor(-1.6471) tensor(0.1615) tensor([2., 0.])\n",
      "tensor(4.2981) tensor(0.3029) tensor(0.5751) tensor([5., 0.])\n",
      "tensor(1.9858) tensor(-0.3288) tensor(0.4185) tensor([4., 0.])\n",
      "tensor(3.7005) tensor(-0.4170) tensor(0.3972) tensor([3., 0.])\n",
      "tensor(1.3242) tensor(3.2392) tensor(0.9623) tensor([1., 0.])\n",
      "tensor(2.3474) tensor(-0.9486) tensor(0.2792) tensor([3., 0.])\n",
      "tensor(2.8895) tensor(-1.1861) tensor(0.2340) tensor([4., 0.])\n",
      "tensor(1.4178) tensor(1.1332) tensor(0.7564) tensor([1.5000, 0.0000])\n",
      "tensor(1.4522) tensor(2.6182) tensor(0.9320) tensor([2., 0.])\n",
      "tensor(2.5900) tensor(-0.8389) tensor(0.3018) tensor([1., 0.])\n",
      "tensor(3.2143) tensor(-0.7789) tensor(0.3146) tensor([4., 0.])\n",
      "tensor(2.2877) tensor(-1.0130) tensor(0.2664) tensor([3., 0.])\n",
      "tensor(2.5082) tensor(-1.1459) tensor(0.2412) tensor([3., 0.])\n",
      "tensor(2.1998) tensor(-1.9676) tensor(0.1227) tensor([2.5000, 0.0000])\n",
      "tensor(2.3404) tensor(-0.4658) tensor(0.3856) tensor([2., 0.])\n",
      "tensor(1.4121) tensor(3.3428) tensor(0.9659) tensor([1., 0.])\n",
      "tensor(1.9380) tensor(-1.1027) tensor(0.2492) tensor([2., 0.])\n",
      "tensor(1.9912) tensor(-0.8344) tensor(0.3027) tensor([1., 0.])\n",
      "tensor(3.0914) tensor(-0.7471) tensor(0.3214) tensor([3., 0.])\n",
      "tensor(3.5236) tensor(-0.7375) tensor(0.3236) tensor([4., 0.])\n",
      "tensor(2.3947) tensor(-0.8789) tensor(0.2934) tensor([3., 0.])\n",
      "tensor(1.8367) tensor(-1.9631) tensor(0.1231) tensor([3., 0.])\n",
      "tensor(2.2418) tensor(-1.9215) tensor(0.1277) tensor([3., 0.])\n",
      "tensor(2.3957) tensor(-0.7367) tensor(0.3237) tensor([3., 0.])\n",
      "tensor(2.0508) tensor(-0.5651) tensor(0.3624) tensor([2., 0.])\n",
      "tensor(2.7536) tensor(-0.9724) tensor(0.2744) tensor([3., 0.])\n",
      "tensor(1.8105) tensor(-0.2648) tensor(0.4342) tensor([1., 0.])\n",
      "tensor(3.3743) tensor(-0.9503) tensor(0.2788) tensor([5., 0.])\n",
      "tensor(2.8622) tensor(-1.2365) tensor(0.2250) tensor([4., 0.])\n",
      "tensor(2.3464) tensor(-1.2313) tensor(0.2260) tensor([3., 0.])\n",
      "tensor(2.7852) tensor(-1.0166) tensor(0.2657) tensor([3., 0.])\n",
      "tensor(2.5776) tensor(-0.7022) tensor(0.3313) tensor([3., 0.])\n",
      "tensor(3.7435) tensor(-0.3733) tensor(0.4078) tensor([3., 0.])\n",
      "tensor(2.1915) tensor(-0.6575) tensor(0.3413) tensor([2., 0.])\n",
      "tensor(2.0081) tensor(-0.9748) tensor(0.2739) tensor([3., 0.])\n",
      "tensor(1.6447) tensor(-2.6906) tensor(0.0635) tensor([1., 0.])\n",
      "tensor(2.0754) tensor(-1.1402) tensor(0.2423) tensor([2., 0.])\n",
      "tensor(1.7987) tensor(-1.1157) tensor(0.2468) tensor([2., 0.])\n",
      "tensor(1.8174) tensor(-1.0399) tensor(0.2612) tensor([3., 0.])\n",
      "tensor(2.0590) tensor(-1.5929) tensor(0.1690) tensor([2., 0.])\n",
      "tensor(2.5525) tensor(-1.0410) tensor(0.2609) tensor([2., 0.])\n",
      "tensor(2.5225) tensor(-1.1180) tensor(0.2464) tensor([2., 0.])\n",
      "tensor(1.8132) tensor(-1.4079) tensor(0.1966) tensor([1., 0.])\n",
      "tensor(1.6747) tensor(-1.8572) tensor(0.1350) tensor([1.5000, 0.0000])\n",
      "tensor(1.9438) tensor(-0.8534) tensor(0.2987) tensor([1.5000, 1.0000])\n",
      "tensor(2.2110) tensor(-0.9192) tensor(0.2851) tensor([2., 0.])\n",
      "tensor(2.2676) tensor(-1.9283) tensor(0.1269) tensor([3., 0.])\n",
      "tensor(2.9683) tensor(-1.3451) tensor(0.2067) tensor([3., 0.])\n",
      "tensor(2.1990) tensor(-1.6054) tensor(0.1672) tensor([3., 0.])\n",
      "tensor(2.9683) tensor(-1.3451) tensor(0.2067) tensor([3., 0.])\n",
      "tensor(2.6206) tensor(-1.1314) tensor(0.2439) tensor([2., 0.])\n",
      "tensor(2.5156) tensor(-1.6062) tensor(0.1671) tensor([2., 0.])\n",
      "tensor(1.8741) tensor(-0.9622) tensor(0.2764) tensor([2., 0.])\n",
      "tensor(3.3103) tensor(-0.9134) tensor(0.2863) tensor([3., 0.])\n",
      "tensor(1.3850) tensor(2.6703) tensor(0.9353) tensor([2., 0.])\n",
      "tensor(2.7738) tensor(-1.1273) tensor(0.2447) tensor([3., 0.])\n",
      "tensor(1.8162) tensor(-0.5330) tensor(0.3698) tensor([3., 0.])\n",
      "tensor(3.9314) tensor(-0.2898) tensor(0.4281) tensor([4.5000, 0.0000])\n",
      "tensor(1.9421) tensor(-2.2891) tensor(0.0920) tensor([3., 0.])\n",
      "tensor(2.0039) tensor(-0.0995) tensor(0.4752) tensor([3., 0.])\n",
      "tensor(2.3476) tensor(-1.7249) tensor(0.1512) tensor([2., 0.])\n",
      "tensor(2.3253) tensor(-1.4070) tensor(0.1967) tensor([3., 0.])\n",
      "tensor(2.2330) tensor(-0.2407) tensor(0.4401) tensor([2., 0.])\n",
      "tensor(1.9535) tensor(-2.0555) tensor(0.1135) tensor([1.5000, 0.0000])\n",
      "tensor(1.5874) tensor(-1.1883) tensor(0.2336) tensor([2., 0.])\n",
      "tensor(2.4903) tensor(-1.0409) tensor(0.2610) tensor([3., 0.])\n",
      "tensor(2.2425) tensor(-1.2477) tensor(0.2231) tensor([3., 0.])\n",
      "tensor(1.8964) tensor(-2.3799) tensor(0.0847) tensor([2., 0.])\n",
      "tensor(2.1425) tensor(-0.0690) tensor(0.4828) tensor([3., 0.])\n",
      "tensor(1.9569) tensor(-0.5723) tensor(0.3607) tensor([2., 0.])\n",
      "tensor(2.5699) tensor(-0.5858) tensor(0.3576) tensor([3., 0.])\n",
      "tensor(2.2068) tensor(-1.8202) tensor(0.1394) tensor([2., 0.])\n",
      "tensor(2.7501) tensor(-0.9434) tensor(0.2802) tensor([3., 0.])\n",
      "tensor(3.0178) tensor(-0.5009) tensor(0.3773) tensor([2., 0.])\n",
      "tensor(2.2169) tensor(-0.2475) tensor(0.4384) tensor([2., 0.])\n",
      "tensor(2.5381) tensor(-0.5373) tensor(0.3688) tensor([2., 0.])\n",
      "tensor(2.9548) tensor(-0.6499) tensor(0.3430) tensor([3., 0.])\n",
      "tensor(3.1467) tensor(-0.5233) tensor(0.3721) tensor([3., 0.])\n",
      "tensor(2.3361) tensor(-0.3730) tensor(0.4078) tensor([3., 0.])\n",
      "tensor(3.0660) tensor(-1.3906) tensor(0.1993) tensor([3., 0.])\n",
      "tensor(1.6421) tensor(0.2936) tensor(0.5729) tensor([2., 0.])\n",
      "tensor(2.3284) tensor(-0.7860) tensor(0.3130) tensor([1., 0.])\n",
      "tensor(2.3210) tensor(-1.3123) tensor(0.2121) tensor([2., 0.])\n",
      "tensor(2.5315) tensor(-1.7383) tensor(0.1495) tensor([3., 0.])\n",
      "tensor(2.1900) tensor(-1.5868) tensor(0.1698) tensor([3., 0.])\n",
      "tensor(3.4066) tensor(-0.7531) tensor(0.3201) tensor([3., 0.])\n",
      "tensor(2.1722) tensor(-0.1336) tensor(0.4666) tensor([2., 0.])\n",
      "tensor(2.0066) tensor(-1.2165) tensor(0.2286) tensor([2., 0.])\n",
      "tensor(2.4979) tensor(-1.5450) tensor(0.1758) tensor([3., 0.])\n",
      "tensor(2.1344) tensor(-0.0636) tensor(0.4841) tensor([2.5000, 0.0000])\n",
      "tensor(2.3848) tensor(-0.3481) tensor(0.4139) tensor([2., 0.])\n",
      "tensor(2.2305) tensor(-1.3608) tensor(0.2041) tensor([3., 0.])\n",
      "tensor(3.0847) tensor(-0.9819) tensor(0.2725) tensor([3., 0.])\n",
      "tensor(2.9052) tensor(-1.3211) tensor(0.2106) tensor([3., 0.])\n",
      "tensor(1.8436) tensor(1.1430) tensor(0.7582) tensor([2., 0.])\n",
      "tensor(3.6832) tensor(-0.6098) tensor(0.3521) tensor([3., 0.])\n",
      "tensor(2.0339) tensor(-1.8167) tensor(0.1398) tensor([2., 0.])\n",
      "tensor(2.1381) tensor(-1.4975) tensor(0.1828) tensor([2., 0.])\n",
      "tensor(2.1182) tensor(-0.1597) tensor(0.4602) tensor([1.5000, 0.0000])\n",
      "tensor(2.9328) tensor(-1.1984) tensor(0.2318) tensor([3., 0.])\n",
      "tensor(1.9231) tensor(0.1541) tensor(0.5384) tensor([2., 0.])\n",
      "tensor(2.1647) tensor(0.3375) tensor(0.5836) tensor([2., 0.])\n",
      "tensor(2.2140) tensor(-0.7043) tensor(0.3309) tensor([3., 0.])\n",
      "tensor(3.7177) tensor(-0.5472) tensor(0.3665) tensor([3., 0.])\n",
      "tensor(2.1058) tensor(0.6972) tensor(0.6676) tensor([2., 0.])\n",
      "tensor(1.9436) tensor(-2.2453) tensor(0.0958) tensor([3., 0.])\n",
      "tensor(2.5940) tensor(-0.9275) tensor(0.2834) tensor([2., 0.])\n",
      "tensor(2.5231) tensor(-0.7145) tensor(0.3286) tensor([2., 0.])\n",
      "tensor(4.5182) tensor(0.0053) tensor(0.5013) tensor([3., 0.])\n",
      "tensor(2.2476) tensor(-1.4469) tensor(0.1905) tensor([2., 0.])\n",
      "tensor(2.5167) tensor(-1.0501) tensor(0.2592) tensor([3., 0.])\n",
      "tensor(2.8944) tensor(-0.9194) tensor(0.2851) tensor([4., 0.])\n",
      "tensor(2.8796) tensor(-1.3776) tensor(0.2014) tensor([3., 0.])\n",
      "tensor(2.9538) tensor(-0.9602) tensor(0.2768) tensor([3., 0.])\n",
      "tensor(1.7806) tensor(-1.8718) tensor(0.1333) tensor([2., 0.])\n",
      "tensor(3.9239) tensor(-0.4282) tensor(0.3945) tensor([4., 0.])\n",
      "tensor(2.9963) tensor(-0.9972) tensor(0.2695) tensor([3., 0.])\n",
      "tensor(2.6605) tensor(-0.5848) tensor(0.3578) tensor([3., 0.])\n",
      "tensor(3.2228) tensor(-0.4958) tensor(0.3785) tensor([4., 0.])\n",
      "tensor(1.8850) tensor(-1.7425) tensor(0.1490) tensor([1., 0.])\n",
      "tensor(1.9559) tensor(-1.5550) tensor(0.1744) tensor([1.5000, 0.0000])\n",
      "tensor(2.3174) tensor(-1.4857) tensor(0.1846) tensor([2., 0.])\n",
      "tensor(2.2396) tensor(-0.4648) tensor(0.3858) tensor([3., 0.])\n",
      "tensor(2.5947) tensor(-0.2458) tensor(0.4389) tensor([2., 0.])\n",
      "tensor(2.3980) tensor(-0.6790) tensor(0.3365) tensor([3., 0.])\n",
      "tensor(2.1391) tensor(-0.6535) tensor(0.3422) tensor([2., 0.])\n",
      "tensor(1.8122) tensor(-1.6325) tensor(0.1635) tensor([1., 0.])\n",
      "tensor(2.7999) tensor(-0.9734) tensor(0.2742) tensor([3., 0.])\n",
      "tensor(1.8077) tensor(-0.7158) tensor(0.3283) tensor([3., 0.])\n",
      "tensor(4.3271) tensor(0.3900) tensor(0.5963) tensor([4.5000, 0.0000])\n",
      "tensor(1.6515) tensor(-1.5855) tensor(0.1700) tensor([2., 0.])\n",
      "tensor(2.2682) tensor(-1.5001) tensor(0.1824) tensor([3., 0.])\n",
      "tensor(2.0306) tensor(-2.3839) tensor(0.0844) tensor([2., 0.])\n",
      "tensor(2.3749) tensor(-1.2507) tensor(0.2226) tensor([3., 0.])\n",
      "tensor(3.3456) tensor(-1.0125) tensor(0.2665) tensor([3., 0.])\n",
      "tensor(2.2671) tensor(-1.2583) tensor(0.2213) tensor([2., 0.])\n",
      "tensor(2.4361) tensor(-1.3169) tensor(0.2113) tensor([4., 0.])\n",
      "tensor(4.5192) tensor(-0.0315) tensor(0.4921) tensor([4., 0.])\n",
      "tensor(2.5463) tensor(-0.7289) tensor(0.3254) tensor([2., 0.])\n",
      "tensor(2.5002) tensor(-0.0661) tensor(0.4835) tensor([2., 0.])\n",
      "tensor(2.6236) tensor(-1.1650) tensor(0.2378) tensor([3., 0.])\n",
      "tensor(1.5048) tensor(0.9143) tensor(0.7139) tensor([1., 0.])\n",
      "tensor(2.6175) tensor(-0.4553) tensor(0.3881) tensor([2., 0.])\n",
      "tensor(3.4746) tensor(-0.7690) tensor(0.3167) tensor([3., 0.])\n",
      "tensor(2.4759) tensor(-0.9638) tensor(0.2761) tensor([3., 0.])\n",
      "tensor(3.6453) tensor(-0.6755) tensor(0.3373) tensor([3., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2656) tensor(-0.9109) tensor(0.2868) tensor([3., 0.])\n",
      "tensor(3.9581) tensor(-0.2424) tensor(0.4397) tensor([5., 0.])\n",
      "tensor(2.0720) tensor(-1.7484) tensor(0.1483) tensor([2., 0.])\n",
      "tensor(1.6853) tensor(-1.3024) tensor(0.2138) tensor([3., 1.])\n",
      "tensor(2.1772) tensor(-1.8125) tensor(0.1403) tensor([2., 0.])\n",
      "tensor(2.4720) tensor(-0.2905) tensor(0.4279) tensor([1.5000, 0.0000])\n",
      "tensor(2.6893) tensor(-0.8420) tensor(0.3011) tensor([2., 0.])\n",
      "tensor(2.9753) tensor(-1.0998) tensor(0.2498) tensor([3., 0.])\n",
      "tensor(2.1299) tensor(-1.7380) tensor(0.1496) tensor([2., 0.])\n",
      "tensor(2.0650) tensor(-1.0885) tensor(0.2519) tensor([3., 0.])\n",
      "tensor(3.8152) tensor(-0.7831) tensor(0.3137) tensor([5., 1.])\n",
      "tensor(2.1983) tensor(-0.6109) tensor(0.3519) tensor([1., 0.])\n",
      "tensor(2.5086) tensor(-1.3473) tensor(0.2063) tensor([2., 0.])\n",
      "tensor(1.4399) tensor(-0.6985) tensor(0.3322) tensor([2., 0.])\n",
      "tensor(4.5472) tensor(0.5534) tensor(0.6349) tensor([5., 0.])\n",
      "tensor(3.5465) tensor(-0.9350) tensor(0.2819) tensor([5., 0.])\n",
      "tensor(2.9697) tensor(-1.1657) tensor(0.2376) tensor([1., 0.])\n",
      "tensor(3.0014) tensor(-0.9965) tensor(0.2696) tensor([3., 0.])\n",
      "tensor(1.9018) tensor(-1.9735) tensor(0.1220) tensor([1., 0.])\n",
      "tensor(2.2107) tensor(-0.5627) tensor(0.3629) tensor([2., 0.])\n",
      "tensor(2.5145) tensor(-0.8439) tensor(0.3007) tensor([1.5000, 0.0000])\n",
      "tensor(3.2078) tensor(-0.9274) tensor(0.2835) tensor([3., 0.])\n",
      "tensor(2.0054) tensor(0.4323) tensor(0.6064) tensor([2., 0.])\n",
      "tensor(2.0929) tensor(-1.0358) tensor(0.2620) tensor([2., 0.])\n",
      "tensor(2.1807) tensor(-1.6564) tensor(0.1603) tensor([3., 0.])\n",
      "tensor(4.5998) tensor(0.4368) tensor(0.6075) tensor([5., 0.])\n",
      "tensor(2.9029) tensor(-1.4745) tensor(0.1863) tensor([3., 0.])\n",
      "tensor(3.2770) tensor(-1.1631) tensor(0.2381) tensor([2., 0.])\n",
      "tensor(2.9433) tensor(-1.0390) tensor(0.2614) tensor([4.5000, 0.0000])\n",
      "tensor(2.2854) tensor(-0.5570) tensor(0.3642) tensor([3., 0.])\n",
      "tensor(2.3897) tensor(-1.1538) tensor(0.2398) tensor([3., 0.])\n",
      "tensor(2.0603) tensor(-1.9006) tensor(0.1300) tensor([3., 0.])\n",
      "tensor(1.9451) tensor(0.5705) tensor(0.6389) tensor([2., 0.])\n",
      "tensor(2.8729) tensor(-1.1330) tensor(0.2436) tensor([4., 0.])\n",
      "tensor(2.9968) tensor(-1.2610) tensor(0.2208) tensor([3., 0.])\n",
      "tensor(1.9754) tensor(0.9603) tensor(0.7232) tensor([2., 0.])\n",
      "tensor(2.0837) tensor(-0.5478) tensor(0.3664) tensor([1., 0.])\n",
      "tensor(1.8443) tensor(0.7137) tensor(0.6712) tensor([1., 0.])\n",
      "tensor(2.6067) tensor(-0.9680) tensor(0.2753) tensor([2.5000, 0.0000])\n",
      "tensor(2.8940) tensor(-1.0678) tensor(0.2558) tensor([3., 0.])\n",
      "tensor(2.3141) tensor(-0.2108) tensor(0.4475) tensor([2., 0.])\n",
      "tensor(2.9793) tensor(-0.9262) tensor(0.2837) tensor([3., 0.])\n",
      "tensor(3.3292) tensor(-0.9254) tensor(0.2839) tensor([4., 0.])\n",
      "tensor(4.1468) tensor(-0.3452) tensor(0.4145) tensor([2., 0.])\n",
      "tensor(1.6427) tensor(-0.3559) tensor(0.4119) tensor([2., 0.])\n",
      "tensor(2.5577) tensor(-0.9126) tensor(0.2865) tensor([3., 0.])\n",
      "tensor(2.0128) tensor(-0.4819) tensor(0.3818) tensor([2., 0.])\n",
      "tensor(3.4578) tensor(-0.6566) tensor(0.3415) tensor([3., 0.])\n",
      "tensor(2.1214) tensor(-1.1712) tensor(0.2366) tensor([2., 0.])\n",
      "tensor(2.1384) tensor(-0.0421) tensor(0.4895) tensor([3., 0.])\n",
      "tensor(2.9307) tensor(-1.0450) tensor(0.2602) tensor([3., 0.])\n",
      "tensor(1.9183) tensor(-0.6714) tensor(0.3382) tensor([2., 0.])\n",
      "tensor(2.7680) tensor(-0.8797) tensor(0.2932) tensor([2., 0.])\n",
      "tensor(2.1550) tensor(-1.2345) tensor(0.2254) tensor([2., 0.])\n",
      "tensor(3.1529) tensor(-1.1869) tensor(0.2338) tensor([3., 0.])\n",
      "tensor(2.3392) tensor(-1.0360) tensor(0.2619) tensor([3., 0.])\n",
      "tensor(2.6572) tensor(-1.2721) tensor(0.2189) tensor([2., 0.])\n",
      "tensor(2.0940) tensor(-1.1035) tensor(0.2491) tensor([2., 0.])\n",
      "tensor(2.8101) tensor(-0.9089) tensor(0.2872) tensor([1., 0.])\n",
      "tensor(1.7421) tensor(0.4470) tensor(0.6099) tensor([2., 0.])\n",
      "tensor(4.3257) tensor(-0.3865) tensor(0.4046) tensor([5., 0.])\n",
      "tensor(2.0365) tensor(-1.6052) tensor(0.1673) tensor([2., 0.])\n",
      "tensor(3.7851) tensor(-0.1877) tensor(0.4532) tensor([5., 0.])\n",
      "tensor(2.9454) tensor(-0.9069) tensor(0.2876) tensor([3.5000, 0.0000])\n",
      "tensor(2.1134) tensor(0.7461) tensor(0.6783) tensor([2., 0.])\n",
      "tensor(3.3588) tensor(-0.6608) tensor(0.3406) tensor([2., 0.])\n",
      "tensor(2.5756) tensor(-0.9482) tensor(0.2792) tensor([3., 0.])\n",
      "tensor(1.9390) tensor(-1.5794) tensor(0.1709) tensor([2., 0.])\n",
      "tensor(2.3331) tensor(-1.2867) tensor(0.2164) tensor([2., 0.])\n",
      "tensor(4.3751) tensor(0.2474) tensor(0.5615) tensor([4.5000, 0.0000])\n",
      "tensor(1.8420) tensor(-1.4390) tensor(0.1917) tensor([2., 0.])\n",
      "tensor(2.7882) tensor(-0.8286) tensor(0.3039) tensor([4., 0.])\n",
      "tensor(2.1057) tensor(-1.4844) tensor(0.1848) tensor([2., 0.])\n",
      "tensor(1.9707) tensor(-1.8745) tensor(0.1330) tensor([2., 0.])\n",
      "tensor(1.9495) tensor(-1.1068) tensor(0.2485) tensor([2., 0.])\n",
      "tensor(4.4202) tensor(0.0315) tensor(0.5079) tensor([5., 0.])\n",
      "tensor(4.0791) tensor(-0.2952) tensor(0.4267) tensor([3., 0.])\n",
      "tensor(2.4203) tensor(-1.2784) tensor(0.2178) tensor([3., 0.])\n",
      "tensor(2.4129) tensor(-0.4992) tensor(0.3777) tensor([2., 0.])\n",
      "tensor(3.0418) tensor(-1.5063) tensor(0.1815) tensor([3., 0.])\n",
      "tensor(1.5413) tensor(1.4688) tensor(0.8129) tensor([2., 0.])\n",
      "tensor(1.6359) tensor(-1.4085) tensor(0.1965) tensor([1., 0.])\n",
      "tensor(2.7536) tensor(-1.0879) tensor(0.2520) tensor([4., 0.])\n",
      "tensor(2.3084) tensor(-1.0613) tensor(0.2571) tensor([1., 0.])\n",
      "tensor(2.5620) tensor(-0.6473) tensor(0.3436) tensor([4., 0.])\n",
      "tensor(2.5553) tensor(-1.2078) tensor(0.2301) tensor([3., 0.])\n",
      "tensor(3.2864) tensor(-0.5511) tensor(0.3656) tensor([2., 0.])\n",
      "tensor(3.0373) tensor(-0.9705) tensor(0.2748) tensor([2., 0.])\n",
      "tensor(2.2033) tensor(-1.3929) tensor(0.1989) tensor([2., 0.])\n",
      "tensor(4.2077) tensor(-0.3833) tensor(0.4053) tensor([3., 0.])\n",
      "tensor(2.2538) tensor(-0.8573) tensor(0.2979) tensor([2., 0.])\n",
      "tensor(2.1487) tensor(0.0412) tensor(0.5103) tensor([2., 0.])\n",
      "tensor(2.1807) tensor(-0.1201) tensor(0.4700) tensor([3., 0.])\n",
      "tensor(2.4515) tensor(-1.4569) tensor(0.1889) tensor([2., 0.])\n",
      "tensor(1.8541) tensor(-1.3549) tensor(0.2051) tensor([3., 0.])\n",
      "tensor(2.7883) tensor(-0.0674) tensor(0.4831) tensor([2., 0.])\n",
      "tensor(4.1719) tensor(-0.2791) tensor(0.4307) tensor([4., 0.])\n",
      "tensor(4.4334) tensor(0.2356) tensor(0.5586) tensor([4., 0.])\n",
      "tensor(1.9677) tensor(-0.1372) tensor(0.4658) tensor([2., 0.])\n",
      "tensor(3.9860) tensor(-0.1913) tensor(0.4523) tensor([4., 0.])\n",
      "tensor(3.9469) tensor(-0.3258) tensor(0.4193) tensor([5., 0.])\n",
      "tensor(2.1026) tensor(-0.3252) tensor(0.4194) tensor([2., 0.])\n",
      "tensor(2.3877) tensor(-0.3535) tensor(0.4125) tensor([3., 0.])\n",
      "tensor(3.3025) tensor(-1.2417) tensor(0.2241) tensor([3., 0.])\n",
      "tensor(2.2722) tensor(-1.0817) tensor(0.2532) tensor([3., 0.])\n",
      "tensor(3.8359) tensor(-0.6474) tensor(0.3436) tensor([3., 0.])\n",
      "tensor(3.2200) tensor(-1.3358) tensor(0.2082) tensor([3., 0.])\n",
      "tensor(3.7119) tensor(-0.2375) tensor(0.4409) tensor([4., 0.])\n",
      "tensor(3.0133) tensor(-1.0185) tensor(0.2653) tensor([3., 0.])\n",
      "tensor(3.0387) tensor(-1.1884) tensor(0.2335) tensor([3., 0.])\n",
      "tensor(2.0564) tensor(-1.6898) tensor(0.1558) tensor([2., 0.])\n",
      "tensor(2.1149) tensor(0.4543) tensor(0.6117) tensor([2., 0.])\n",
      "tensor(2.3168) tensor(-0.6049) tensor(0.3532) tensor([3., 0.])\n",
      "tensor(4.2830) tensor(-0.4735) tensor(0.3838) tensor([5., 0.])\n",
      "tensor(2.0344) tensor(-1.7004) tensor(0.1544) tensor([2., 0.])\n",
      "tensor(2.5454) tensor(-1.0529) tensor(0.2587) tensor([2., 0.])\n",
      "tensor(3.6408) tensor(-0.5867) tensor(0.3574) tensor([3., 0.])\n",
      "tensor(3.3330) tensor(-0.4768) tensor(0.3830) tensor([5., 0.])\n",
      "tensor(1.5402) tensor(-0.8605) tensor(0.2972) tensor([2., 0.])\n",
      "tensor(2.0907) tensor(-1.0831) tensor(0.2529) tensor([1., 0.])\n",
      "tensor(3.2302) tensor(-1.2422) tensor(0.2240) tensor([3., 0.])\n",
      "tensor(2.1941) tensor(-1.0283) tensor(0.2634) tensor([3., 0.])\n",
      "tensor(2.2356) tensor(-1.2804) tensor(0.2175) tensor([2., 0.])\n",
      "tensor(2.8962) tensor(-0.9746) tensor(0.2740) tensor([5., 0.])\n",
      "tensor(2.1826) tensor(-0.6246) tensor(0.3487) tensor([2., 0.])\n",
      "tensor(2.1744) tensor(-0.7200) tensor(0.3274) tensor([2., 0.])\n",
      "tensor(3.9629) tensor(0.0699) tensor(0.5175) tensor([4., 0.])\n",
      "tensor(2.3406) tensor(-1.1719) tensor(0.2365) tensor([2., 0.])\n",
      "tensor(2.3458) tensor(-1.4030) tensor(0.1973) tensor([2., 0.])\n",
      "tensor(2.2064) tensor(-0.1776) tensor(0.4557) tensor([2., 0.])\n",
      "tensor(2.6620) tensor(-1.0088) tensor(0.2672) tensor([2., 0.])\n",
      "tensor(3.1251) tensor(-0.8075) tensor(0.3084) tensor([2., 0.])\n",
      "tensor(2.8112) tensor(-0.9312) tensor(0.2827) tensor([3., 0.])\n",
      "tensor(1.3020) tensor(0.0509) tensor(0.5127) tensor([2., 0.])\n",
      "tensor(2.4248) tensor(-1.1868) tensor(0.2338) tensor([2., 0.])\n",
      "tensor(1.9136) tensor(-0.5237) tensor(0.3720) tensor([2., 0.])\n",
      "tensor(2.3665) tensor(-0.0372) tensor(0.4907) tensor([2., 0.])\n",
      "tensor(2.3461) tensor(-0.8759) tensor(0.2940) tensor([3., 0.])\n",
      "tensor(2.5667) tensor(-0.9599) tensor(0.2769) tensor([2., 0.])\n",
      "tensor(2.4956) tensor(-1.1406) tensor(0.2422) tensor([2., 0.])\n",
      "tensor(4.3701) tensor(-0.0992) tensor(0.4752) tensor([5., 0.])\n",
      "tensor(2.4612) tensor(-0.8677) tensor(0.2957) tensor([2., 0.])\n",
      "tensor(4.4653) tensor(-0.0371) tensor(0.4907) tensor([4., 0.])\n",
      "tensor(2.3797) tensor(-0.9152) tensor(0.2859) tensor([2., 0.])\n",
      "tensor(3.5847) tensor(-0.5235) tensor(0.3720) tensor([4., 0.])\n",
      "tensor(2.0822) tensor(-1.5677) tensor(0.1725) tensor([3., 0.])\n",
      "tensor(1.9556) tensor(-0.2637) tensor(0.4345) tensor([2., 0.])\n",
      "tensor(2.1283) tensor(-1.7088) tensor(0.1533) tensor([2., 0.])\n",
      "tensor(2.5837) tensor(-0.7951) tensor(0.3111) tensor([2.5000, 0.0000])\n",
      "tensor(2.1042) tensor(-1.0128) tensor(0.2664) tensor([1., 0.])\n",
      "tensor(2.3047) tensor(-0.0943) tensor(0.4764) tensor([2., 0.])\n",
      "tensor(3.8820) tensor(-0.7143) tensor(0.3286) tensor([3., 0.])\n",
      "tensor(1.9647) tensor(-1.1171) tensor(0.2465) tensor([2., 0.])\n",
      "tensor(1.8657) tensor(-0.3788) tensor(0.4064) tensor([1., 0.])\n",
      "tensor(3.6417) tensor(-0.6520) tensor(0.3425) tensor([3., 0.])\n",
      "tensor(4.2833) tensor(-0.4662) tensor(0.3855) tensor([5., 0.])\n",
      "tensor(2.1257) tensor(-0.8304) tensor(0.3036) tensor([3., 0.])\n",
      "tensor(3.7665) tensor(-0.6057) tensor(0.3530) tensor([3., 0.])\n",
      "tensor(1.9948) tensor(0.1027) tensor(0.5256) tensor([3., 0.])\n",
      "tensor(2.9850) tensor(-1.3030) tensor(0.2137) tensor([3., 0.])\n",
      "tensor(3.0087) tensor(-0.9278) tensor(0.2834) tensor([3., 0.])\n",
      "tensor(4.0185) tensor(-0.3233) tensor(0.4199) tensor([4.5000, 0.0000])\n",
      "tensor(2.7046) tensor(-0.9776) tensor(0.2734) tensor([2., 0.])\n",
      "tensor(3.0692) tensor(-0.7957) tensor(0.3110) tensor([3., 0.])\n",
      "tensor(2.1494) tensor(-0.4458) tensor(0.3904) tensor([2., 0.])\n",
      "tensor(4.6878) tensor(-0.0651) tensor(0.4837) tensor([4., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8020) tensor(0.6058) tensor(0.6470) tensor([2., 0.])\n",
      "tensor(3.8599) tensor(-0.6061) tensor(0.3529) tensor([4., 0.])\n",
      "tensor(3.6116) tensor(-0.8003) tensor(0.3100) tensor([3., 0.])\n",
      "tensor(1.4829) tensor(-1.0050) tensor(0.2680) tensor([2., 0.])\n",
      "tensor(1.8048) tensor(-1.8067) tensor(0.1410) tensor([2., 0.])\n",
      "tensor(1.4996) tensor(-1.8299) tensor(0.1383) tensor([2., 0.])\n",
      "tensor(1.7925) tensor(0.6940) tensor(0.6668) tensor([2., 0.])\n",
      "tensor(1.5287) tensor(0.3943) tensor(0.5973) tensor([1., 0.])\n",
      "tensor(2.8418) tensor(-0.9546) tensor(0.2780) tensor([2., 0.])\n",
      "tensor(1.8570) tensor(-0.5437) tensor(0.3673) tensor([2., 0.])\n",
      "tensor(2.3657) tensor(-0.8524) tensor(0.2989) tensor([3., 0.])\n",
      "tensor(2.6582) tensor(-1.1833) tensor(0.2345) tensor([2., 0.])\n",
      "tensor(2.1500) tensor(0.2335) tensor(0.5581) tensor([2., 0.])\n",
      "tensor(1.6417) tensor(0.4017) tensor(0.5991) tensor([2., 0.])\n",
      "tensor(2.5278) tensor(-0.6239) tensor(0.3489) tensor([3., 0.])\n",
      "tensor(4.1644) tensor(0.0567) tensor(0.5142) tensor([5., 0.])\n",
      "tensor(1.6152) tensor(-1.2081) tensor(0.2300) tensor([1., 0.])\n",
      "tensor(1.6689) tensor(-1.5418) tensor(0.1763) tensor([2., 0.])\n",
      "tensor(2.5679) tensor(-0.7710) tensor(0.3163) tensor([3., 0.])\n",
      "tensor(1.7389) tensor(0.1790) tensor(0.5446) tensor([2., 0.])\n",
      "tensor(2.3184) tensor(-0.5040) tensor(0.3766) tensor([2., 0.])\n",
      "tensor(4.7078) tensor(0.1332) tensor(0.5332) tensor([5., 0.])\n",
      "tensor(2.1166) tensor(-1.4226) tensor(0.1943) tensor([2., 0.])\n",
      "tensor(2.2593) tensor(-0.9965) tensor(0.2696) tensor([3., 0.])\n",
      "tensor(2.2361) tensor(-0.2083) tensor(0.4481) tensor([2., 0.])\n",
      "tensor(2.9026) tensor(-0.8745) tensor(0.2943) tensor([2., 0.])\n",
      "tensor(1.7494) tensor(-1.2948) tensor(0.2150) tensor([2., 0.])\n",
      "tensor(2.2097) tensor(-0.6843) tensor(0.3353) tensor([3., 0.])\n",
      "tensor(2.0530) tensor(-0.9084) tensor(0.2873) tensor([2., 0.])\n",
      "tensor(2.3648) tensor(-0.4308) tensor(0.3939) tensor([3., 0.])\n",
      "tensor(2.0644) tensor(-0.7079) tensor(0.3301) tensor([2., 0.])\n",
      "tensor(2.0451) tensor(0.5664) tensor(0.6379) tensor([3., 0.])\n"
     ]
    }
   ],
   "source": [
    "for p, t in zip(probs,targs):\n",
    "    print(p[0], p[1], torch.sigmoid(p[1]), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avg_sentiment', 'is_example']\n"
     ]
    }
   ],
   "source": [
    "print(STANDARD_THEME_META_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FloatItem [ 3.912143 -0.595983],\n",
       " tensor([ 3.9121, -0.5960]),\n",
       " tensor([ 3.9121, -0.5960]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"plenty of parking available. found a spot every day I came to work. availability is solid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models, csvs, to zip and download (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zip -r models.zip {LM_PATH}/models/ {CLS_PATH}/models  -x {LM_PATH}/models/lstm_wt103/\\*\n",
    "\n",
    "# FileLink('models.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zip verbatims-csvs.zip {PATH}/verbatims.csv {PATH}/verbatims-entities.csv {PATH}/verbatims-meta.csv\n",
    "\n",
    "# FileLink('verbatims-csvs.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict sentiment for our validation dataset, including the actual document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([514, 2]), torch.Size([514, 2]), tensor(0.5716))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions for a single model using the learner's model and data loaders\n",
    "learn.load(f'{m_pre}cls_bestmodel{m_suf}')\n",
    "learn.model.cuda(1)\n",
    "probs, targs, loss = learn.get_preds(DatasetType.Valid, with_loss=True)\n",
    "\n",
    "probs[:,1] = torch.sigmoid(probs[:,1])\n",
    "\n",
    "probs.shape, targs.shape, loss / len(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "??metrics_util.best_fthresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(514, 2)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clas.valid_ds.y.items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7599999904632568, 0.7599999904632568, 0.6100000143051147)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "is_example_threshold_f05 = metrics_util.best_fthresh(\n",
    "    probs[:,1], targs[:,1], beta=0.5, start=0.5, end=.9, average='binary').item()\n",
    "is_example_threshold_f1 = metrics_util.best_fthresh(\n",
    "    probs[:,1], targs[:,1], beta=1, start=0.5, end=.9, average='binary').item()\n",
    "is_example_threshold_f2 = metrics_util.best_fthresh(\n",
    "    probs[:,1], targs[:,1], beta=2, start=0.5, end=.9, average='binary').item()\n",
    "\n",
    "is_example_threshold_f05, is_example_threshold_f1, is_example_threshold_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = metrics.fbeta_score(targs[:,1], (probs[:,1] > is_example_threshold_f1), beta=1, average='binary')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688715934753418"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = ((probs[:,1] > is_example_threshold_f1).byte() == targs[:,1].byte()).float().mean()\n",
    "preds.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9688715934753418, 0.9688715934753418, 0.9357976913452148)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine accuracy based on optimal threshold\n",
    "is_example_val_acc_f05 = accuracy_thresh(probs[:,1], targs[:,1], is_example_threshold_f05, sigmoid=False).item()\n",
    "is_example_val_acc_f1 = accuracy_thresh(probs[:,1], targs[:,1], is_example_threshold_f1, sigmoid=False).item()\n",
    "is_example_val_acc_f2 = accuracy_thresh(probs[:,1], targs[:,1], is_example_threshold_f2, sigmoid=False).item()\n",
    "\n",
    "is_example_val_acc_f05, is_example_val_acc_f1, is_example_val_acc_f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review classifier - Is Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "print (sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([514, 2]), torch.Size([514, 2]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_targs = targs[:,1]\n",
    "eval_probs = probs[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Accuracy\n",
    "\n",
    "The percentage of correct predictions.  Answers the question, *\"Overall, how often is the classifier correct?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9688715953307393\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(eval_targs, (eval_probs > is_example_threshold_f1).float()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null Accuracy\n",
    " \n",
    "The accuracy achieved by always predicting the most frequent class.  Answers the question, *\"What would the accuracy be by always predicting the most frequent case?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 508\n"
     ]
    }
   ],
   "source": [
    "u_classes, u_counts = np.unique(eval_targs, return_counts=True)\n",
    "most_freq_class, most_freq_class_count = u_classes[np.argmax(u_counts)], np.max(u_counts)\n",
    "print(most_freq_class, most_freq_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9883268482490273"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq_class_count / len(eval_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohen's kappa\n",
    "\n",
    "This measure is intended to compare labelings by different human annotators (not a classifier vs. ground truth)\n",
    "\n",
    "Kappa socres are between -1 and 1 ( >= .8 is generally considered good agreement; <= 0 means no agreement ... e.g., practically random labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18670886075949367\n"
     ]
    }
   ],
   "source": [
    "print(metrics.cohen_kappa_score(eval_targs, (eval_probs > is_example_threshold_f1).float()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "Describes the performance of a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, \n",
    "                          title='Confusion matrix', cmap=plt.cm.Blues, print_info=False):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        if (print_info): print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        if (print_info): print('Confusion matrix, without normalization')\n",
    "\n",
    "    if (print_info): print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(eval_targs, (eval_probs > is_example_threshold_f1).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_confusion_matrix(cm, classes=u_classes,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_confusion_matrix(cm, classes=u_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       508\n",
      "           1       0.14      0.33      0.20         6\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       514\n",
      "   macro avg       0.57      0.65      0.59       514\n",
      "weighted avg       0.98      0.97      0.97       514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(eval_targs, (eval_probs > is_example_threshold_f1).float(), [0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw probability distribution\n",
    "\n",
    "Useful to see how the threshold can be adjusted to increase sensitivity or specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(eval_probs, bins=10)\n",
    "# plt.xlim(0,1)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability of IsVeryPositive')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrates how you can **decrease** the threshold for predicting label in order to **increase the sensitivity** of the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curves and Area Under the Curve (AUC)\n",
    "\n",
    "***ROC Curve*** answers the question, *\"How would sensitivity and specificity be affected by various thresholds without changing the threshold?\"*  It is a way **to visualize the performance of a binary classifier.**\n",
    "\n",
    "The ROC curve can help you **choose a threshold** that balances sensitivity and specificity based on your particular business case.\n",
    "\n",
    "ROC curves visualize all possible classification thresholds whereas misclassification rate only represents your error rate for a single threshold.\n",
    "\n",
    "A classifier that does a good job at separating the classes will have a ROC curve that hugs the upper left corner of the plot.  Converseley, a classifier the does a poor job separating the classes will have a ROC curve that is close to the diagonal line (0,0 -> 1,1).  That diagonal line represents a classifier that does no better than random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(eval_targs, eval_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.xlim = ([0.0, 1.0])\n",
    "plt.ylim = ([0.0, 1.0])\n",
    "plt.title('ROC curve for all labels')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity/Recall)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***AUC*** = the percentage of the ROC plot that is underneath the curve.  \n",
    "\n",
    "AUC summarizes the performance of a classifier in a **single number**.  It says, *\"If you randomly chose one positive and one negative observation, what is the likelihood that your classifier will assign a higher predicted probability to the positive observation.\"*\n",
    "\n",
    "**An AUC of ~ 0.8 is very good while an AUC of ~ 0.5 represents a poor classifier.**\n",
    "\n",
    "The ROC curve and AUC are insensitive to whether your predicted probabilities are properly calibrated to actually represent probabilities of class membership (e.g., it works if predicted probs range from 0.9 to 1 instead of 0 to 1).  All the AUC metric cares about is how well your classifier separated the two classes\n",
    "\n",
    "Notes:\n",
    "1.  AUC is useful even when there is **high class imbalance** (unlike classification accuracy)\n",
    "2.  AUC is useful even when predicted probabilities are not properly calibrated (e.g., not between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7112860892388452\n"
     ]
    }
   ],
   "source": [
    "print(metrics.roc_auc_score(eval_targs, eval_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review classifier - Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46159816"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mse\n",
    "metrics.mean_squared_error(targs[:,0], probs[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6794101543859132"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rmse\n",
    "math.sqrt(metrics.mean_squared_error(targs[:,0], probs[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5226906"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mae\n",
    "metrics.mean_absolute_error(targs[:,0], probs[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble forwards and backwards passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    learn_fwd.purge(); learn_fwd = None;\n",
    "    learn_bwd.purge(); learn_bwd = None;\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "except: pass\n",
    "\n",
    "\n",
    "bsz = 80\n",
    "m_suf = '_multitask'\n",
    "\n",
    "learn_fwd = load_learner(STANDARD_THEME_META_PATH, file=f'fwd_export_clas{m_suf}.pkl')\n",
    "data_fwd = load_data(STANDARD_THEME_META_PATH, f'data_cls_standard_theme_meta.pkl', bs=bsz)\n",
    "learn_fwd.data = data_fwd\n",
    "\n",
    "learn_bwd = load_learner(STANDARD_THEME_META_PATH, file=f'bwd_export_clas{m_suf}.pkl')\n",
    "data_bwd = load_data(STANDARD_THEME_META_PATH, f'data_cls_standard_theme_meta.pkl', bs=bsz, backwards=True)\n",
    "learn_bwd.data = data_bwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([514, 2]), torch.Size([514, 2]), torch.Size([]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_fwd, lbl_fwd, loss_fwd = learn_fwd.get_preds(ordered=False, with_loss=True)\n",
    "probs_bwd, lbl_bwd, loss_bwd = learn_bwd.get_preds(ordered=False, with_loss=True)\n",
    "\n",
    "probs_fwd[:,1] = torch.sigmoid(probs_fwd[:,1])\n",
    "probs_bwd[:,1] = torch.sigmoid(probs_bwd[:,1])\n",
    "\n",
    "probs_fwd.shape, probs_bwd.shape, loss_fwd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5457), tensor(0.5716), tensor(0.5586))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fwd/len(probs_fwd), loss_bwd/len(probs_fwd), (loss_fwd/len(probs_fwd) + loss_bwd/len(probs_fwd)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_final = (probs_fwd + probs_bwd) / 2\n",
    "# probs_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fowards Only\n",
      "-------------\n",
      "f05:\tOptimal threshold = 0.7900000214576721\t(Accuracy = 0.9649805426597595)\n",
      "f1:\tOptimal threshold = 0.7900000214576721\t\t(Accuracy = 0.9649805426597595)\n",
      "f2:\tOptimal threshold = 0.7900000214576721\t(Accuracy = 0.9649805426597595)\n",
      "\n",
      "Accuracy: 0.8754863739013672\n"
     ]
    }
   ],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "is_example_threshold_f05 = metrics_util.best_fthresh(\n",
    "    probs_fwd[:,1], lbl_fwd[:,1], beta=0.5, start=0.5, end=.9, average='binary').item()\n",
    "is_example_threshold_f1 = metrics_util.best_fthresh(\n",
    "    probs_fwd[:,1], lbl_fwd[:,1], beta=1, start=0.5, end=.9, average='binary').item()\n",
    "is_example_threshold_f2 = metrics_util.best_fthresh(\n",
    "    probs_fwd[:,1], lbl_fwd[:,1], beta=2, start=0.5, end=.9, average='binary').item()\n",
    "\n",
    "is_example_threshold_f05, is_example_threshold_f1, is_example_threshold_f2\n",
    "\n",
    "# determine accuracy based on optimal threshold\n",
    "is_example_val_acc_f05 = accuracy_thresh(probs_fwd[:,1], lbl_fwd[:,1], is_example_threshold_f05, sigmoid=False).item()\n",
    "is_example_val_acc_f1 = accuracy_thresh(probs_fwd[:,1], lbl_fwd[:,1], is_example_threshold_f1, sigmoid=False).item()\n",
    "is_example_val_acc_f2 = accuracy_thresh(probs_fwd[:,1], lbl_fwd[:,1], is_example_threshold_f2, sigmoid=False).item()\n",
    "\n",
    "is_example_val_acc_f05, is_example_val_acc_f1, is_example_val_acc_f2\n",
    "\n",
    "print('Fowards Only\\n-------------')\n",
    "print(f'f05:\\tOptimal threshold = {is_example_threshold_f05}\\t(Accuracy = {is_example_val_acc_f05})')\n",
    "print(f'f1:\\tOptimal threshold = {is_example_threshold_f1}\\t\\t(Accuracy = {is_example_val_acc_f1})')\n",
    "print(f'f2:\\tOptimal threshold = {is_example_threshold_f2}\\t(Accuracy = {is_example_val_acc_f2})')\n",
    "\n",
    "print(f'\\nAccuracy: {accuracy_thresh(probs_fwd[:,1], lbl_fwd[:,1], sigmoid=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backwards Only\n",
      "-------------\n",
      "f05:\tOptimal threshold = 0.7599999904632568\t(Accuracy = 0.9688715934753418)\n",
      "f1:\tOptimal threshold = 0.7599999904632568\t\t(Accuracy = 0.9688715934753418)\n",
      "f2:\tOptimal threshold = 0.6100000143051147\t(Accuracy = 0.9357976913452148)\n",
      "\n",
      "Accuracy: 0.8754863739013672\n"
     ]
    }
   ],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "is_example_threshold_f05 = metrics_util.best_fthresh(\n",
    "    probs_bwd[:,1], lbl_bwd[:,1], beta=0.5, start=0.5, end=.9, average='binary').item()\n",
    "is_example_threshold_f1 = metrics_util.best_fthresh(\n",
    "    probs_bwd[:,1], lbl_bwd[:,1], beta=1, start=0.5, end=.9, average='binary').item()\n",
    "is_example_threshold_f2 = metrics_util.best_fthresh(\n",
    "    probs_bwd[:,1], lbl_bwd[:,1], beta=2, start=0.5, end=.9, average='binary').item()\n",
    "\n",
    "is_example_threshold_f05, is_example_threshold_f1, is_example_threshold_f2\n",
    "\n",
    "# determine accuracy based on optimal threshold\n",
    "is_example_val_acc_f05 = accuracy_thresh(probs_bwd[:,1], lbl_bwd[:,1], is_example_threshold_f05, sigmoid=False).item()\n",
    "is_example_val_acc_f1 = accuracy_thresh(probs_bwd[:,1], lbl_bwd[:,1], is_example_threshold_f1, sigmoid=False).item()\n",
    "is_example_val_acc_f2 = accuracy_thresh(probs_bwd[:,1], lbl_bwd[:,1], is_example_threshold_f2, sigmoid=False).item()\n",
    "\n",
    "is_example_val_acc_f05, is_example_val_acc_f1, is_example_val_acc_f2\n",
    "\n",
    "print('Backwards Only\\n-------------')\n",
    "print(f'f05:\\tOptimal threshold = {is_example_threshold_f05}\\t(Accuracy = {is_example_val_acc_f05})')\n",
    "print(f'f1:\\tOptimal threshold = {is_example_threshold_f1}\\t\\t(Accuracy = {is_example_val_acc_f1})')\n",
    "print(f'f2:\\tOptimal threshold = {is_example_threshold_f2}\\t(Accuracy = {is_example_val_acc_f2})')\n",
    "\n",
    "print(f'\\nAccuracy: {accuracy_thresh(probs_bwd[:,1], lbl_bwd[:,1], sigmoid=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble\n",
      "-------------\n",
      "f05:\tOptimal threshold = 0.7599999904632568\t(Accuracy = 0.9649805426597595)\n",
      "f1:\tOptimal threshold = 0.7599999904632568\t\t(Accuracy = 0.9649805426597595)\n",
      "f2:\tOptimal threshold = 0.7599999904632568\t(Accuracy = 0.9649805426597595)\n",
      "\n",
      "Accuracy: 0.8949416279792786\n"
     ]
    }
   ],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "is_example_threshold_f05 = metrics_util.best_fthresh(\n",
    "    probs_final[:,1], lbl_bwd[:,1], beta=0.5, start=0.5, end=.9, average='binary').item()\n",
    "is_example_threshold_f1 = metrics_util.best_fthresh(\n",
    "    probs_final[:,1], lbl_bwd[:,1], beta=1, start=0.5, end=.9, average='binary').item()\n",
    "is_example_threshold_f2 = metrics_util.best_fthresh(\n",
    "    probs_final[:,1], lbl_bwd[:,1], beta=2, start=0.5, end=.9, average='binary').item()\n",
    "\n",
    "is_example_threshold_f05, is_example_threshold_f1, is_example_threshold_f2\n",
    "\n",
    "# determine accuracy based on optimal threshold\n",
    "is_example_val_acc_f05 = accuracy_thresh(probs_final[:,1], lbl_bwd[:,1], is_example_threshold_f05, sigmoid=False).item()\n",
    "is_example_val_acc_f1 = accuracy_thresh(probs_final[:,1], lbl_bwd[:,1], is_example_threshold_f1, sigmoid=False).item()\n",
    "is_example_val_acc_f2 = accuracy_thresh(probs_final[:,1], lbl_bwd[:,1], is_example_threshold_f2, sigmoid=False).item()\n",
    "\n",
    "is_example_val_acc_f05, is_example_val_acc_f1, is_example_val_acc_f2\n",
    "\n",
    "print('Ensemble\\n-------------')\n",
    "print(f'f05:\\tOptimal threshold = {is_example_threshold_f05}\\t(Accuracy = {is_example_val_acc_f05})')\n",
    "print(f'f1:\\tOptimal threshold = {is_example_threshold_f1}\\t\\t(Accuracy = {is_example_val_acc_f1})')\n",
    "print(f'f2:\\tOptimal threshold = {is_example_threshold_f2}\\t(Accuracy = {is_example_val_acc_f2})')\n",
    "\n",
    "print(f'\\nAccuracy: {accuracy_thresh(probs_final[:,1], lbl_bwd[:,1], sigmoid=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5049) tensor(0.4342) 0.6589569619745712\n"
     ]
    }
   ],
   "source": [
    "# sentiment metrics\n",
    "sentiment_mae = metrics.mean_absolute_error(lbl_bwd[:,0], probs_final[:,0])\n",
    "sentiment_mse = metrics.mean_squared_error(lbl_bwd[:,0], probs_final[:,0])\n",
    "sentiment_rmse = math.sqrt(metrics.mean_squared_error(lbl_bwd[:,0], probs_final[:,0]))\n",
    "\n",
    "print(sentiment_mae, sentiment_mse, sentiment_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5586)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_valid_loss = (loss_fwd/len(probs_fwd) + loss_bwd/len(probs_fwd)) / 2\n",
    "final_valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference (ad-hoc documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avg_sentiment', 'is_example']\n"
     ]
    }
   ],
   "source": [
    "print(STANDARD_THEME_META_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comments = [\n",
    "    'The parking situation REALLY sucks around here.  It needs to be fixed',\n",
    "    'I LOVE working at UCSD!!!  It is wonderful',\n",
    "    \"\"\"Some staff are just uninformed.There is no support for solo-individual study (no closed off rooms).\n",
    "        Once a guy (quite tall) walked in into the girl's restroom and used the stalls standing up. \n",
    "        There was no line in the guy's restroom. This happened when I done and was going to walk out. \n",
    "        I was extremely uncomfortable\"\"\",\n",
    "    \"I love UCSD!!! It is a terrible place to work!\",\n",
    "    \"I was really uncomfortable to express my opinion!!!\"\n",
    "]\n",
    "\n",
    "doc_probs, doc_preds, doc_toks = get_cls_doc_predictions(learn.model, vocab, tokenizer, test_comments, \n",
    "                                                         threshold=is_example_threshold_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 5)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_probs), len(doc_probs), len(doc_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> xxmaj the parking situation xxup really sucks around here . xxmaj it needs to be fixed\n",
      "Probabilities:\ttensor([[3.0199, 0.0708]])\n",
      "Predictions:\ttensor([1., 0.])\n",
      "\n",
      "> i xxup love working at xxup ucsd ! ! ! xxmaj it is wonderful\n",
      "Probabilities:\ttensor([[3.0176, 0.1215]])\n",
      "Predictions:\ttensor([1., 0.])\n",
      "\n",
      "> xxmaj some staff are just uninformed . xxmaj there   is no support for solo - individual study ( no closed off rooms ) . \n",
      "  xxmaj once a guy ( quite tall ) walked in into the girl 's restroom and used the stalls standing up . \n",
      "  xxmaj there was no line in the guy 's restroom . xxmaj this happened when i done and was going to walk out . \n",
      "  i was extremely uncomfortable\n",
      "Probabilities:\ttensor([[3.0305, 0.1088]])\n",
      "Predictions:\ttensor([1., 0.])\n",
      "\n",
      "> i love xxup ucsd ! ! ! xxmaj it is a terrible place to work !\n",
      "Probabilities:\ttensor([[3.0079, 0.1034]])\n",
      "Predictions:\ttensor([1., 0.])\n",
      "\n",
      "> i was really uncomfortable to express my opinion ! ! !\n",
      "Probabilities:\ttensor([[3.0387, 0.0918]])\n",
      "Predictions:\ttensor([1., 0.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d_probs, d_preds, d_toks in zip(doc_probs, doc_preds, doc_toks):\n",
    "    print(f'> {\" \".join([t for t in d_toks])}\\nProbabilities:\\t{d_probs}\\nPredictions:\\t{d_preds}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference (batch ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "yyyymmdd = datetime.date.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "m_suf = '_multitask'\n",
    "\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37308\n"
     ]
    }
   ],
   "source": [
    "verbatims_df = pd.read_csv(STANDARD_THEME_PATH/'saw/20191021_ensemble_predictions_multilabel.csv', \n",
    "                           dtype={**lm_dtypes}, parse_dates=[])\n",
    "\n",
    "inf_df = verbatims_df.copy() #verbatims_df[test_df.SurveyID == 130].copy()\n",
    "inf_df.reset_index(drop=True, inplace=True)\n",
    "print(len(verbatims_df))\n",
    "\n",
    "corpus_cols = ['theme', 'AnswerText'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>QuestionAnsID</th>\n",
       "      <th>AnswerText</th>\n",
       "      <th>AnswerText_NonEnglish</th>\n",
       "      <th>Language</th>\n",
       "      <th>SurveyID</th>\n",
       "      <th>SurveyTypeID</th>\n",
       "      <th>BenchmarkSurveyType</th>\n",
       "      <th>ClientId</th>\n",
       "      <th>RspID</th>\n",
       "      <th>QuestionCategoryAbbr</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>QuestionClass</th>\n",
       "      <th>QuestionCategoryID</th>\n",
       "      <th>QuestionReportAbbr</th>\n",
       "      <th>QuestionCategoryLabel</th>\n",
       "      <th>BenchmarkLevel1</th>\n",
       "      <th>BenchmarkLevel2</th>\n",
       "      <th>BenchmarkLevel3</th>\n",
       "      <th>ClientBenchmarkLevel</th>\n",
       "      <th>GroupCode</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>GroupLevel1Code</th>\n",
       "      <th>GroupLevel1Name</th>\n",
       "      <th>GroupLevel2Code</th>\n",
       "      <th>GroupLevel2Name</th>\n",
       "      <th>GroupLevel3Code</th>\n",
       "      <th>GroupLevel3Name</th>\n",
       "      <th>GroupLevel4Code</th>\n",
       "      <th>GroupLevel4Name</th>\n",
       "      <th>GroupLevel5Code</th>\n",
       "      <th>GroupLevel5Name</th>\n",
       "      <th>GroupLevel6Code</th>\n",
       "      <th>GroupLevel6Name</th>\n",
       "      <th>GroupLevel7Code</th>\n",
       "      <th>GroupLevel7Name</th>\n",
       "      <th>GroupLevel8Code</th>\n",
       "      <th>GroupLevel8Name</th>\n",
       "      <th>prob_adequate_staffing</th>\n",
       "      <th>prob_advancement_and_training_opportunities</th>\n",
       "      <th>prob_appropriate_stress_work_assigned_equitably</th>\n",
       "      <th>prob_benefits</th>\n",
       "      <th>prob_better_ways_recognized_participate_in_decisions</th>\n",
       "      <th>prob_career_advancement</th>\n",
       "      <th>prob_committed_to_diversity</th>\n",
       "      <th>prob_communicates_essential_information</th>\n",
       "      <th>prob_ethical_conduct_perform_responsibilities_spirit_of_cooperation</th>\n",
       "      <th>prob_evaluated_fairly</th>\n",
       "      <th>prob_experienced_discrimination</th>\n",
       "      <th>prob_facilities_workspace_safety</th>\n",
       "      <th>prob_faculty_value_contributions</th>\n",
       "      <th>prob_favoritism_cliques</th>\n",
       "      <th>prob_fear_of_retaliation_negative_consequences</th>\n",
       "      <th>prob_feel_valued_by_department</th>\n",
       "      <th>prob_flexibility_work_life_balance</th>\n",
       "      <th>prob_good_use_of_skills</th>\n",
       "      <th>prob_have_necessary_tools</th>\n",
       "      <th>prob_have_voice_on_campus_valued_member_of_ucsd</th>\n",
       "      <th>prob_internal_processes_effective</th>\n",
       "      <th>prob_parking_transportation</th>\n",
       "      <th>prob_salary_pay</th>\n",
       "      <th>prob_satisfied_with_diversity_progams</th>\n",
       "      <th>prob_supervisor_effectiveness_resolves_staff_issues</th>\n",
       "      <th>pred_adequate_staffing</th>\n",
       "      <th>pred_advancement_and_training_opportunities</th>\n",
       "      <th>pred_appropriate_stress_work_assigned_equitably</th>\n",
       "      <th>pred_benefits</th>\n",
       "      <th>pred_better_ways_recognized_participate_in_decisions</th>\n",
       "      <th>pred_career_advancement</th>\n",
       "      <th>pred_committed_to_diversity</th>\n",
       "      <th>pred_communicates_essential_information</th>\n",
       "      <th>pred_ethical_conduct_perform_responsibilities_spirit_of_cooperation</th>\n",
       "      <th>pred_evaluated_fairly</th>\n",
       "      <th>pred_experienced_discrimination</th>\n",
       "      <th>pred_facilities_workspace_safety</th>\n",
       "      <th>pred_faculty_value_contributions</th>\n",
       "      <th>pred_favoritism_cliques</th>\n",
       "      <th>pred_fear_of_retaliation_negative_consequences</th>\n",
       "      <th>pred_feel_valued_by_department</th>\n",
       "      <th>pred_flexibility_work_life_balance</th>\n",
       "      <th>pred_good_use_of_skills</th>\n",
       "      <th>pred_have_necessary_tools</th>\n",
       "      <th>pred_have_voice_on_campus_valued_member_of_ucsd</th>\n",
       "      <th>pred_internal_processes_effective</th>\n",
       "      <th>pred_parking_transportation</th>\n",
       "      <th>pred_salary_pay</th>\n",
       "      <th>pred_satisfied_with_diversity_progams</th>\n",
       "      <th>pred_supervisor_effectiveness_resolves_staff_issues</th>\n",
       "      <th>threshold_f05</th>\n",
       "      <th>threshold_f1</th>\n",
       "      <th>threshold_f2</th>\n",
       "      <th>val_acc_f05</th>\n",
       "      <th>val_acc_f1</th>\n",
       "      <th>val_acc_f2</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69390</td>\n",
       "      <td>2576</td>\n",
       "      <td>no comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>110</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>175922</td>\n",
       "      <td>EDI</td>\n",
       "      <td>If you would like to elaborate on any of your answers to the conduct and behavioral questions ab...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Conduct &amp; Behavioral - Comments</td>\n",
       "      <td>EDI</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>455.0</td>\n",
       "      <td>3562</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>800.0</td>\n",
       "      <td>VICE CHANCELLOR CHIEF FINANCIAL OFFICER</td>\n",
       "      <td>818.0</td>\n",
       "      <td>HOUSING, DINING, HOSPITALITY</td>\n",
       "      <td>444.0</td>\n",
       "      <td>FACILITIES AND BUILDING SERVICES TOTAL STAFF</td>\n",
       "      <td>455.0</td>\n",
       "      <td>FACILITIES AND BUILDING SERVICES ALARMS, LOCK &amp; KEY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.006411</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.015509</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.227842</td>\n",
       "      <td>0.013337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  QuestionAnsID  AnswerText AnswerText_NonEnglish Language  SurveyID  SurveyTypeID BenchmarkSurveyType ClientId   RspID QuestionCategoryAbbr                                                                                         QuestionText QuestionClass  QuestionCategoryID               QuestionReportAbbr QuestionCategoryLabel BenchmarkLevel1 BenchmarkLevel2 BenchmarkLevel3 ClientBenchmarkLevel  GroupCode GroupID  GroupLevel1Code GroupLevel1Name  GroupLevel2Code                          GroupLevel2Name  GroupLevel3Code               GroupLevel3Name  GroupLevel4Code                               GroupLevel4Name  GroupLevel5Code                                      GroupLevel5Name  GroupLevel6Code GroupLevel6Name  GroupLevel7Code GroupLevel7Name  GroupLevel8Code GroupLevel8Name  prob_adequate_staffing  prob_advancement_and_training_opportunities  prob_appropriate_stress_work_assigned_equitably  prob_benefits  prob_better_ways_recognized_participate_in_decisions  \\\n",
       "0  69390           2576  no comment                   NaN  English       110             9                 SAW     UCSD  175922                  EDI  If you would like to elaborate on any of your answers to the conduct and behavioral questions ab...      Verbatim               117.0  Conduct & Behavioral - Comments                   EDI            None            None            None                    1      455.0    3562         999999.0    UC San Diego            800.0  VICE CHANCELLOR CHIEF FINANCIAL OFFICER            818.0  HOUSING, DINING, HOSPITALITY            444.0  FACILITIES AND BUILDING SERVICES TOTAL STAFF            455.0  FACILITIES AND BUILDING SERVICES ALARMS, LOCK & KEY              NaN             NaN              NaN             NaN              NaN             NaN                0.001966                                     0.003236                                         0.007138       0.000055                                              0.000644   \n",
       "\n",
       "   prob_career_advancement  prob_committed_to_diversity  prob_communicates_essential_information  prob_ethical_conduct_perform_responsibilities_spirit_of_cooperation  prob_evaluated_fairly  prob_experienced_discrimination  prob_facilities_workspace_safety  prob_faculty_value_contributions  prob_favoritism_cliques  prob_fear_of_retaliation_negative_consequences  prob_feel_valued_by_department  prob_flexibility_work_life_balance  prob_good_use_of_skills  prob_have_necessary_tools  prob_have_voice_on_campus_valued_member_of_ucsd  prob_internal_processes_effective  prob_parking_transportation  prob_salary_pay  prob_satisfied_with_diversity_progams  prob_supervisor_effectiveness_resolves_staff_issues  pred_adequate_staffing  pred_advancement_and_training_opportunities  pred_appropriate_stress_work_assigned_equitably  pred_benefits  pred_better_ways_recognized_participate_in_decisions  pred_career_advancement  pred_committed_to_diversity  pred_communicates_essential_information  \\\n",
       "0                 0.000236                     0.001841                                 0.000519                                                             0.006411               0.008533                         0.000188                          0.004777                          0.000998                 0.000224                                        0.015509                        0.001519                             0.00025                 0.000111                   0.000058                                         0.001251                           0.000567                     0.000108         0.002254                               0.227842                                             0.013337                       0                                            0                                                0              0                                                     0                        0                            0                                        0   \n",
       "\n",
       "   pred_ethical_conduct_perform_responsibilities_spirit_of_cooperation  pred_evaluated_fairly  pred_experienced_discrimination  pred_facilities_workspace_safety  pred_faculty_value_contributions  pred_favoritism_cliques  pred_fear_of_retaliation_negative_consequences  pred_feel_valued_by_department  pred_flexibility_work_life_balance  pred_good_use_of_skills  pred_have_necessary_tools  pred_have_voice_on_campus_valued_member_of_ucsd  pred_internal_processes_effective  pred_parking_transportation  pred_salary_pay  pred_satisfied_with_diversity_progams  pred_supervisor_effectiveness_resolves_staff_issues  threshold_f05  threshold_f1  threshold_f2  val_acc_f05  val_acc_f1  val_acc_f2  val_loss  \n",
       "0                                                                    0                      0                                0                                 0                                 0                        0                                               0                               0                                   0                        0                          0                                                0                                  0                            0                0                                      0                                                    0           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_theme_cols = filter_col = [col for col in inf_df if col.startswith('prob_')]\n",
    "# pred_theme_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "932700"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df = inf_df.melt(id_vars=list(lm_dtypes.keys()) + ['threshold_f05', 'threshold_f1', 'threshold_f2', 'val_acc_f05', 'val_acc_f1', 'val_acc_f2', 'val_loss'], \n",
    "                     value_vars=pred_theme_cols, \n",
    "                     var_name='theme', \n",
    "                     value_name='theme_prob')\n",
    "len(inf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69363"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df = inf_df.loc[inf_df.theme_prob >= inf_df.threshold_f2]\n",
    "len(inf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_df['url_friendly_theme'] = inf_df.theme.apply(\n",
    "    lambda s: re.sub(\"(.*?)_([a-zA-Z])\",\"\\g<1> \\g<2>\",s).replace('prob', '').strip().title().replace(' ',''))\n",
    "\n",
    "inf_df['theme'] = inf_df.url_friendly_theme.apply(lambda s: re.sub(\"([a-z])([A-Z])\",\"\\g<1> \\g<2>\",s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>QuestionAnsID</th>\n",
       "      <th>AnswerText</th>\n",
       "      <th>AnswerText_NonEnglish</th>\n",
       "      <th>Language</th>\n",
       "      <th>SurveyID</th>\n",
       "      <th>SurveyTypeID</th>\n",
       "      <th>BenchmarkSurveyType</th>\n",
       "      <th>ClientId</th>\n",
       "      <th>RspID</th>\n",
       "      <th>QuestionCategoryAbbr</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>QuestionClass</th>\n",
       "      <th>QuestionCategoryID</th>\n",
       "      <th>QuestionReportAbbr</th>\n",
       "      <th>QuestionCategoryLabel</th>\n",
       "      <th>BenchmarkLevel1</th>\n",
       "      <th>BenchmarkLevel2</th>\n",
       "      <th>BenchmarkLevel3</th>\n",
       "      <th>ClientBenchmarkLevel</th>\n",
       "      <th>GroupCode</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>GroupLevel1Code</th>\n",
       "      <th>GroupLevel1Name</th>\n",
       "      <th>GroupLevel2Code</th>\n",
       "      <th>GroupLevel2Name</th>\n",
       "      <th>GroupLevel3Code</th>\n",
       "      <th>GroupLevel3Name</th>\n",
       "      <th>GroupLevel4Code</th>\n",
       "      <th>GroupLevel4Name</th>\n",
       "      <th>GroupLevel5Code</th>\n",
       "      <th>GroupLevel5Name</th>\n",
       "      <th>GroupLevel6Code</th>\n",
       "      <th>GroupLevel6Name</th>\n",
       "      <th>GroupLevel7Code</th>\n",
       "      <th>GroupLevel7Name</th>\n",
       "      <th>GroupLevel8Code</th>\n",
       "      <th>GroupLevel8Name</th>\n",
       "      <th>threshold_f05</th>\n",
       "      <th>threshold_f1</th>\n",
       "      <th>threshold_f2</th>\n",
       "      <th>val_acc_f05</th>\n",
       "      <th>val_acc_f1</th>\n",
       "      <th>val_acc_f2</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>theme</th>\n",
       "      <th>theme_prob</th>\n",
       "      <th>url_friendly_theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>144569</td>\n",
       "      <td>1877</td>\n",
       "      <td>We are at least five people down in my department and there are many who are carrying at least t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>108611</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.373670</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>424896</td>\n",
       "      <td>76290</td>\n",
       "      <td>Even when fully staffed there is much more work than can be done in a reasonable amount of time.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>197</td>\n",
       "      <td>38</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCD</td>\n",
       "      <td>379967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If you would like to elaborate on any of your responses to the questions above, please do so her...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Additional Comments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121000.0</td>\n",
       "      <td>4873</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC Davis</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Finance, Operations and Administration</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Administrative IT</td>\n",
       "      <td>121000.0</td>\n",
       "      <td>Client &amp; Infrastructure Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.827684</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>187417</td>\n",
       "      <td>1877</td>\n",
       "      <td>My neutral or negative comments are not related to my department. Lack of funding for positions ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>121</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>122425</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.626001</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>581648</td>\n",
       "      <td>87097</td>\n",
       "      <td>Patrick Krug\\r\\nRobert Nissen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>209</td>\n",
       "      <td>41</td>\n",
       "      <td>SAW-FACULTY</td>\n",
       "      <td>CSLA-Faculty</td>\n",
       "      <td>432197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Would you like to highlight a faculty or staff member who has made a particular impact on creati...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recognize Colleague</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.292417</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>590077</td>\n",
       "      <td>9439</td>\n",
       "      <td>With so many new systems coming on board, it is integral to continue, and expand, communications...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>445617</td>\n",
       "      <td>None</td>\n",
       "      <td>The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>201.0</td>\n",
       "      <td>IdeaWave Comments</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>10201.0</td>\n",
       "      <td>3441</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>ACADEMIC AFFAIRS</td>\n",
       "      <td>10002.0</td>\n",
       "      <td>DIVISIONS/SCHOOLS</td>\n",
       "      <td>10004.0</td>\n",
       "      <td>BIOLOGICAL SCIENCES</td>\n",
       "      <td>10201.0</td>\n",
       "      <td>BIOLOGY - DEAN/ADMIN SUPPORT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.272820</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      Id  QuestionAnsID                                                                                           AnswerText AnswerText_NonEnglish Language  SurveyID  SurveyTypeID BenchmarkSurveyType      ClientId   RspID QuestionCategoryAbbr                                                                                         QuestionText QuestionClass  QuestionCategoryID                    QuestionReportAbbr           QuestionCategoryLabel BenchmarkLevel1 BenchmarkLevel2 BenchmarkLevel3 ClientBenchmarkLevel  GroupCode GroupID  GroupLevel1Code GroupLevel1Name  GroupLevel2Code                         GroupLevel2Name  GroupLevel3Code    GroupLevel3Name  GroupLevel4Code                   GroupLevel4Name  GroupLevel5Code               GroupLevel5Name  GroupLevel6Code GroupLevel6Name  GroupLevel7Code GroupLevel7Name  GroupLevel8Code GroupLevel8Name  threshold_f05  threshold_f1  threshold_f2  val_acc_f05  val_acc_f1  val_acc_f2  val_loss              theme  theme_prob  \\\n",
       "0      7  144569           1877  We are at least five people down in my department and there are many who are carrying at least t...                   NaN  English       120             9                 SAW          UCSD  108611                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1        NaN    2579              NaN             NaN              NaN                                     NaN              NaN                NaN              NaN                               NaN              NaN                           NaN              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.373670   \n",
       "1      8  424896          76290     Even when fully staffed there is much more work than can be done in a reasonable amount of time.                   NaN  English       197            38                 SAW           UCD  379967                  NaN  If you would like to elaborate on any of your responses to the questions above, please do so her...           NaN                 NaN                   Additional Comments                             NaN             NaN             NaN             NaN                  NaN   121000.0    4873         999999.0        UC Davis         100000.0  Finance, Operations and Administration         120000.0  Administrative IT         121000.0  Client & Infrastructure Services              NaN                           NaN              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.827684   \n",
       "2     18  187417           1877  My neutral or negative comments are not related to my department. Lack of funding for positions ...                   NaN  English       121             9                 SAW          UCSD  122425                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1        NaN    1930              NaN             NaN              NaN                                     NaN              NaN                NaN              NaN                               NaN              NaN                           NaN              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.626001   \n",
       "3     35  581648          87097                                                                        Patrick Krug\\r\\nRobert Nissen                   NaN  English       209            41         SAW-FACULTY  CSLA-Faculty  432197                  NaN  Would you like to highlight a faculty or staff member who has made a particular impact on creati...      Verbatim                 NaN                   Recognize Colleague                             NaN             NaN             NaN             NaN                  NaN        NaN    5268              NaN             NaN              NaN                                     NaN              NaN                NaN              NaN                               NaN              NaN                           NaN              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.292417   \n",
       "4     37  590077           9439  With so many new systems coming on board, it is integral to continue, and expand, communications...                   NaN  English       212             9                 SAW          UCSD  445617                 None  The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...      Verbatim               201.0                     IdeaWave Comments                           Other            None            None            None                    1    10201.0    3441         999999.0    UC San Diego          10000.0                        ACADEMIC AFFAIRS          10002.0  DIVISIONS/SCHOOLS          10004.0               BIOLOGICAL SCIENCES          10201.0  BIOLOGY - DEAN/ADMIN SUPPORT              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.272820   \n",
       "\n",
       "  url_friendly_theme  \n",
       "0   AdequateStaffing  \n",
       "1   AdequateStaffing  \n",
       "2   AdequateStaffing  \n",
       "3   AdequateStaffing  \n",
       "4   AdequateStaffing  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_results(backwards:bool=False, m_suf:str='multilabel'):\n",
    "    \n",
    "    model_prefix = 'bwd' if backwards else 'fwd'\n",
    "    \n",
    "    # 1. grab learner, procs, and data\n",
    "    inf_learn = load_learner(STANDARD_THEME_META_PATH, file=f'{model_prefix}_export_clas_{m_suf}.pkl')\n",
    "    txt_procs = inf_learn.data.train_ds.processor\n",
    "    inf_data = TextList.from_df(inf_df, cols=corpus_cols, processor=txt_procs).split_none().label_empty()\n",
    "    \n",
    "    # 2. define a suitable dataloader\n",
    "    collate_fn = partial(pad_collate, pad_first=True, backwards=backwards)\n",
    "    sampler = SortSampler(inf_data.train.x, key=[len(t) for t in inf_data.train.x.items].__getitem__)\n",
    "    dl = DeviceDataLoader.create(inf_data.train, bs=128, sampler=sampler, collate_fn=collate_fn, device=device)\n",
    "    \n",
    "    # 3. get probs and document vectors\n",
    "    inf_learn.model = inf_learn.model.to(device)\n",
    "    inf_learn.model = inf_learn.model.eval()\n",
    "    \n",
    "    test_probs, doc_vecs, concat_doc_vecs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for index, (xb, yb) in enumerate(dl):\n",
    "            if index % 1000 == 0:  print(index)\n",
    "\n",
    "            # reset hidden state (if you don't do this you will OOM)\n",
    "            inf_learn.model.reset()\n",
    "\n",
    "            # why \"detach\"? the computation of gradients wrt the weights of netG can be fully \n",
    "            # avoided in the backward pass if the graph is detached where it is.\n",
    "            probs, raw_outputs, outputs = inf_learn.model(xb)\n",
    "            test_probs.append(to_detach(probs))\n",
    "\n",
    "\n",
    "    all_probs = torch.cat(test_probs)\n",
    "\n",
    "    # 4. ensure results are returned in order\n",
    "    if hasattr(dl, 'sampler'):\n",
    "        sampler_idxs = [i for i in dl.sampler]\n",
    "        reverse_sampler = np.argsort(sampler_idxs)\n",
    "        all_probs = all_probs[reverse_sampler]\n",
    "        \n",
    "    # 5. return ordered results\n",
    "    inf_learn, inf_data = None, None; gc.collect()\n",
    "    \n",
    "    return all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([69363, 2])\n",
      "torch.Size([69363, 2])\n",
      "torch.Size([69363, 2])\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "probs_fwd = get_classification_results(backwards=False, m_suf='multitask')\n",
    "probs_bwd = get_classification_results(backwards=True, m_suf='multitask')\n",
    "\n",
    "probs_fwd[:,1] = torch.sigmoid(probs_fwd[:,1])\n",
    "probs_bwd[:,1] = torch.sigmoid(probs_bwd[:,1])\n",
    "\n",
    "probs_final = (probs_fwd + probs_bwd) / 2\n",
    "\n",
    "print(probs_final.shape)\n",
    "print(probs_fwd.shape)\n",
    "print(probs_bwd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the probabilities of each label to `inf_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_avg_sentiment</th>\n",
       "      <th>prob_is_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.495984</td>\n",
       "      <td>0.289978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.847534</td>\n",
       "      <td>0.224968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.388277</td>\n",
       "      <td>0.337524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.723387</td>\n",
       "      <td>0.391268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.927198</td>\n",
       "      <td>0.559345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prob_avg_sentiment  prob_is_example\n",
       "0            2.495984         0.289978\n",
       "1            2.847534         0.224968\n",
       "2            2.388277         0.337524\n",
       "3            3.723387         0.391268\n",
       "4            2.927198         0.559345"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_labels = ['prob_' + lbl for lbl in STANDARD_THEME_META_LABELS]\n",
    "probs_df = pd.DataFrame(probs_final.numpy(), columns=prob_labels)\n",
    "probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>QuestionAnsID</th>\n",
       "      <th>AnswerText</th>\n",
       "      <th>AnswerText_NonEnglish</th>\n",
       "      <th>Language</th>\n",
       "      <th>SurveyID</th>\n",
       "      <th>SurveyTypeID</th>\n",
       "      <th>BenchmarkSurveyType</th>\n",
       "      <th>ClientId</th>\n",
       "      <th>RspID</th>\n",
       "      <th>QuestionCategoryAbbr</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>QuestionClass</th>\n",
       "      <th>QuestionCategoryID</th>\n",
       "      <th>QuestionReportAbbr</th>\n",
       "      <th>QuestionCategoryLabel</th>\n",
       "      <th>BenchmarkLevel1</th>\n",
       "      <th>BenchmarkLevel2</th>\n",
       "      <th>BenchmarkLevel3</th>\n",
       "      <th>ClientBenchmarkLevel</th>\n",
       "      <th>GroupCode</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>GroupLevel1Code</th>\n",
       "      <th>GroupLevel1Name</th>\n",
       "      <th>GroupLevel2Code</th>\n",
       "      <th>GroupLevel2Name</th>\n",
       "      <th>GroupLevel3Code</th>\n",
       "      <th>GroupLevel3Name</th>\n",
       "      <th>GroupLevel4Code</th>\n",
       "      <th>GroupLevel4Name</th>\n",
       "      <th>GroupLevel5Code</th>\n",
       "      <th>GroupLevel5Name</th>\n",
       "      <th>GroupLevel6Code</th>\n",
       "      <th>GroupLevel6Name</th>\n",
       "      <th>GroupLevel7Code</th>\n",
       "      <th>GroupLevel7Name</th>\n",
       "      <th>GroupLevel8Code</th>\n",
       "      <th>GroupLevel8Name</th>\n",
       "      <th>threshold_f05</th>\n",
       "      <th>threshold_f1</th>\n",
       "      <th>threshold_f2</th>\n",
       "      <th>val_acc_f05</th>\n",
       "      <th>val_acc_f1</th>\n",
       "      <th>val_acc_f2</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>theme</th>\n",
       "      <th>theme_prob</th>\n",
       "      <th>url_friendly_theme</th>\n",
       "      <th>prob_avg_sentiment</th>\n",
       "      <th>prob_is_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>144569</td>\n",
       "      <td>1877</td>\n",
       "      <td>We are at least five people down in my department and there are many who are carrying at least t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>108611</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.373670</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>2.495984</td>\n",
       "      <td>0.289978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>424896</td>\n",
       "      <td>76290</td>\n",
       "      <td>Even when fully staffed there is much more work than can be done in a reasonable amount of time.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>197</td>\n",
       "      <td>38</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCD</td>\n",
       "      <td>379967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If you would like to elaborate on any of your responses to the questions above, please do so her...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Additional Comments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121000.0</td>\n",
       "      <td>4873</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC Davis</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Finance, Operations and Administration</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Administrative IT</td>\n",
       "      <td>121000.0</td>\n",
       "      <td>Client &amp; Infrastructure Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.827684</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>2.847534</td>\n",
       "      <td>0.224968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>187417</td>\n",
       "      <td>1877</td>\n",
       "      <td>My neutral or negative comments are not related to my department. Lack of funding for positions ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>121</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>122425</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.626001</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>2.388277</td>\n",
       "      <td>0.337524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>581648</td>\n",
       "      <td>87097</td>\n",
       "      <td>Patrick Krug\\r\\nRobert Nissen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>209</td>\n",
       "      <td>41</td>\n",
       "      <td>SAW-FACULTY</td>\n",
       "      <td>CSLA-Faculty</td>\n",
       "      <td>432197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Would you like to highlight a faculty or staff member who has made a particular impact on creati...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recognize Colleague</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.292417</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>3.723387</td>\n",
       "      <td>0.391268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>590077</td>\n",
       "      <td>9439</td>\n",
       "      <td>With so many new systems coming on board, it is integral to continue, and expand, communications...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>445617</td>\n",
       "      <td>None</td>\n",
       "      <td>The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>201.0</td>\n",
       "      <td>IdeaWave Comments</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>10201.0</td>\n",
       "      <td>3441</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>ACADEMIC AFFAIRS</td>\n",
       "      <td>10002.0</td>\n",
       "      <td>DIVISIONS/SCHOOLS</td>\n",
       "      <td>10004.0</td>\n",
       "      <td>BIOLOGICAL SCIENCES</td>\n",
       "      <td>10201.0</td>\n",
       "      <td>BIOLOGY - DEAN/ADMIN SUPPORT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.272820</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>2.927198</td>\n",
       "      <td>0.559345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      Id  QuestionAnsID                                                                                           AnswerText AnswerText_NonEnglish Language  SurveyID  SurveyTypeID BenchmarkSurveyType      ClientId   RspID QuestionCategoryAbbr                                                                                         QuestionText QuestionClass  QuestionCategoryID                    QuestionReportAbbr           QuestionCategoryLabel BenchmarkLevel1 BenchmarkLevel2 BenchmarkLevel3 ClientBenchmarkLevel  GroupCode GroupID  GroupLevel1Code GroupLevel1Name  GroupLevel2Code                         GroupLevel2Name  GroupLevel3Code    GroupLevel3Name  GroupLevel4Code                   GroupLevel4Name  GroupLevel5Code               GroupLevel5Name  GroupLevel6Code GroupLevel6Name  GroupLevel7Code GroupLevel7Name  GroupLevel8Code GroupLevel8Name  threshold_f05  threshold_f1  threshold_f2  val_acc_f05  val_acc_f1  val_acc_f2  val_loss              theme  theme_prob  \\\n",
       "0      7  144569           1877  We are at least five people down in my department and there are many who are carrying at least t...                   NaN  English       120             9                 SAW          UCSD  108611                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1        NaN    2579              NaN             NaN              NaN                                     NaN              NaN                NaN              NaN                               NaN              NaN                           NaN              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.373670   \n",
       "1      8  424896          76290     Even when fully staffed there is much more work than can be done in a reasonable amount of time.                   NaN  English       197            38                 SAW           UCD  379967                  NaN  If you would like to elaborate on any of your responses to the questions above, please do so her...           NaN                 NaN                   Additional Comments                             NaN             NaN             NaN             NaN                  NaN   121000.0    4873         999999.0        UC Davis         100000.0  Finance, Operations and Administration         120000.0  Administrative IT         121000.0  Client & Infrastructure Services              NaN                           NaN              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.827684   \n",
       "2     18  187417           1877  My neutral or negative comments are not related to my department. Lack of funding for positions ...                   NaN  English       121             9                 SAW          UCSD  122425                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1        NaN    1930              NaN             NaN              NaN                                     NaN              NaN                NaN              NaN                               NaN              NaN                           NaN              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.626001   \n",
       "3     35  581648          87097                                                                        Patrick Krug\\r\\nRobert Nissen                   NaN  English       209            41         SAW-FACULTY  CSLA-Faculty  432197                  NaN  Would you like to highlight a faculty or staff member who has made a particular impact on creati...      Verbatim                 NaN                   Recognize Colleague                             NaN             NaN             NaN             NaN                  NaN        NaN    5268              NaN             NaN              NaN                                     NaN              NaN                NaN              NaN                               NaN              NaN                           NaN              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.292417   \n",
       "4     37  590077           9439  With so many new systems coming on board, it is integral to continue, and expand, communications...                   NaN  English       212             9                 SAW          UCSD  445617                 None  The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...      Verbatim               201.0                     IdeaWave Comments                           Other            None            None            None                    1    10201.0    3441         999999.0    UC San Diego          10000.0                        ACADEMIC AFFAIRS          10002.0  DIVISIONS/SCHOOLS          10004.0               BIOLOGICAL SCIENCES          10201.0  BIOLOGY - DEAN/ADMIN SUPPORT              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.272820   \n",
       "\n",
       "  url_friendly_theme  prob_avg_sentiment  prob_is_example  \n",
       "0   AdequateStaffing            2.495984         0.289978  \n",
       "1   AdequateStaffing            2.847534         0.224968  \n",
       "2   AdequateStaffing            2.388277         0.337524  \n",
       "3   AdequateStaffing            3.723387         0.391268  \n",
       "4   AdequateStaffing            2.927198         0.559345  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df_filtered.update(probs_df)\n",
    "final_df = pd.concat([inf_df, probs_df], axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in predictions based on f1 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lbl in STANDARD_THEME_META_LABELS[1:]:\n",
    "    final_df[f'pred_{lbl}'] = (final_df[f'prob_{lbl}'] > is_example_threshold_f1).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include found thresholds and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['is_example_threshold_f05'] = is_example_threshold_f05\n",
    "final_df['is_example_threshold_f1'] = is_example_threshold_f1\n",
    "final_df['is_example_threshold_f2'] = is_example_threshold_f2\n",
    "\n",
    "final_df['is_example_val_acc_f05'] = is_example_val_acc_f05\n",
    "final_df['is_example_val_acc_f1'] = is_example_val_acc_f1\n",
    "final_df['is_example_val_acc_f2'] = is_example_val_acc_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['sentiment_mae'] = sentiment_mae.item()\n",
    "final_df['sentiment_mse'] = sentiment_mse.item()\n",
    "final_df['sentiment_rmse'] = sentiment_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['val_loss_metadata'] = final_valid_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>QuestionAnsID</th>\n",
       "      <th>AnswerText</th>\n",
       "      <th>AnswerText_NonEnglish</th>\n",
       "      <th>Language</th>\n",
       "      <th>SurveyID</th>\n",
       "      <th>SurveyTypeID</th>\n",
       "      <th>BenchmarkSurveyType</th>\n",
       "      <th>ClientId</th>\n",
       "      <th>RspID</th>\n",
       "      <th>QuestionCategoryAbbr</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>QuestionClass</th>\n",
       "      <th>QuestionCategoryID</th>\n",
       "      <th>QuestionReportAbbr</th>\n",
       "      <th>QuestionCategoryLabel</th>\n",
       "      <th>BenchmarkLevel1</th>\n",
       "      <th>BenchmarkLevel2</th>\n",
       "      <th>BenchmarkLevel3</th>\n",
       "      <th>ClientBenchmarkLevel</th>\n",
       "      <th>GroupCode</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>GroupLevel1Code</th>\n",
       "      <th>GroupLevel1Name</th>\n",
       "      <th>GroupLevel2Code</th>\n",
       "      <th>GroupLevel2Name</th>\n",
       "      <th>GroupLevel3Code</th>\n",
       "      <th>GroupLevel3Name</th>\n",
       "      <th>GroupLevel4Code</th>\n",
       "      <th>GroupLevel4Name</th>\n",
       "      <th>GroupLevel5Code</th>\n",
       "      <th>GroupLevel5Name</th>\n",
       "      <th>GroupLevel6Code</th>\n",
       "      <th>GroupLevel6Name</th>\n",
       "      <th>GroupLevel7Code</th>\n",
       "      <th>GroupLevel7Name</th>\n",
       "      <th>GroupLevel8Code</th>\n",
       "      <th>GroupLevel8Name</th>\n",
       "      <th>threshold_f05</th>\n",
       "      <th>threshold_f1</th>\n",
       "      <th>threshold_f2</th>\n",
       "      <th>val_acc_f05</th>\n",
       "      <th>val_acc_f1</th>\n",
       "      <th>val_acc_f2</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>theme</th>\n",
       "      <th>theme_prob</th>\n",
       "      <th>url_friendly_theme</th>\n",
       "      <th>prob_avg_sentiment</th>\n",
       "      <th>prob_is_example</th>\n",
       "      <th>pred_is_example</th>\n",
       "      <th>is_example_threshold_f05</th>\n",
       "      <th>is_example_threshold_f1</th>\n",
       "      <th>is_example_threshold_f2</th>\n",
       "      <th>is_example_val_acc_f05</th>\n",
       "      <th>is_example_val_acc_f1</th>\n",
       "      <th>is_example_val_acc_f2</th>\n",
       "      <th>sentiment_mae</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>sentiment_rmse</th>\n",
       "      <th>val_loss_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>144569</td>\n",
       "      <td>1877</td>\n",
       "      <td>We are at least five people down in my department and there are many who are carrying at least t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>108611</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.373670</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>2.495984</td>\n",
       "      <td>0.289978</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.504937</td>\n",
       "      <td>0.434224</td>\n",
       "      <td>0.658957</td>\n",
       "      <td>0.55863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>424896</td>\n",
       "      <td>76290</td>\n",
       "      <td>Even when fully staffed there is much more work than can be done in a reasonable amount of time.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>197</td>\n",
       "      <td>38</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCD</td>\n",
       "      <td>379967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If you would like to elaborate on any of your responses to the questions above, please do so her...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Additional Comments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121000.0</td>\n",
       "      <td>4873</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC Davis</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Finance, Operations and Administration</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Administrative IT</td>\n",
       "      <td>121000.0</td>\n",
       "      <td>Client &amp; Infrastructure Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.827684</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>2.847534</td>\n",
       "      <td>0.224968</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.504937</td>\n",
       "      <td>0.434224</td>\n",
       "      <td>0.658957</td>\n",
       "      <td>0.55863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>187417</td>\n",
       "      <td>1877</td>\n",
       "      <td>My neutral or negative comments are not related to my department. Lack of funding for positions ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>121</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>122425</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.626001</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>2.388277</td>\n",
       "      <td>0.337524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.504937</td>\n",
       "      <td>0.434224</td>\n",
       "      <td>0.658957</td>\n",
       "      <td>0.55863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>581648</td>\n",
       "      <td>87097</td>\n",
       "      <td>Patrick Krug\\r\\nRobert Nissen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>209</td>\n",
       "      <td>41</td>\n",
       "      <td>SAW-FACULTY</td>\n",
       "      <td>CSLA-Faculty</td>\n",
       "      <td>432197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Would you like to highlight a faculty or staff member who has made a particular impact on creati...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recognize Colleague</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.292417</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>3.723387</td>\n",
       "      <td>0.391268</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.504937</td>\n",
       "      <td>0.434224</td>\n",
       "      <td>0.658957</td>\n",
       "      <td>0.55863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>590077</td>\n",
       "      <td>9439</td>\n",
       "      <td>With so many new systems coming on board, it is integral to continue, and expand, communications...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>445617</td>\n",
       "      <td>None</td>\n",
       "      <td>The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>201.0</td>\n",
       "      <td>IdeaWave Comments</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>10201.0</td>\n",
       "      <td>3441</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>ACADEMIC AFFAIRS</td>\n",
       "      <td>10002.0</td>\n",
       "      <td>DIVISIONS/SCHOOLS</td>\n",
       "      <td>10004.0</td>\n",
       "      <td>BIOLOGICAL SCIENCES</td>\n",
       "      <td>10201.0</td>\n",
       "      <td>BIOLOGY - DEAN/ADMIN SUPPORT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.079133</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>0.272820</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>2.927198</td>\n",
       "      <td>0.559345</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.964981</td>\n",
       "      <td>0.504937</td>\n",
       "      <td>0.434224</td>\n",
       "      <td>0.658957</td>\n",
       "      <td>0.55863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      Id  QuestionAnsID                                                                                           AnswerText AnswerText_NonEnglish Language  SurveyID  SurveyTypeID BenchmarkSurveyType      ClientId   RspID QuestionCategoryAbbr                                                                                         QuestionText QuestionClass  QuestionCategoryID                    QuestionReportAbbr           QuestionCategoryLabel BenchmarkLevel1 BenchmarkLevel2 BenchmarkLevel3 ClientBenchmarkLevel  GroupCode GroupID  GroupLevel1Code GroupLevel1Name  GroupLevel2Code                         GroupLevel2Name  GroupLevel3Code    GroupLevel3Name  GroupLevel4Code                   GroupLevel4Name  GroupLevel5Code               GroupLevel5Name  GroupLevel6Code GroupLevel6Name  GroupLevel7Code GroupLevel7Name  GroupLevel8Code GroupLevel8Name  threshold_f05  threshold_f1  threshold_f2  val_acc_f05  val_acc_f1  val_acc_f2  val_loss              theme  theme_prob  \\\n",
       "0      7  144569           1877  We are at least five people down in my department and there are many who are carrying at least t...                   NaN  English       120             9                 SAW          UCSD  108611                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1        NaN    2579              NaN             NaN              NaN                                     NaN              NaN                NaN              NaN                               NaN              NaN                           NaN              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.373670   \n",
       "1      8  424896          76290     Even when fully staffed there is much more work than can be done in a reasonable amount of time.                   NaN  English       197            38                 SAW           UCD  379967                  NaN  If you would like to elaborate on any of your responses to the questions above, please do so her...           NaN                 NaN                   Additional Comments                             NaN             NaN             NaN             NaN                  NaN   121000.0    4873         999999.0        UC Davis         100000.0  Finance, Operations and Administration         120000.0  Administrative IT         121000.0  Client & Infrastructure Services              NaN                           NaN              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.827684   \n",
       "2     18  187417           1877  My neutral or negative comments are not related to my department. Lack of funding for positions ...                   NaN  English       121             9                 SAW          UCSD  122425                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1        NaN    1930              NaN             NaN              NaN                                     NaN              NaN                NaN              NaN                               NaN              NaN                           NaN              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.626001   \n",
       "3     35  581648          87097                                                                        Patrick Krug\\r\\nRobert Nissen                   NaN  English       209            41         SAW-FACULTY  CSLA-Faculty  432197                  NaN  Would you like to highlight a faculty or staff member who has made a particular impact on creati...      Verbatim                 NaN                   Recognize Colleague                             NaN             NaN             NaN             NaN                  NaN        NaN    5268              NaN             NaN              NaN                                     NaN              NaN                NaN              NaN                               NaN              NaN                           NaN              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.292417   \n",
       "4     37  590077           9439  With so many new systems coming on board, it is integral to continue, and expand, communications...                   NaN  English       212             9                 SAW          UCSD  445617                 None  The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...      Verbatim               201.0                     IdeaWave Comments                           Other            None            None            None                    1    10201.0    3441         999999.0    UC San Diego          10000.0                        ACADEMIC AFFAIRS          10002.0  DIVISIONS/SCHOOLS          10004.0               BIOLOGICAL SCIENCES          10201.0  BIOLOGY - DEAN/ADMIN SUPPORT              NaN             NaN              NaN             NaN              NaN             NaN           0.27          0.27          0.14     0.980913    0.980913    0.972199  0.079133  Adequate Staffing    0.272820   \n",
       "\n",
       "  url_friendly_theme  prob_avg_sentiment  prob_is_example  pred_is_example  is_example_threshold_f05  is_example_threshold_f1  is_example_threshold_f2  is_example_val_acc_f05  is_example_val_acc_f1  is_example_val_acc_f2  sentiment_mae  sentiment_mse  sentiment_rmse  val_loss_metadata  \n",
       "0   AdequateStaffing            2.495984         0.289978                0                      0.76                     0.76                     0.76                0.964981               0.964981               0.964981       0.504937       0.434224        0.658957            0.55863  \n",
       "1   AdequateStaffing            2.847534         0.224968                0                      0.76                     0.76                     0.76                0.964981               0.964981               0.964981       0.504937       0.434224        0.658957            0.55863  \n",
       "2   AdequateStaffing            2.388277         0.337524                0                      0.76                     0.76                     0.76                0.964981               0.964981               0.964981       0.504937       0.434224        0.658957            0.55863  \n",
       "3   AdequateStaffing            3.723387         0.391268                0                      0.76                     0.76                     0.76                0.964981               0.964981               0.964981       0.504937       0.434224        0.658957            0.55863  \n",
       "4   AdequateStaffing            2.927198         0.559345                0                      0.76                     0.76                     0.76                0.964981               0.964981               0.964981       0.504937       0.434224        0.658957            0.55863  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "final_df.to_csv(STANDARD_THEME_META_PATH/f'{yyyymmdd}_ensemble_predictions{m_suf}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7599999904632568\n",
      "0.7599999904632568\n",
      "0.7599999904632568\n",
      "2.9090850353240967\n"
     ]
    }
   ],
   "source": [
    "print(final_df.iloc[0].is_example_threshold_f05)\n",
    "print(final_df.iloc[0].is_example_threshold_f1)\n",
    "print(final_df.iloc[0].is_example_threshold_f2)\n",
    "print(final_df.prob_avg_sentiment.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.layer_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Embedding(39904, 400, padding_idx=1)\n",
      "  (1): EmbeddingDropout(\n",
      "    (emb): Embedding(39904, 400, padding_idx=1)\n",
      "  )\n",
      ")\n",
      "\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(400, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 400, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "\n",
      "Sequential(\n",
      "  (0): PoolingLinearClassifier(\n",
      "    (layers): Sequential(\n",
      "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.2, inplace=False)\n",
      "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ print(f'{lg}\\n') for lg in learn.layer_groups ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
