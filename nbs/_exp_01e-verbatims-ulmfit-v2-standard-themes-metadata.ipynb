{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp standard_themes/metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tritonlytics MultiTask Classification - Standard Themes Metadata\n",
    "\n",
    "> Multi-modal models for predicting IsExample and Theme sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import datetime\n",
    "import sklearn.metrics as skm\n",
    "from tritonlytics_ai.utils import *\n",
    "\n",
    "from fastai import __version__ as fa2_version\n",
    "from fastai.text.all import *\n",
    "from blurr.modeling.all import MultiTargetLoss\n",
    "\n",
    "import spacy\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "spacy_es = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb, gc\n",
    "\n",
    "# pandas and plotting config\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9,6)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version: 2.0.14\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "print(f'fastai version: {fa2_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32408"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = pickle.load(open(LM_PATH/'vocab.pkl', 'rb')); len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 80\n",
    "bptt= 72\n",
    "wd = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 24000\n",
    "\n",
    "include_fld_tok = True\n",
    "include_bos_tok = True\n",
    "include_eos_tok = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define what text columns to use (can be multiple)\n",
    "corpus_cols = ['theme', 'answer_text'] \n",
    "\n",
    "# define how to identify the text we are using for the LM\n",
    "corpus_suf = '_multitask' #'_cleaned'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(STANDARD_THEME_META_PATH/'train.csv')\n",
    "valid_df = pd.read_csv(STANDARD_THEME_META_PATH/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.is_example.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any rows whre the \"corpus_cols\" are nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=corpus_cols, inplace=True)\n",
    "valid_df.dropna(subset=corpus_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(set(train_df.theme.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab.itos += [ item.lower() for item in list(set(train_df.theme.unique())) ]\n",
    "# vocab.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(vocab.itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_valid'] = False\n",
    "valid_df['is_valid'] = True\n",
    "df = pd.concat([train_df, valid_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepend custom tokenization rules to defaults\n",
    "custom_lowercase = partial(lowercase, add_bos=include_bos_tok, add_eos=include_eos_tok)\n",
    "\n",
    "custom_tok_rules = defaults.text_proc_rules[:-1] + [custom_lowercase, \n",
    "                                                    make_replacements, \n",
    "                                                    fix_ampm, \n",
    "                                                    fix_sentence_ends, \n",
    "                                                    fix_hyphenated_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the mid-level `DataBlocks` API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 132 ms, sys: 3.91 ms, total: 136 ms\n",
      "Wall time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "blocks = (\n",
    "    TextBlock.from_df(corpus_cols, vocab=vocab, seq_len=bptt, rules=custom_tok_rules, mark_fields=include_fld_tok),\n",
    "    RegressionBlock(),\n",
    "    CategoryBlock()\n",
    ")\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('text'),\n",
    "                   get_y=[ColReader('avg_sentiment'), ColReader('is_example')],\n",
    "                   splitter=ColSplitter(col='is_valid'), \n",
    "                   n_inp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dblock.summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 s, sys: 1.4 s, total: 15 s\n",
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dls = dblock.dataloaders(df, bs=bsz, seq_len=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Datasets vocab has 2 items : the inputs vocab (32408 items), and the targets (2 items)\n"
     ]
    }
   ],
   "source": [
    "print((\n",
    "    f'The Datasets vocab has {len(dls.vocab)} items : the inputs vocab ({len(dls.vocab[0])} items), '\n",
    "    f'and the targets ({len(dls.vocab[1])} items)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorText([   2,    4,  371,    8,  458,   68,    8, 5843,   68,    8,  475,    4,\n",
      "         290,  109,   17,   10,   27,   38,  323, 1260,   49,  322,  636,   11,\n",
      "         675, 4474,   21,   26,   32,   57,  684,   11,   30,  122,    9]), tensor(3.), TensorCategory(0))\n"
     ]
    }
   ],
   "source": [
    "print(dls.train_ds[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxfld 1 xxmaj supervisor xxmaj effectiveness / xxmaj resolves xxmaj staff xxmaj issues xxfld 2 xxmaj in the xxmaj enterprise xxmaj network and xxmaj telecommunications group of xxup its , the environment continues to be toxic , retaliatory , abusive , and discriminatory as in past years . xxmaj under the direction of xxmaj james xxmaj seddon , supervisor xxmaj malerie xxmaj samadi harasses and talks down to employees . xxmaj manipulates and edits official documentation to make staff look and give lower performance appraisal ratings or retaliate against them . xxmaj also , use the same practice to provide their friends with higher performance ratings and award them with higher merit increases . xxmaj senior management continues to harbor this behavior without any consequence and or accountability . xxmaj james and xxmaj malerie exploit minorities and give preferential treatment to personnel hired by them . xxmaj regularly abuse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos xxfld 1 xxmaj evaluated xxmaj fairly xxfld 2 xxmaj in the xxmaj enterprise xxmaj network and xxmaj telecommunications group of xxup its , the environment continues to be toxic , retaliatory , abusive , and discriminatory as in past years . xxmaj under the direction of xxmaj james xxmaj seddon , supervisor xxmaj malerie xxmaj samadi harasses and talks down to employees . xxmaj manipulates and edits official documentation to make staff look and give lower performance appraisal ratings or retaliate against them . xxmaj also , use the same practice to provide their friends with higher performance ratings and award them with higher merit increases . xxmaj senior management continues to harbor this behavior without any consequence and or accountability . xxmaj james and xxmaj malerie exploit minorities and give preferential treatment to personnel hired by them . xxmaj regularly abuse the power that the xxmaj university of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 482]) torch.cuda.LongTensor torch.Size([80]) torch.Size([80]) torch.cuda.FloatTensor torch.cuda.LongTensor 80\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dls.train))\n",
    "print(batch[0].size(), batch[0].type(), batch[1].size(), batch[2].size(), batch[1].type(), batch[2].type(), bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xxbos xxfld 1 xxmaj supervisor xxmaj effectiveness / xxmaj resolves xxmaj staff xxmaj issues xxfld 2 xxmaj in the xxmaj enterprise xxmaj network and xxmaj telecommunications group of xxup its , the environment continues to be toxic , retaliatory , abusive , and discriminatory as in past years . xxmaj under the direction of xxmaj james xxmaj seddon , supervisor xxmaj malerie xxmaj samadi harasses and talks down to employees . xxmaj manipulates and edits official documentation to make staff look and give lower performance appraisal ratings or retaliate against them . xxmaj also , use the same practice to provide their friends with higher performance ratings and award them with higher merit increases . xxmaj senior management continues to harbor this behavior without any consequence and or accountability . xxmaj james and xxmaj malerie exploit minorities and give preferential treatment to personnel hired by them . xxmaj regularly abuse the power that the xxmaj university of xxmaj california gives them and exercise nepotism because they are both product of such practices . \\\\ r \\n xxmaj other supervisors like xxmaj ynez xxmaj hicks also participates in the same practices of xxunk , nepotism , and favoritism . \\\\ r \\n xxmaj it is unacceptable that this behavior and practices continue to be used by management without any accountability . xxmaj principles of the community are ignored continuously daily . xxmaj when this type of situation is brought up to xxmaj human xxmaj resources , they ignore them because no one is enforcing the xxup uc xxmaj principles . xxmaj james xxmaj seddon and xxmaj malerie xxmaj samadi in the xxmaj datacom group do n't care about staff promotion , compensation , and well being . xxmaj they only care about themselves and their friends . xxmaj hiring practices are unfair ; they manipulate the process so they can hire barely qualified personnel into experienced positions . xxmaj existing staff is overworked because newer personnel can not pull their weight , yet xxmaj malerie and xxmaj james make it look like they are in their appraisals . xxmaj they mentally abuse staff and minimize their work performance . xxmaj recently one of the team member past away while working at home . a stroke caused by the stress and the pressure that xxmaj malerie was putting on xxmaj david xxmaj ramirez . xxmaj she used him to get her promotion to supervisor and make her look good in front of others . \\\\ r \\n xxmaj both xxmaj james and xxmaj malerie are the perfect examples of bad management . xxmaj somehow they continue to occupy their positions , and xxmaj senior xxmaj management does n't do anything about it . \\\\ r \\n xxmaj the lowest level the xxmaj datacom team has been in years , all because of xxmaj james and xxmaj malerie 's arrogance and lack of ethics .\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([ dls.vocab[0][idx] for idx in batch[0][0,:] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the `Dataloaders` object for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataloaders\n",
    "torch.save(dls, STANDARD_THEME_META_PATH/f'data_standard_theme_meta.pkl')\n",
    "# dls = torch.load(STANDARD_THEME_META_PATH/f'data_standard_theme_meta.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure a forward or backwards run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwards = False\n",
    "m_suf = '_multitask' #'_cleaned'\n",
    "m_pre = 'bwd_' if (backwards) else 'fwd_'\n",
    "\n",
    "dls = torch.load(STANDARD_THEME_META_PATH/f'data_standard_theme_meta.pkl')\n",
    "\n",
    "def reverse_text(nums): return nums.flip(0)\n",
    "if (backwards): \n",
    "    dls.tfms.append(Transform(reverse_text))\n",
    "    dls.before_batch = partial(pad_input_chunk, pad_first=not backwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from /lm/models -> class/models (both fwd and bwd weights)\n",
    "! cp {LM_PATH/'models/*_lm_enc.pth'} {STANDARD_THEME_META_PATH/'models/'}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure MM head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MM(Module):\n",
    "    def __init__(self, in_features=50): \n",
    "        super().__init__()\n",
    "        self.pred_is_example = nn.Linear(in_features, 2, bias=False)\n",
    "        self.pred_avg_sentiment = nn.Linear(in_features, 1, bias=False)\n",
    "        self.pred_avg_sent_range = SigmoidRange(1., 5.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        is_example = self.pred_is_example(x)\n",
    "        avg_sentiment = self.pred_avg_sent_range(self.pred_avg_sentiment(x))\n",
    "        \n",
    "        return avg_sentiment, is_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 115.48148148148148]\n"
     ]
    }
   ],
   "source": [
    "is_example_weights = list(np.max(train_df.is_example.value_counts()) /train_df.is_example.value_counts())\n",
    "print(is_example_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metrics\n",
    "def sentiment_mse(preds, *targs):\n",
    "    return mse(preds[0], targs[0])\n",
    "\n",
    "def is_example_acc(preds, *targs):\n",
    "    return accuracy(preds[1], targs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "best_model_cb = SaveModelCallback(monitor='valid_loss', comp=np.less, fname=f'{m_pre}mm_bestmodel{m_suf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our custom multi-target loss\n",
    "multi_targ_loss = MultiTargetLoss(loss_classes=[MSELossFlat, CrossEntropyLossFlat],\n",
    "                                  loss_classes_kwargs=[{}, {'weight': FloatTensor(is_example_weights).to('cuda:1')}],\n",
    "                                  weights=[1, 0.1], \n",
    "                                  reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cbs = []\n",
    "fit_cbs = [best_model_cb]\n",
    "\n",
    "learn_metrics = [is_example_acc, sentiment_mse]\n",
    "\n",
    "# build learner\n",
    "learn = text_classifier_learner(dls, \n",
    "                                AWD_LSTM, \n",
    "                                pretrained=False,\n",
    "                                alpha=2.0, beta=1.0,      # default - alpha=2.0, beta=1.0\n",
    "                                moms=(0.8,0.7,0.8),       # default - (0.95, 0.85, 0.95)\n",
    "                                wd=wd,                    # default - None\n",
    "                                seq_len=bptt,             # default - 72\n",
    "                                drop_mult=0.5,            # default - 0.5\n",
    "                                lin_ftrs=[50],            # default - [50]\n",
    "                                ps=[0.1],                 # default - [0.1]\n",
    "                                metrics=learn_metrics, \n",
    "                                cbs=learn_cbs,\n",
    "                                n_out=1,\n",
    "                                path=STANDARD_THEME_META_PATH)\n",
    "\n",
    "learn.loss_func = multi_targ_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load_encoder(f'{m_pre}lm_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinBnDrop(\n",
       "  (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.1, inplace=False)\n",
       "  (2): Linear(in_features=50, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model._modules['1']._modules['layers']._modules['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model._modules['1']._modules['layers']._modules['1']._modules['2'] = MM(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model = learn.model.to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.splitter = awd_lstm_clas_split\n",
    "learn.opt = learn.create_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>is_example_acc</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SequentialRNN (Input shape: ['80 x 482'])\n",
       "================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "================================================================\n",
       "RNNDropout           80 x 50 x 400        0          False     \n",
       "________________________________________________________________\n",
       "RNNDropout           80 x 50 x 1152       0          False     \n",
       "________________________________________________________________\n",
       "RNNDropout           80 x 50 x 1152       0          False     \n",
       "________________________________________________________________\n",
       "BatchNorm1d          80 x 1200            2,400      True      \n",
       "________________________________________________________________\n",
       "Dropout              80 x 1200            0          False     \n",
       "________________________________________________________________\n",
       "Linear               80 x 50              60,000     True      \n",
       "________________________________________________________________\n",
       "ReLU                 80 x 50              0          False     \n",
       "________________________________________________________________\n",
       "BatchNorm1d          80 x 50              100        True      \n",
       "________________________________________________________________\n",
       "Dropout              80 x 50              0          False     \n",
       "________________________________________________________________\n",
       "Linear               80 x 2               100        True      \n",
       "________________________________________________________________\n",
       "Linear               80 x 1               50         True      \n",
       "________________________________________________________________\n",
       "SigmoidRange         80 x 1               0          False     \n",
       "________________________________________________________________\n",
       "\n",
       "Total params: 62,650\n",
       "Total trainable params: 62,650\n",
       "Total non-trainable params: 0\n",
       "\n",
       "Optimizer used: <function Adam at 0x7f1d31734680>\n",
       "Loss function: MultiTargetLoss()\n",
       "\n",
       "Model frozen up to parameter group #4\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback\n",
       "  - ModelResetter\n",
       "  - RNNRegularizer"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = STANDARD_THEME_META_PATH/f'models/{m_pre}mm_bestmodel{m_suf}*'\n",
    "if (best_model_path.exists()): best_model_path.unlink(missing_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr= 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.03019951581954956, lr_steep=1.5848931980144698e-06)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>is_example_acc</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.733456</td>\n",
       "      <td>0.526497</td>\n",
       "      <td>0.908484</td>\n",
       "      <td>0.482469</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.5264973640441895.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=lr, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('data/classification/standard_themes/meta/models/fwd_mm_last_ft_multitask.pth')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save(f'{m_pre}mm_last_ft{m_suf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>is_example_acc</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.612754</td>\n",
       "      <td>0.494718</td>\n",
       "      <td>0.909438</td>\n",
       "      <td>0.444064</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.4947182834148407.\n"
     ]
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, lr_max=slice(5e-2/(2.6**4), 5e-2), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('data/classification/standard_themes/meta/models/fwd_mm_last2_ft_multitask.pth')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save(f'{m_pre}mm_last2_ft{m_suf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>is_example_acc</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.485630</td>\n",
       "      <td>0.441041</td>\n",
       "      <td>0.959962</td>\n",
       "      <td>0.393227</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.44104138016700745.\n"
     ]
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, lr_max=slice(1e-2/(2.6**4),5e-3), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('data/classification/standard_themes/meta/models/fwd_mm_last3_ft_multitask.pth')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save(f'{m_pre}mm_last3_ft{m_suf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>is_example_acc</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.430081</td>\n",
       "      <td>0.436342</td>\n",
       "      <td>0.929457</td>\n",
       "      <td>0.390007</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.406086</td>\n",
       "      <td>0.426981</td>\n",
       "      <td>0.897998</td>\n",
       "      <td>0.380801</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.385023</td>\n",
       "      <td>0.454818</td>\n",
       "      <td>0.872259</td>\n",
       "      <td>0.407560</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.318625</td>\n",
       "      <td>0.454470</td>\n",
       "      <td>0.965682</td>\n",
       "      <td>0.397874</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.294054</td>\n",
       "      <td>0.464966</td>\n",
       "      <td>0.976168</td>\n",
       "      <td>0.387045</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.258420</td>\n",
       "      <td>0.462405</td>\n",
       "      <td>0.968541</td>\n",
       "      <td>0.397607</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.232994</td>\n",
       "      <td>0.481579</td>\n",
       "      <td>0.972355</td>\n",
       "      <td>0.397500</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.213427</td>\n",
       "      <td>0.497897</td>\n",
       "      <td>0.975214</td>\n",
       "      <td>0.407183</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.206671</td>\n",
       "      <td>0.511222</td>\n",
       "      <td>0.980934</td>\n",
       "      <td>0.406714</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.200293</td>\n",
       "      <td>0.503890</td>\n",
       "      <td>0.974261</td>\n",
       "      <td>0.406936</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.4363422691822052.\n",
      "Better model found at epoch 1 with valid_loss value: 0.4269811809062958.\n"
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, lr_max=slice(5e-3/(2.6**4),5e-3), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('data/classification/standard_themes/meta/models/fwd_mm_multitask.pth')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save(f'{m_pre}mm{m_suf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname=f'{m_pre}export_mm{m_suf}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load(f'{m_pre}mm_bestmodel{m_suf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#3) [0.4269811809062958,0.8979980945587158,0.38080084323883057]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate() # ... returns [loss, metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "      <th>category</th>\n",
       "      <th>text__</th>\n",
       "      <th>category_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxfld 1 xxmaj advancement and xxmaj training xxmaj opportunities xxfld 2 xxmaj insights as alumna / former student of xxup ucsd , working on main campus 3.5 + years , mexican - american female &amp; varied experience from start - up to non - profit to corporate : \\ r \\n 1 . xxmaj dept / culture : all</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>(2.162134885787964,)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos xxfld 1 xxmaj satisfied with xxmaj diversity xxmaj xxunk xxfld 2 xxmaj my work environment at xxup s. xxup i. xxup o. xxmaj directors office , has been very unsatisfactory . xxmaj when my former work director xxmaj gary xxmaj xxunk retired , xxmaj dennis xxmaj brand took over as my work director . xxmaj he did not seem</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>(2.069725513458252,)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos xxfld 1 xxmaj internal xxmaj processes xxmaj effective xxfld 2 xxmaj if you are under a xxmaj union xxmaj contract , i was told that my annual review does n't matter . i will receive my 3 % raise each year no matter what . xxmaj where is the incentive to go above and beyond ? xxmaj the departments</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>(2.7194347381591797,)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxbos xxfld 1 xxmaj have xxmaj voice within my xxmaj institution / xxmaj valued xxmaj member of my xxmaj institution xxfld 2 i am satisfied with my department but very dissatisfied with xxup anr at the state / headquarters level . xxmaj in my department , i have a voice , can influence small decisions and am recognized for my</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>(2.025029182434082,)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=4, trunc_at=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use it for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_learn = load_learner(STANDARD_THEME_META_PATH/f'{m_pre}export_mm{m_suf}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('xxbos i feel very uncomfortable talking to my supervisor even though she loves dogs . xxmaj help xxrep 3 !',\n",
       " ((2.1534781455993652), '1'),\n",
       " tensor([[2.1535]]),\n",
       " tensor([[2.1535]]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn.predict('I feel very uncomfortable talking to my supervisor even though she loves dogs. Help!!!', \n",
    "                  with_input=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review final validation loss for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avg_sentiment', 'is_example']\n"
     ]
    }
   ],
   "source": [
    "print(STANDARD_THEME_META_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load(f'{m_pre}mm_bestmodel{m_suf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#3) [0.4269811809062958,0.8979980945587158,0.38080084323883057]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.49097761511802673\n"
     ]
    }
   ],
   "source": [
    "probs, targs, loss = learn.get_preds(dl=dls.valid, with_loss=True)\n",
    "\n",
    "print(f'Validation Loss: {loss.mean()}')\n",
    "# print(f'Validation Loss (per label): {loss.mean(dim=0)}') # ... no longer works (see forum comment from sylvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7855]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8570]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.4427]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.0007]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.1403]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.8239]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.4053]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.8118]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.4978]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4700]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9128]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.3134]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.1398]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1975]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7298]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([2.7021]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.5804]) tensor(5.) tensor(1) tensor(0)\n",
      "tensor([2.5860]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8714]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7017]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.7657]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0300]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9544]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9245]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0877]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.9461]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1396]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0697]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([1.9066]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1419]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.1283]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0150]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.7453]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1631]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7943]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5889]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0158]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9632]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8606]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1001]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7011]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3643]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3012]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4984]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.7450]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([3.4809]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([4.0998]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1692]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.3436]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.5591]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2604]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([1.7663]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.5249]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.3291]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8727]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([1.8669]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1488]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4596]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0282]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2517]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.5045]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0158]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4240]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9688]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2200]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.5483]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1752]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9926]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8898]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.2338]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.1842]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4435]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0705]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.0128]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3124]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2779]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1221]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0163]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8110]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3079]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0099]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2759]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.8900]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2074]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0585]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8399]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9880]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5795]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3560]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7043]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.2208]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.6527]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([4.5230]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.8229]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([2.4894]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4216]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.5371]) tensor(3.5000) tensor(0) tensor(0)\n",
      "tensor([2.0863]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([3.2000]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9567]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4610]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1141]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2336]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0919]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1862]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3248]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.3865]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6082]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.9940]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4480]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8509]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1775]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.5687]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0450]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1119]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.4918]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4156]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0917]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9887]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8275]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1417]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1129]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4595]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0783]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9516]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6106]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.8282]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9516]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.7969]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3671]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([2.3231]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8607]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0623]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1985]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.1748]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.6842]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8568]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1834]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3942]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8709]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7983]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8254]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.4035]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4575]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7645]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0237]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0847]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9780]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.3103]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9649]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.3820]) tensor(4.) tensor(1) tensor(0)\n",
      "tensor([2.5754]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.3579]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.2964]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0000]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0949]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0356]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.0672]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([4.1249]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2032]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6733]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.3011]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.6559]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0599]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1157]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8110]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.5517]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([4.5521]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.5227]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.0278]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.4395]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([3.1536]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([1.7829]) tensor(1.5000) tensor(1) tensor(0)\n",
      "tensor([1.6311]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8099]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.8824]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2554]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4204]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3477]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3520]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4247]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0243]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.7217]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2373]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1896]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9698]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8991]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0652]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9510]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.5209]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.4339]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.0347]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([4.0570]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.2535]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9695]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3112]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0127]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9317]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.2713]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.6765]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([1.8262]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1586]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2878]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9800]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1033]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6282]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0788]) tensor(3.) tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9153]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9520]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2392]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4559]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9829]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7738]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.1746]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9718]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8980]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2898]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0442]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8237]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([1.6772]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0750]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.4497]) tensor(1.5000) tensor(1) tensor(0)\n",
      "tensor([3.1290]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3939]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.9126]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.7650]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.0897]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([1.8333]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9585]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7806]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6769]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2524]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2247]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3111]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([1.9107]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([3.6611]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0225]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8105]) tensor(4.) tensor(1) tensor(0)\n",
      "tensor([1.7388]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.2686]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9871]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.5075]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.1575]) tensor(5.) tensor(1) tensor(0)\n",
      "tensor([1.8881]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.6361]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2648]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3856]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([4.7147]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.2399]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0864]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9983]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9894]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0363]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1411]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.7569]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9549]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5658]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0694]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1809]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([1.8829]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.5863]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([4.6400]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.1531]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4890]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9979]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([2.2192]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9252]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3162]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.7889]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.3155]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4815]) tensor(4.) tensor(1) tensor(0)\n",
      "tensor([2.3880]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9058]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1860]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0178]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.0570]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0804]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1296]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9277]) tensor(2.) tensor(1) tensor(1)\n",
      "tensor([4.1003]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.7247]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.1624]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2777]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7235]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.9214]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([4.1525]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1608]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([1.9600]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.6502]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2654]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([3.8099]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.4267]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([2.1989]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1599]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9293]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3256]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1219]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.3293]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9296]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.6051]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([3.6246]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1508]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1704]) tensor(2.) tensor(0) tensor(1)\n",
      "tensor([1.9806]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3475]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9141]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0809]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0605]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.1090]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.1801]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([3.1476]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8210]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([2.2921]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4039]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0161]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0798]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9292]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.8919]) tensor(3.5000) tensor(0) tensor(0)\n",
      "tensor([3.4575]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.5384]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.5486]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0928]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([1.9054]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2676]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2554]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5193]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9192]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.5836]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.9012]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1513]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0740]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.1566]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1106]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4002]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3833]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1459]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.5017]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1480]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.7642]) tensor(1.) tensor(1) tensor(1)\n",
      "tensor([2.0968]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8325]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4619]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6541]) tensor(3.5000) tensor(0) tensor(0)\n",
      "tensor([3.9222]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1182]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.0263]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.9064]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.7519]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.9285]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2697]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([1.9180]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3279]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.5017]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([1.7627]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.0030]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.1467]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.0835]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1390]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9791]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1547]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.5656]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4521]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.6308]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.3569]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5205]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3038]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.3021]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.2120]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.0842]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.4857]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0015]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4237]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3535]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0526]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.2330]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.0087]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([3.1053]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9817]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.9072]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4116]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0016]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.0585]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0369]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.1981]) tensor(1.5000) tensor(1) tensor(0)\n",
      "tensor([2.4912]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0419]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0773]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9157]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3132]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3469]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4125]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1949]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2576]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4278]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8862]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.6506]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1163]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5746]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1800]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2016]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2581]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9400]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([4.1912]) tensor(1.) tensor(0) tensor(1)\n",
      "tensor([1.9424]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5803]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.5114]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.7819]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0928]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.0766]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.7607]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.0745]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1816]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2127]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0163]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9251]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4147]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0419]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.4349]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([1.9899]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7839]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.2230]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8060]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8450]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2026]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([1.9857]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4821]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9697]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9033]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.0255]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8729]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9008]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8758]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.4400]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6908]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5664]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.6790]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5025]) tensor(5.) tensor(1) tensor(0)\n",
      "tensor([2.3663]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9806]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9927]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2887]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0281]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8969]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9250]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0318]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.5399]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2997]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.7630]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0859]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.8814]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8590]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0627]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1290]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1621]) tensor(3.) tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1173]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.3668]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([1.9547]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1861]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0737]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([4.6645]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.9889]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0715]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6372]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2347]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3114]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.3449]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.5768]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.2603]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9922]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.2241]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2776]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7774]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9501]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0704]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([1.9076]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0995]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1035]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0297]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1824]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.7268]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.7851]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1309]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.0194]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0258]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5107]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([1.8948]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9463]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2571]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9397]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.6510]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([2.2817]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([1.5308]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([4.2231]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.0400]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0013]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3561]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6394]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0916]) tensor(1.5000) tensor(1) tensor(0)\n",
      "tensor([2.5662]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2200]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7524]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5714]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3315]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1171]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0328]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9904]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.3963]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.6311]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1938]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.0888]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3320]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9677]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1559]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.3812]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2550]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.6296]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2915]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0169]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.5006]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.8819]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([3.4315]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.9442]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.5339]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.8073]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.3807]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4650]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9410]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1264]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.4334]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.1596]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2693]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([1.9136]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.3067]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.5733]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.1768]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.2942]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.0051]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2769]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9468]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5381]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([1.9081]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0761]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2139]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([4.0694]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.9052]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9737]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([1.9617]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.0684]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8218]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.7566]) tensor(4.5000) tensor(0) tensor(0)\n",
      "tensor([2.0698]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3319]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0103]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9580]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.0763]) tensor(1.6667) tensor(0) tensor(0)\n",
      "tensor([2.5489]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1256]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5018]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.7104]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7053]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2558]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7589]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6814]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3348]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([2.2057]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8520]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0061]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([2.4433]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9221]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9771]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.1788]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2550]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.7191]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.0367]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.2429]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9860]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0478]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1367]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8128]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6349]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9557]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4804]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.2640]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2272]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.3546]) tensor(2.) tensor(0) tensor(1)\n",
      "tensor([1.9587]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2369]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3177]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0655]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6914]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8837]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3385]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8683]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2615]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.2384]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8734]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.4209]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4027]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.3551]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1484]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([3.0099]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9412]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2316]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0886]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9476]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.6187]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4040]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6526]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.5908]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0637]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9533]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8505]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7146]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0003]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1217]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.3070]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.7519]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0254]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7194]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0076]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3090]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0317]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8103]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8862]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0954]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6121]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1050]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6487]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9006]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9319]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0278]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.0948]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9918]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.7263]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.1576]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([4.4854]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.6773]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0260]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9631]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8515]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0577]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2975]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9600]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.7870]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1941]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0360]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2246]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4186]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1780]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9232]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5784]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2830]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.2003]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1146]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1977]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0895]) tensor(2.) tensor(1) tensor(1)\n",
      "tensor([2.1357]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3254]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4578]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2169]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3668]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2124]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9133]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1798]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.5342]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0307]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.2210]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.9328]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9312]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4017]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1683]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.4410]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2943]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9287]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7552]) tensor(1.5000) tensor(1) tensor(0)\n",
      "tensor([2.4401]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([4.2115]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.8819]) tensor(1.5000) tensor(1) tensor(0)\n",
      "tensor([1.9936]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2793]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9301]) tensor(1.5000) tensor(1) tensor(0)\n",
      "tensor([3.8696]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.9171]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9104]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([1.9115]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.9201]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1700]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9004]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6462]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.7453]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9736]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2227]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.3439]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1824]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1330]) tensor(2.) tensor(1) tensor(1)\n",
      "tensor([2.5654]) tensor(3.) tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5139]) tensor(4.5000) tensor(0) tensor(0)\n",
      "tensor([2.5406]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0587]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.7169]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.3372]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7880]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9271]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.0122]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8225]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1417]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.6945]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.3723]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1757]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.2910]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8355]) tensor(2.) tensor(1) tensor(1)\n",
      "tensor([2.0148]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8804]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9096]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([4.5670]) tensor(4.5000) tensor(0) tensor(0)\n",
      "tensor([2.6544]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1834]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.4811]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.9741]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2356]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8941]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.3094]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.3037]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3635]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4803]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0390]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.9113]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1185]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6502]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7750]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3444]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2558]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0443]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6054]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1688]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([1.9264]) tensor(1.5000) tensor(1) tensor(0)\n",
      "tensor([2.3842]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4989]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5627]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5084]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9611]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.3111]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1769]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([4.0408]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2248]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8895]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2168]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.5731]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.0657]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7059]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.7770]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.3641]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1838]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8677]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9008]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9043]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7609]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0109]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.6044]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2364]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1573]) tensor(4.) tensor(1) tensor(0)\n",
      "tensor([2.5977]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6521]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.5320]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0100]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3425]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0244]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8819]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9790]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.5213]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9336]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2794]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0728]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6309]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0243]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2011]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9519]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2781]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8313]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.8001]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.8141]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4113]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9946]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([1.9045]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8388]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8673]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1206]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0763]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.6187]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4472]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.6712]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([1.9278]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0221]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.2306]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.7440]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.3848]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([1.9490]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2610]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1993]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3155]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3736]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5338]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([3.0771]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.1919]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.8415]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9599]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3024]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9360]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4427]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1183]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1081]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5047]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0764]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.5769]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9842]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0380]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([1.5766]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.0120]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1255]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7306]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.1047]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1692]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.6352]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.4262]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.8011]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9395]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.5414]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9621]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0606]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0861]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1061]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5165]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([3.9927]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.2698]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0057]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1288]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1528]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0272]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.1006]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.8958]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.0696]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1233]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8350]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.3457]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([4.0489]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0129]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7836]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4584]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4125]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1184]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0566]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2781]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8686]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3792]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0439]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7419]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([4.1510]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2040]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4687]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([4.0609]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.3607]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.5515]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8337]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8383]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1762]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([1.8904]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9322]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9739]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6792]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5111]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2638]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9241]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([3.0213]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.6093]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2195]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([2.0518]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.4223]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([3.0288]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.2498]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9976]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.3050]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2277]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7646]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([2.5268]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.5108]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.9517]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8079]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1137]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0651]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.6780]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9646]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1854]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9725]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5577]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2162]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3607]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0018]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9041]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.2975]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.0946]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0345]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1168]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.2676]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9654]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0369]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0680]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.5786]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4434]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2809]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.5143]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4021]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8618]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.0977]) tensor(4.5000) tensor(0) tensor(0)\n",
      "tensor([2.5232]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1859]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8338]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([3.1596]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0080]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5957]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([2.1546]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.1250]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8990]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1355]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5189]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.4743]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1020]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2248]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9379]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([1.6287]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0856]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8541]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([2.8184]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9204]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.4399]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.0386]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([2.9381]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([1.7478]) tensor(2.) tensor(1) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1509]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4212]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.2080]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8694]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([3.4169]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8050]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9533]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.2561]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0870]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1012]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([1.9800]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1219]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.8601]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4244]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0962]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9321]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.7078]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.8285]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.5939]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([1.9637]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.6043]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.3801]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1061]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([3.5563]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2258]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8563]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.3676]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.1484]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9509]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1870]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7917]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0560]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3005]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8415]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([1.8235]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8812]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.0068]) tensor(3.) tensor(1) tensor(0)\n",
      "tensor([4.5443]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.6677]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9651]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6674]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.3119]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0711]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1638]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7442]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0497]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8898]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9932]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([4.3351]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.0957]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7989]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0172]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2058]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1797]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2420]) tensor(4.5000) tensor(0) tensor(0)\n",
      "tensor([2.0676]) tensor(1.5000) tensor(1) tensor(0)\n",
      "tensor([1.8543]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6742]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0116]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1801]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8510]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.6113]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.9323]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0250]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2621]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.5584]) tensor(4.5000) tensor(0) tensor(0)\n",
      "tensor([2.1872]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9784]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8613]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.5976]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9497]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([4.0975]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([3.7661]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9017]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.8936]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4995]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.7923]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.8579]) tensor(4.5000) tensor(1) tensor(0)\n",
      "tensor([1.7024]) tensor(2.) tensor(1) tensor(0)\n",
      "tensor([2.2447]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.1637]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0742]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2587]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0769]) tensor(1.) tensor(1) tensor(0)\n",
      "tensor([1.8134]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0112]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6022]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2124]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1374]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7729]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.0110]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1023]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4737]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8638]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0698]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9967]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8214]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9976]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9519]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8841]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.0966]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9812]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2214]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([4.5149]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.1731]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.5537]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1944]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0261]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3726]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.0838]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7602]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.7624]) tensor(3.) tensor(0) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for prob_sent, prob_example, targ_sent, targ_example in zip(*probs,*targs):\n",
    "    print(prob_sent, targ_sent, torch.argmax(prob_example, dim=-1), targ_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(((1.567490577697754), '1'), tensor([[1.5675]]), tensor([[1.5675]]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"No one cares. No one listens.  My supervisor doesn't follow ethical conduct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(((4.600057601928711), '0'), tensor([[4.6001]]), tensor([[4.6001]]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"plenty of parking available. found a spot every day I came to work. availability is solid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1049, 1]),\n",
       " torch.Size([1049, 2]),\n",
       " torch.Size([1049]),\n",
       " torch.Size([1049]),\n",
       " tensor(0.4910))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions for a single model using the learner's model and data loaders\n",
    "learn = learn.load(f'{m_pre}mm_bestmodel{m_suf}')\n",
    "learn.model.cuda(1)\n",
    "probs, targs, loss  = learn.get_preds(with_loss=True)\n",
    "\n",
    "probs[0].shape, probs[1].shape, targs[0].shape, targs[1].shape, loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_example_prob_true = torch.softmax(probs[1], dim=-1)[:,1]\n",
    "# is_example_prob_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "f05 = OptimalMultiThresholdMetrics(beta=0.5, start=0.05, end=.9, sigmoid=False, \n",
    "                                   average='binary', sample_weight=None)\n",
    "f1 = OptimalMultiThresholdMetrics(beta=1, start=0.05, end=.9, sigmoid=False, \n",
    "                                   average='binary', sample_weight=None)\n",
    "f2 = OptimalMultiThresholdMetrics(beta=2, start=0.05, end=.9, sigmoid=False, \n",
    "                                   average='binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6900000000000002, 0.5800000000000002, 0.5800000000000002)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_example_threshold_f05 = f05.opt_th(is_example_prob_true, targs[1])\n",
    "is_example_threshold_f1 = f1.opt_th(is_example_prob_true, targs[1])\n",
    "is_example_threshold_f2 = f2.opt_th(is_example_prob_true, targs[1])\n",
    "\n",
    "is_example_threshold_f05, is_example_threshold_f1, is_example_threshold_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14035087719298245"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = skm.fbeta_score(targs[1], (is_example_prob_true > is_example_threshold_f1), beta=1, average='binary')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9532888531684875"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = ((is_example_prob_true > is_example_threshold_f1).byte() == targs[1].byte()).float().mean()\n",
    "preds.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8979980945587158, 0.8979980945587158, 0.8979980945587158)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine accuracy based on optimal threshold\n",
    "is_example_val_acc_f05 = accuracy_multi(torch.argmax(probs[1], dim=-1), targs[1], is_example_threshold_f05, sigmoid=False).item()\n",
    "is_example_val_acc_f1 = accuracy_multi(torch.argmax(probs[1], dim=-1), targs[1], is_example_threshold_f1, sigmoid=False).item()\n",
    "is_example_val_acc_f2 = accuracy_multi(torch.argmax(probs[1], dim=-1), targs[1], is_example_threshold_f2, sigmoid=False).item()\n",
    "\n",
    "is_example_val_acc_f05, is_example_val_acc_f1, is_example_val_acc_f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review classifier - Is Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_targs = targs[1].flatten() # targs[:,0]\n",
    "eval_probs = is_example_prob_true.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1049]), torch.Size([1049]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_targs.shape, eval_probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Accuracy\n",
    "\n",
    "The percentage of correct predictions.  Answers the question, *\"Overall, how often is the classifier correct?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9532888465204957\n"
     ]
    }
   ],
   "source": [
    "print(skm.accuracy_score(eval_targs, (eval_probs > is_example_threshold_f1).float(), sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null Accuracy\n",
    " \n",
    "The accuracy achieved by always predicting the most frequent class.  Answers the question, *\"What would the accuracy be by always predicting the most frequent case?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1041\n"
     ]
    }
   ],
   "source": [
    "u_classes, u_counts = np.unique(eval_targs, return_counts=True)\n",
    "most_freq_class, most_freq_class_count = u_classes[np.argmax(u_counts)], np.max(u_counts)\n",
    "print(most_freq_class, most_freq_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923736892278361"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq_class_count / len(eval_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohen's kappa\n",
    "\n",
    "This measure is intended to compare labelings by different human annotators (not a classifier vs. ground truth)\n",
    "\n",
    "Kappa socres are between -1 and 1 ( >= .8 is generally considered good agreement; <= 0 means no agreement ... e.g., practically random labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12892948533274595\n"
     ]
    }
   ],
   "source": [
    "print(skm.cohen_kappa_score(eval_targs, (eval_probs > is_example_threshold_f1).float(), \n",
    "                            weights=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "Describes the performance of a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, \n",
    "                          title='Confusion matrix', cmap=plt.cm.Blues, print_info=False):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        if (print_info): print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        if (print_info): print('Confusion matrix, without normalization')\n",
    "\n",
    "    if (print_info): print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = skm.confusion_matrix(eval_targs, (eval_probs > is_example_threshold_f1).float(), sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_confusion_matrix(cm, classes=u_classes,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_confusion_matrix(cm, classes=u_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1041\n",
      "           1       0.08      0.50      0.14         8\n",
      "\n",
      "    accuracy                           0.95      1049\n",
      "   macro avg       0.54      0.73      0.56      1049\n",
      "weighted avg       0.99      0.95      0.97      1049\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/tritonlytics-ai/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[0, 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(skm.classification_report(eval_targs, (eval_probs > is_example_threshold_f1).float(), [0,1], \n",
    "                                sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw probability distribution\n",
    "\n",
    "Useful to see how the threshold can be adjusted to increase sensitivity or specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(eval_probs, bins=10)\n",
    "# plt.xlim(0,1)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability of IsVeryPositive')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curves and Area Under the Curve (AUC)\n",
    "\n",
    "***ROC Curve*** answers the question, *\"How would sensitivity and specificity be affected by various thresholds without changing the threshold?\"*  It is a way **to visualize the performance of a binary classifier.**\n",
    "\n",
    "The ROC curve can help you **choose a threshold** that balances sensitivity and specificity based on your particular business case.\n",
    "\n",
    "ROC curves visualize all possible classification thresholds whereas misclassification rate only represents your error rate for a single threshold.\n",
    "\n",
    "A classifier that does a good job at separating the classes will have a ROC curve that hugs the upper left corner of the plot.  Converseley, a classifier the does a poor job separating the classes will have a ROC curve that is close to the diagonal line (0,0 -> 1,1).  That diagonal line represents a classifier that does no better than random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = skm.roc_curve(eval_targs, eval_probs, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.xlim = ([0.0, 1.0])\n",
    "plt.ylim = ([0.0, 1.0])\n",
    "plt.title('ROC curve for all labels')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity/Recall)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***AUC*** = the percentage of the ROC plot that is underneath the curve.  \n",
    "\n",
    "AUC summarizes the performance of a classifier in a **single number**.  It says, *\"If you randomly chose one positive and one negative observation, what is the likelihood that your classifier will assign a higher predicted probability to the positive observation.\"*\n",
    "\n",
    "**An AUC of ~ 0.8 is very good while an AUC of ~ 0.5 represents a poor classifier.**\n",
    "\n",
    "The ROC curve and AUC are insensitive to whether your predicted probabilities are properly calibrated to actually represent probabilities of class membership (e.g., it works if predicted probs range from 0.9 to 1 instead of 0 to 1).  All the AUC metric cares about is how well your classifier separated the two classes\n",
    "\n",
    "Notes:\n",
    "1.  AUC is useful even when there is **high class imbalance** (unlike classification accuracy)\n",
    "2.  AUC is useful even when predicted probabilities are not properly calibrated (e.g., not between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8063160422670509\n"
     ]
    }
   ],
   "source": [
    "print(skm.roc_auc_score(eval_targs, eval_probs, average='weighted', sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review regression - Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3808008"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mse\n",
    "skm.mean_squared_error(targs[0], probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6170906039120254"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rmse\n",
    "math.sqrt(skm.mean_squared_error(targs[0], probs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42812845"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mae\n",
    "skm.mean_absolute_error(targs[0], probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Ensemble forwards and backwards passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    learn_fwd.purge(); learn = None;\n",
    "    learn_bwd.purge(); learn_bwd = None;\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "except: pass\n",
    "\n",
    "bsz = 80\n",
    "m_suf = '_multitask'\n",
    "\n",
    "dls = torch.load(STANDARD_THEME_META_PATH/f'data_standard_theme_meta.pkl')\n",
    "\n",
    "learn_fwd = load_learner(fname=STANDARD_THEME_META_PATH/f'fwd_export_mm{m_suf}.pkl')\n",
    "learn_fwd.dls = dls\n",
    "learn_bwd = load_learner(fname=STANDARD_THEME_META_PATH/f'bwd_export_mm{m_suf}.pkl')\n",
    "learn_bwd.dls = dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn_fwd.loss_func = multi_targ_loss\n",
    "learn_bwd.loss_func = multi_targ_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "probs_fwd, lbl_fwd, loss_fwd = learn_fwd.get_preds(with_loss=True, reorder=True)\n",
    "probs_bwd, lbl_bwd, loss_bwd = learn_bwd.get_preds(with_loss=True, reorder=True)\n",
    "\n",
    "probs_fwd[0].shape, probs_bwd[0].shape, loss_fwd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_fwd.mean(), loss_bwd.mean(), (loss_fwd.mean() + loss_bwd.mean()) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "probs_final_sent = (probs_fwd[0] + probs_bwd[0]) / 2\n",
    "probs_final_is_example = (probs_fwd[1] + probs_bwd[1]) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "f05 = OptimalMultiThresholdMetrics(beta=0.5, start=0.05, end=.9, sigmoid=False, \n",
    "                                   average='binary', sample_weight=None)\n",
    "f1 = OptimalMultiThresholdMetrics(beta=1, start=0.05, end=.9, sigmoid=False, \n",
    "                                   average='binary', sample_weight=None)\n",
    "f2 = OptimalMultiThresholdMetrics(beta=2, start=0.05, end=.9, sigmoid=False, \n",
    "                                   average='binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_example_prob_true_fwd = torch.softmax(probs_fwd[1], dim=-1)[:,1]\n",
    "is_example_prob_true_bwd = torch.softmax(probs_bwd[1], dim=-1)[:,1]\n",
    "is_example_prob_true_ensemble = torch.softmax(probs_final_is_example, dim=-1)[:,1]\n",
    "\n",
    "# is_example_prob_true_fwd, is_example_prob_true_bwd, is_example_prob_true_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "is_example_threshold_f05 = f05.opt_th(is_example_prob_true_fwd, lbl_fwd[1])\n",
    "is_example_threshold_f1 = f1.opt_th(is_example_prob_true_fwd, lbl_fwd[1])\n",
    "is_example_threshold_f2 = f2.opt_th(is_example_prob_true_fwd, lbl_fwd[1])\n",
    "\n",
    "is_example_threshold_f05, is_example_threshold_f1, is_example_threshold_f2\n",
    "\n",
    "# determine accuracy based on optimal threshold\n",
    "val_acc_f05 = accuracy_multi(is_example_prob_true_fwd, lbl_fwd[1], is_example_threshold_f05, sigmoid=False).item()\n",
    "val_acc_f1 = accuracy_multi(is_example_prob_true_fwd, lbl_fwd[1], is_example_threshold_f1, sigmoid=False).item()\n",
    "val_acc_f2 = accuracy_multi(is_example_prob_true_fwd, lbl_fwd[1], is_example_threshold_f2, sigmoid=False).item()\n",
    "\n",
    "print('Fowards Only\\n-------------')\n",
    "print(f'f05:\\tOptimal threshold = {is_example_threshold_f05}\\t(Accuracy = {val_acc_f05})')\n",
    "print(f'f1:\\tOptimal threshold = {is_example_threshold_f1}\\t(Accuracy = {val_acc_f1})')\n",
    "print(f'f2:\\tOptimal threshold = {is_example_threshold_f2}\\t(Accuracy = {val_acc_f2})')\n",
    "\n",
    "print(f'\\nAccuracy: {skm.accuracy_score(lbl_fwd[1], (is_example_prob_true_fwd > is_example_threshold_f1).float())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "is_example_threshold_f05 = f05.opt_th(is_example_prob_true_bwd, lbl_fwd[1])\n",
    "is_example_threshold_f1 = f1.opt_th(is_example_prob_true_bwd, lbl_fwd[1])\n",
    "is_example_threshold_f2 = f2.opt_th(is_example_prob_true_bwd, lbl_fwd[1])\n",
    "\n",
    "is_example_threshold_f05, is_example_threshold_f1, is_example_threshold_f2\n",
    "\n",
    "# determine accuracy based on optimal threshold\n",
    "val_acc_f05 = accuracy_multi(is_example_prob_true_bwd, lbl_fwd[1], is_example_threshold_f05, sigmoid=False).item()\n",
    "val_acc_f1 = accuracy_multi(is_example_prob_true_bwd, lbl_fwd[1], is_example_threshold_f1, sigmoid=False).item()\n",
    "val_acc_f2 = accuracy_multi(is_example_prob_true_bwd, lbl_fwd[1], is_example_threshold_f2, sigmoid=False).item()\n",
    "\n",
    "print('Backwards Only\\n-------------')\n",
    "print(f'f05:\\tOptimal threshold = {is_example_threshold_f05}\\t(Accuracy = {val_acc_f05})')\n",
    "print(f'f1:\\tOptimal threshold = {is_example_threshold_f1}\\t(Accuracy = {val_acc_f1})')\n",
    "print(f'f2:\\tOptimal threshold = {is_example_threshold_f2}\\t(Accuracy = {val_acc_f2})')\n",
    "\n",
    "print(f'\\nAccuracy: {skm.accuracy_score(lbl_fwd[1], (is_example_prob_true_bwd > is_example_threshold_f1).float())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "is_example_threshold_f05 = f05.opt_th(is_example_prob_true_ensemble, lbl_fwd[1])\n",
    "is_example_threshold_f1 = f1.opt_th(is_example_prob_true_ensemble, lbl_fwd[1])\n",
    "is_example_threshold_f2 = f2.opt_th(is_example_prob_true_ensemble, lbl_fwd[1])\n",
    "\n",
    "is_example_threshold_f05, is_example_threshold_f1, is_example_threshold_f2\n",
    "\n",
    "# determine accuracy based on optimal threshold\n",
    "val_acc_f05 = accuracy_multi(is_example_prob_true_ensemble, lbl_fwd[1], is_example_threshold_f05, sigmoid=False).item()\n",
    "val_acc_f1 = accuracy_multi(is_example_prob_true_ensemble, lbl_fwd[1], is_example_threshold_f1, sigmoid=False).item()\n",
    "val_acc_f2 = accuracy_multi(is_example_prob_true_ensemble, lbl_fwd[1], is_example_threshold_f2, sigmoid=False).item()\n",
    "\n",
    "print('Ensemble Only\\n-------------')\n",
    "print(f'f05:\\tOptimal threshold = {is_example_threshold_f05}\\t(Accuracy = {val_acc_f05})')\n",
    "print(f'f1:\\tOptimal threshold = {is_example_threshold_f1}\\t(Accuracy = {val_acc_f1})')\n",
    "print(f'f2:\\tOptimal threshold = {is_example_threshold_f2}\\t(Accuracy = {val_acc_f2})')\n",
    "\n",
    "print(f'\\nAccuracy: {skm.accuracy_score(lbl_fwd[1], (is_example_prob_true_ensemble > is_example_threshold_f1).float())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sentiment metrics\n",
    "sentiment_mae = skm.mean_absolute_error(lbl_fwd[0], probs_final_sent)\n",
    "sentiment_mse = skm.mean_squared_error(lbl_fwd[0], probs_final_sent)\n",
    "sentiment_rmse = math.sqrt(skm.mean_squared_error(lbl_fwd[0], probs_final_sent))\n",
    "\n",
    "print(sentiment_mae, sentiment_mse, sentiment_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_valid_loss = (loss_fwd.mean() + loss_bwd.mean()) / 2; final_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "float(sentiment_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save this information to be added to inference returned data\n",
    "model_results = {\n",
    "    'is_example_threshold_f05': is_example_threshold_f05,\n",
    "    'is_example_threshold_f1': is_example_threshold_f1,\n",
    "    'is_example_threshold_f2': is_example_threshold_f2,\n",
    "    \n",
    "    'val_acc_f05': val_acc_f05,\n",
    "    'val_acc_f1': val_acc_f1,\n",
    "    'val_acc_f2': val_acc_f2,\n",
    "    \n",
    "    'sentiment_mae': float(sentiment_mae),\n",
    "    'sentiment_mse': float(sentiment_mse),\n",
    "    'sentiment_rmse': float(sentiment_rmse),\n",
    "    \n",
    "    'final_valid_loss': final_valid_loss.item()\n",
    "}\n",
    "\n",
    "with open(STANDARD_THEME_META_PATH/'model_results.json', 'w') as f: json.dump(model_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Inference (ad-hoc documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(STANDARD_THEME_META_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_comments = [\n",
    "    'The parking situation REALLY sucks around here.  It needs to be fixed',\n",
    "    'I LOVE working at UCSD!!!  It is wonderful',\n",
    "    \"\"\"Some staff are just uninformed.There is no support for solo-individual study (no closed off rooms).\n",
    "        Once a guy (quite tall) walked in into the girl's restroom and used the stalls standing up. \n",
    "        There was no line in the guy's restroom. This happened when I done and was going to walk out. \n",
    "        I was extremely uncomfortable\"\"\",\n",
    "    \"I love UCSD!!! It is a terrible place to work!\",\n",
    "    \"I was really uncomfortable to express my opinion!!!\"\n",
    "]\n",
    "\n",
    "for c in test_comments: print(learn_fwd.predict(c, with_input=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Inference (batch ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "yyyymmdd = datetime.date.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "m_suf = '_multitask'\n",
    "\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "verbatims_df = pd.read_csv(STANDARD_THEME_SAW_PATH/'20200511_ensemble_predictions_multilabel.csv', \n",
    "                           dtype={**TASK_LM_DTYPES}, parse_dates=[])\n",
    "\n",
    "inf_df = verbatims_df.copy() #verbatims_df[test_df.SurveyID == 130].copy()\n",
    "inf_df.reset_index(drop=True, inplace=True)\n",
    "print(len(verbatims_df))\n",
    "\n",
    "corpus_cols = ['theme', 'AnswerText'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inf_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_theme_cols = filter_col = [col for col in inf_df if col.startswith('prob_')]\n",
    "# pred_theme_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inf_df = inf_df.melt(id_vars=list(TASK_LM_DTYPES.keys()) + ['threshold_f05', 'threshold_f1', 'threshold_f2', 'val_acc_f05', 'val_acc_f1', 'val_acc_f2', 'val_loss'], \n",
    "                     value_vars=pred_theme_cols, \n",
    "                     var_name='theme', \n",
    "                     value_name='theme_prob')\n",
    "len(inf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inf_df = inf_df.loc[inf_df.theme_prob >= inf_df.threshold_f2]\n",
    "len(inf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inf_df['url_friendly_theme'] = inf_df.theme.apply(\n",
    "    lambda s: re.sub(\"(.*?)_([a-zA-Z])\",\"\\g<1> \\g<2>\",s).replace('prob', '').strip().title().replace(' ',''))\n",
    "\n",
    "inf_df['theme'] = inf_df.url_friendly_theme.apply(lambda s: re.sub(\"([a-z])([A-Z])\",\"\\g<1> \\g<2>\",s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inf_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model_results(backwards:bool=False, m_suf:str='multilabel'):\n",
    "    \n",
    "    model_prefix = 'bwd' if backwards else 'fwd'\n",
    "    \n",
    "    # 1. grab learner, procs, and data\n",
    "    inf_learn = load_learner(fname=STANDARD_THEME_META_PATH/f'{model_prefix}_export_mm_{m_suf}.pkl', cpu=False)\n",
    "    inf_learn.model = inf_learn.model.to(device)\n",
    "    inf_learn.model = inf_learn.model.eval()\n",
    "    \n",
    "    # 2. define a suitable dataloader\n",
    "    tok_inf_df, tok_counts = tokenize_df(inf_df, corpus_cols)\n",
    "    inf_dl = inf_learn.dls.test_dl(tok_inf_df, rm_type_tfms=None, bs=128)\n",
    "    if (backwards): inf_dl.tfms.add(Transform(lambda nums: nums.flip(0)))\n",
    "\n",
    "    # 3. get probs\n",
    "    test_probs_sent, test_probs_is_example = [], []\n",
    "    with torch.no_grad():\n",
    "        for index, b in enumerate(inf_dl):\n",
    "            if index % 1000 == 0:  print(index)\n",
    "\n",
    "            # reset hidden state (if you don't do this you will OOM)\n",
    "            inf_learn.model.reset()\n",
    "            \n",
    "            # note: even though there is no targets, each batch is a tuple!\n",
    "            probs, raw_outputs, outputs = inf_learn.model(b[0])\n",
    "            \n",
    "            # why \"detach\"? the computation of gradients wrt the weights of netG can be fully \n",
    "            # avoided in the backward pass if the graph is detached where it is.\n",
    "            test_probs_sent.append(to_detach(probs[0]))\n",
    "            test_probs_is_example.append(to_detach(probs[1]))\n",
    "\n",
    "    all_probs_sent = L(torch.cat(test_probs_sent))\n",
    "    all_probs_is_example = L(torch.cat(test_probs_is_example))\n",
    "\n",
    "    # 4. ensure results are returned in order\n",
    "    # test_dl.get_idxs() => unsorted/original order items\n",
    "    all_probs_sent = all_probs_sent[0][np.argsort(inf_dl.get_idxs())]\n",
    "    all_probs_is_example = all_probs_is_example[0][np.argsort(inf_dl.get_idxs())]\n",
    "\n",
    "    # 5. return ordered results\n",
    "    inf_learn, inf_data = None, None; gc.collect()\n",
    "    \n",
    "    return all_probs_sent, all_probs_is_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "probs_fwd_sent, probs_fwd_is_example = get_model_results(backwards=False, m_suf='multitask')\n",
    "probs_bwd_sent, probs_bwd_is_example = get_model_results(backwards=True, m_suf='multitask')\n",
    "\n",
    "probs_final_sent = (probs_fwd_sent + probs_bwd_sent) / 2\n",
    "probs_final_is_example = torch.softmax((probs_fwd_is_example + probs_bwd_is_example) / 2, dim=-1)[:,1]\n",
    "\n",
    "# probs_final = torch.sigmoid((probs_fwd + probs_bwd) / 2)\n",
    "\n",
    "print(probs_final_sent.shape)\n",
    "print(probs_final_sent[:5])\n",
    "print(probs_final_is_example.shape)\n",
    "print(probs_final_is_example[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add the probabilities of each label to `inf_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.concatenate((probs_final_sent.numpy(), probs_final_is_example.numpy()[:,None]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined_probs = np.concatenate((probs_final_sent.numpy(), probs_final_is_example.numpy()[:,None]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob_labels = ['prob_' + lbl for lbl in STANDARD_THEME_META_LABELS]\n",
    "probs_df = pd.DataFrame(combined_probs, columns=prob_labels)\n",
    "probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test_df_filtered.update(probs_df)\n",
    "final_df = pd.concat([inf_df, probs_df], axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add in predictions based on f1 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for lbl in STANDARD_THEME_META_LABELS[1:]:\n",
    "    final_df[f'pred_{lbl}'] = (final_df[f'prob_{lbl}'] > is_example_threshold_f1).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Include found thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_df['is_example_threshold_f05'] = is_example_threshold_f05\n",
    "final_df['is_example_threshold_f1'] = is_example_threshold_f1\n",
    "final_df['is_example_threshold_f2'] = is_example_threshold_f2\n",
    "\n",
    "final_df['is_example_val_acc_f05'] = val_acc_f05\n",
    "final_df['is_example_val_acc_f1'] = val_acc_f1\n",
    "final_df['is_example_val_acc_f2'] = val_acc_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_df['sentiment_mae'] = sentiment_mae.item()\n",
    "final_df['sentiment_mse'] = sentiment_mse.item()\n",
    "final_df['sentiment_rmse'] = sentiment_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_df['val_loss_metadata'] = final_valid_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "final_df.to_csv(STANDARD_THEME_META_PATH/f'{yyyymmdd}_ensemble_predictions{m_suf}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(final_df[final_df.Id == 589305].AnswerText.values[0])\n",
    "final_df[final_df.Id == 589305]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(final_df.iloc[0].is_example_threshold_f05)\n",
    "print(final_df.iloc[0].is_example_threshold_f1)\n",
    "print(final_df.iloc[0].is_example_threshold_f2)\n",
    "print(final_df.prob_avg_sentiment.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(learn.opt.param_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[ print(f'{lg}\\n') for lg in learn.opt.param_groups ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "losses = np.array([1,2,3,4,5,6,7,8,9,10]); losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(losses[:5].mean() + losses[5:].mean()) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "468px",
    "left": "1307px",
    "right": "20px",
    "top": "120px",
    "width": "353px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
