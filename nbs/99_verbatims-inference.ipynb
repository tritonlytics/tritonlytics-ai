{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference\n",
    "\n",
    "> All inference related methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import datetime, warnings, gc\n",
    "from inspect import signature\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "from fastai2.text.all import *\n",
    "\n",
    "from tritonlytics_ai.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def concat_pool(raw_outputs):\n",
    "    last_rnn_layer = raw_outputs[:,-1,None] # (e.g. (bs,n_hid,emb_sz) => (bs,1,emb_sz)) \n",
    "    bsz = last_rnn_layer.shape[0] \n",
    "    \n",
    "    avg_pool = F.adaptive_avg_pool1d(last_rnn_layer.permute(0,2,1), 1).view(bsz, -1)\n",
    "    max_pool = F.adaptive_max_pool1d(last_rnn_layer.permute(0,2,1), 1).view(bsz, -1)\n",
    "    last_outp = last_rnn_layer[:,-1,:]\n",
    "\n",
    "    return torch.cat([last_outp, max_pool, avg_pool], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_verbatims_ulmfit_sentiment_preds(inf_df,\n",
    "                                          learn_exports_fpath=SENTIMENT_CLS_PATH, \n",
    "                                          m_suf='multilabel', \n",
    "                                          backwards=False,\n",
    "                                          corpus_cols=['answer_text'], \n",
    "                                          device=torch.device('cpu')):\n",
    "    \n",
    "    model_prefix = 'bwd' if backwards else 'fwd'\n",
    "    \n",
    "    # 1. grab learner, procs, and data\n",
    "    inf_learn = load_learner(fname=learn_exports_fpath/f'{model_prefix}_export_clas_{m_suf}.pkl', cpu=False)\n",
    "    inf_learn.model = inf_learn.model.to(device)\n",
    "    inf_learn.model = inf_learn.model.eval()\n",
    "    \n",
    "    # 2. define a suitable dataloader\n",
    "    tok_inf_df, tok_counts = tokenize_df(inf_df, corpus_cols)\n",
    "    inf_dl = inf_learn.dls.test_dl(tok_inf_df, rm_type_tfms=None, bs=128)\n",
    "    if (backwards): inf_dl.tfms.add(Transform(lambda nums: nums.flip(0)))\n",
    "\n",
    "    # 3. get probs and document vectors\n",
    "    test_probs, doc_vecs, concat_doc_vecs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for index, b in enumerate(inf_dl):\n",
    "            if index % 1000 == 0:  pass #print(index)\n",
    "\n",
    "            # reset hidden state (if you don't do this you will OOM)\n",
    "            inf_learn.model.reset()\n",
    "            \n",
    "            # note: even though there is no targets, each batch is a tuple!\n",
    "            probs, raw_outputs, outputs = inf_learn.model(b[0])\n",
    "            \n",
    "            # why \"detach\"? the computation of gradients wrt the weights of netG can be fully \n",
    "            # avoided in the backward pass if the graph is detached where it is.\n",
    "            test_probs.append(to_detach(probs))\n",
    "            doc_vecs.append(to_detach(raw_outputs[:,-1,:]))\n",
    "            concat_doc_vecs.append(to_detach(concat_pool(raw_outputs)))\n",
    "\n",
    "    all_probs = L(torch.cat(test_probs))\n",
    "    all_vecs = L(torch.cat(doc_vecs))\n",
    "    all_concat_vecs = L(torch.cat(concat_doc_vecs))\n",
    "\n",
    "    # 4. ensure results are returned in order\n",
    "    # test_dl.get_idxs() => unsorted/original order items\n",
    "    all_probs = all_probs[0][np.argsort(inf_dl.get_idxs())]\n",
    "    all_vecs = all_vecs[0][np.argsort(inf_dl.get_idxs())]\n",
    "    all_concat_vecs = all_concat_vecs[0][np.argsort(inf_dl.get_idxs())]\n",
    "        \n",
    "    # 5. return ordered results\n",
    "    inf_learn, inf_data = None, None; gc.collect()\n",
    "    \n",
    "    return all_probs, all_vecs, all_concat_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_verbatims_ulmfit_standard_themes_saw(inf_df,\n",
    "                                              learn_exports_fpath=STANDARD_THEME_SAW_PATH, \n",
    "                                              m_suf='multilabel', \n",
    "                                              backwards=False,\n",
    "                                              corpus_cols=['answer_text'], \n",
    "                                              device=torch.device('cpu')):\n",
    "    \n",
    "    model_prefix = 'bwd' if backwards else 'fwd'\n",
    "    \n",
    "    # 1. grab learner, procs, and data\n",
    "    inf_learn = load_learner(fname=learn_exports_fpath/f'{model_prefix}_export_clas_{m_suf}.pkl', cpu=False)\n",
    "    inf_learn.model = inf_learn.model.to(device)\n",
    "    inf_learn.model = inf_learn.model.eval()\n",
    "    \n",
    "    # 2. define a suitable dataloader\n",
    "    tok_inf_df, tok_counts = tokenize_df(inf_df, corpus_cols)\n",
    "    inf_dl = inf_learn.dls.test_dl(tok_inf_df, rm_type_tfms=None, bs=128)\n",
    "    if (backwards): inf_dl.tfms.add(Transform(lambda nums: nums.flip(0)))\n",
    "\n",
    "    # 3. get probs and document vectors\n",
    "    test_probs, doc_vecs, concat_doc_vecs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for index, b in enumerate(inf_dl):\n",
    "            if index % 1000 == 0: pass #print(index)\n",
    "\n",
    "            # reset hidden state (if you don't do this you will OOM)\n",
    "            inf_learn.model.reset()\n",
    "            \n",
    "            # note: even though there is no targets, each batch is a tuple!\n",
    "            probs, raw_outputs, outputs = inf_learn.model(b[0])\n",
    "            \n",
    "            # why \"detach\"? the computation of gradients wrt the weights of netG can be fully \n",
    "            # avoided in the backward pass if the graph is detached where it is.\n",
    "            test_probs.append(to_detach(probs))\n",
    "            doc_vecs.append(to_detach(raw_outputs[:,-1,:]))\n",
    "            concat_doc_vecs.append(to_detach(concat_pool(raw_outputs)))\n",
    "\n",
    "    all_probs = L(torch.cat(test_probs))\n",
    "    all_vecs = L(torch.cat(doc_vecs))\n",
    "    all_concat_vecs = L(torch.cat(concat_doc_vecs))\n",
    "\n",
    "    # 4. ensure results are returned in order\n",
    "    # test_dl.get_idxs() => unsorted/original order items\n",
    "    all_probs = all_probs[0][np.argsort(inf_dl.get_idxs())]\n",
    "    all_vecs = all_vecs[0][np.argsort(inf_dl.get_idxs())]\n",
    "    all_concat_vecs = all_concat_vecs[0][np.argsort(inf_dl.get_idxs())]\n",
    "        \n",
    "    # 5. return ordered results\n",
    "    inf_learn, inf_data = None, None; gc.collect()\n",
    "    \n",
    "    return all_probs, all_vecs, all_concat_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# our multi-modal module for standard themes meta preds\n",
    "class MM(Module):\n",
    "    def __init__(self, in_features=50): \n",
    "        super().__init__()\n",
    "        self.pred_is_example = nn.Linear(in_features, 2, bias=False)\n",
    "        self.pred_avg_sentiment = nn.Linear(in_features, 1, bias=False)\n",
    "        self.pred_avg_sent_range = SigmoidRange(1., 5.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        is_example = self.pred_is_example(x)\n",
    "        avg_sentiment = self.pred_avg_sent_range(self.pred_avg_sentiment(x))\n",
    "        \n",
    "        return avg_sentiment, is_example\n",
    "    \n",
    "# \"load_learner\" requires our custom metrics used in training be present here\n",
    "def sentiment_mse(preds, *targs): return mse(preds[0], targs[0])\n",
    "def is_example_acc(preds, *targs): return accuracy(preds[1], targs[1])\n",
    "\n",
    "\n",
    "def _get_verbatims_ulmfit_standard_themes_meta(inf_df,\n",
    "                                               learn_exports_fpath=STANDARD_THEME_META_PATH, \n",
    "                                               m_suf='multitask', \n",
    "                                               backwards=False,\n",
    "                                               corpus_cols=['theme', 'answer_text'], \n",
    "                                               device=torch.device('cpu')):\n",
    "    \n",
    "    model_prefix = 'bwd' if backwards else 'fwd'\n",
    "    \n",
    "    # 1. grab learner, procs, and data\n",
    "    inf_learn = load_learner(fname=learn_exports_fpath/f'{model_prefix}_export_mm_{m_suf}.pkl', cpu=False)\n",
    "    inf_learn.model = inf_learn.model.to(device)\n",
    "    inf_learn.model = inf_learn.model.eval()\n",
    "    \n",
    "    # 2. define a suitable dataloader\n",
    "    tok_inf_df, tok_counts = tokenize_df(inf_df, corpus_cols)\n",
    "    inf_dl = inf_learn.dls.test_dl(tok_inf_df, rm_type_tfms=None, bs=128)\n",
    "    if (backwards): inf_dl.tfms.add(Transform(lambda nums: nums.flip(0)))\n",
    "\n",
    "    # 3. get probs\n",
    "    test_probs_sent, test_probs_is_example = [], []\n",
    "    with torch.no_grad():\n",
    "        for index, b in enumerate(inf_dl):\n",
    "            if index % 1000 == 0: pass #print(index)\n",
    "\n",
    "            # reset hidden state (if you don't do this you will OOM)\n",
    "            inf_learn.model.reset()\n",
    "            \n",
    "            # note: even though there is no targets, each batch is a tuple!\n",
    "            probs, raw_outputs, outputs = inf_learn.model(b[0])\n",
    "            \n",
    "            # why \"detach\"? the computation of gradients wrt the weights of netG can be fully \n",
    "            # avoided in the backward pass if the graph is detached where it is.\n",
    "            test_probs_sent.append(to_detach(probs[0]))\n",
    "            test_probs_is_example.append(to_detach(probs[1]))\n",
    "\n",
    "    all_probs_sent = L(torch.cat(test_probs_sent))\n",
    "    all_probs_is_example = L(torch.cat(test_probs_is_example))\n",
    "\n",
    "    # 4. ensure results are returned in order\n",
    "    # test_dl.get_idxs() => unsorted/original order items\n",
    "    all_probs_sent = all_probs_sent[0][np.argsort(inf_dl.get_idxs())]\n",
    "    all_probs_is_example = all_probs_is_example[0][np.argsort(inf_dl.get_idxs())]\n",
    "\n",
    "    # 5. return ordered results\n",
    "    inf_learn, inf_data = None, None; gc.collect()\n",
    "    \n",
    "    return all_probs_sent, all_probs_is_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Inference methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_sentiment_preds(inf_df, learn_exports_fpath=SENTIMENT_CLS_PATH, m_suf='multilabel',\n",
    "                        corpus_cols=['answer_text'], \n",
    "                        with_doc_vecs=True,\n",
    "                        device=torch.device('cpu')):\n",
    "    \n",
    "    # ensemble forward and backwards models\n",
    "    probs_fwd, vecs_fwd, concat_vecs_fwd = _get_verbatims_ulmfit_sentiment_preds(inf_df,\n",
    "                                                                                 learn_exports_fpath,\n",
    "                                                                                 m_suf=m_suf,\n",
    "                                                                                 backwards=False,\n",
    "                                                                                 corpus_cols=corpus_cols,\n",
    "                                                                                 device=device)\n",
    "    \n",
    "    probs_bwd, vecs_bwd, concat_vecs_bwd = _get_verbatims_ulmfit_sentiment_preds(inf_df,\n",
    "                                                                                 learn_exports_fpath,\n",
    "                                                                                 m_suf=m_suf,\n",
    "                                                                                 backwards=True,\n",
    "                                                                                 corpus_cols=corpus_cols,\n",
    "                                                                                 device=device)\n",
    "\n",
    "    probs_final = torch.sigmoid((probs_fwd + probs_bwd) / 2)\n",
    "\n",
    "    # grab the probabilities of each sentiment label; concatentate to input\n",
    "    prob_labels = ['prob_' + lbl for lbl in SENT_LABELS[1:]]\n",
    "    probs_df = pd.DataFrame(probs_final.numpy(), columns=prob_labels)\n",
    "    \n",
    "    final_df = pd.concat([inf_df, probs_df], axis=1)\n",
    "    \n",
    "    if (not with_doc_vecs): return final_df\n",
    "    return final_df, vecs_fwd, vecs_bwd, concat_vecs_fwd, concat_vecs_bwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_standard_theme_saw_preds(inf_df, learn_exports_fpath=STANDARD_THEME_SAW_PATH, m_suf='multilabel',\n",
    "                                 corpus_cols=['answer_text'],\n",
    "                                 with_doc_vecs=True,\n",
    "                                 device=torch.device('cpu')):\n",
    "    \n",
    "    # ensemble forward and backwards models\n",
    "    probs_fwd, vecs_fwd, concat_vecs_fwd = _get_verbatims_ulmfit_standard_themes_saw(inf_df,\n",
    "                                                                                     learn_exports_fpath,\n",
    "                                                                                     m_suf=m_suf,\n",
    "                                                                                     backwards=False,\n",
    "                                                                                     corpus_cols=corpus_cols,\n",
    "                                                                                     device=device)\n",
    "    \n",
    "    probs_bwd, vecs_bwd, concat_vecs_bwd = _get_verbatims_ulmfit_standard_themes_saw(inf_df,\n",
    "                                                                                     learn_exports_fpath,\n",
    "                                                                                     m_suf=m_suf,\n",
    "                                                                                     backwards=True,\n",
    "                                                                                     corpus_cols=corpus_cols,\n",
    "                                                                                     device=device)\n",
    "\n",
    "    probs_final = torch.sigmoid((probs_fwd + probs_bwd) / 2)\n",
    "\n",
    "    # grab the probabilities of each sentiment label; concatentate to input\n",
    "    prob_labels = ['prob_' + lbl for lbl in STANDARD_THEME_SAW_LABELS]\n",
    "    probs_df = pd.DataFrame(probs_final.numpy(), columns=prob_labels)\n",
    "    \n",
    "    final_df = pd.concat([inf_df, probs_df], axis=1)\n",
    "    \n",
    "    # add metadata specific thresholds, accuracies, and combined loss\n",
    "    with open(learn_exports_fpath/'model_results.json') as f: model_results = json.load(f)\n",
    "    \n",
    "    final_df['threshold_f05'] = model_results['threshold_f05']\n",
    "    final_df['threshold_f1'] = model_results['threshold_f1']\n",
    "    final_df['threshold_f2'] = model_results['threshold_f2']\n",
    "\n",
    "    final_df['val_acc_f05'] = model_results['val_acc_f05']\n",
    "    final_df['val_acc_f1'] = model_results['val_acc_f1']\n",
    "    final_df['val_acc_f2'] = model_results['val_acc_f2']\n",
    "    \n",
    "    final_df['val_loss'] = model_results['val_loss']\n",
    "    \n",
    "    if (not with_doc_vecs): return final_df\n",
    "    return final_df, vecs_fwd, vecs_bwd, concat_vecs_fwd, concat_vecs_bwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_standard_theme_preds(themes_df, learn_exports_fpath=STANDARD_THEME_META_PATH, m_suf='multitask',\n",
    "                            corpus_cols=['theme', 'answer_text'],\n",
    "                            device=torch.device('cpu')):\n",
    "    \n",
    "    # 1. we need to massage the \"themes_df\" so that we have one row per predicted theme (only keeping those\n",
    "    # themes that meet the minimum f2 threshold)\n",
    "    pred_theme_cols = filter_col = [col for col in themes_df if col.startswith('prob_')]\n",
    "    \n",
    "    inf_df = themes_df.melt(id_vars=list(TASK_LM_DTYPES_SC.keys()) + ['threshold_f05', 'threshold_f1', 'threshold_f2', 'val_acc_f05', 'val_acc_f1', 'val_acc_f2', 'val_loss'], \n",
    "                            value_vars=pred_theme_cols, \n",
    "                            var_name='theme', \n",
    "                            value_name='theme_prob')\n",
    "    \n",
    "    inf_df = inf_df.loc[inf_df.theme_prob >= inf_df.threshold_f2]\n",
    "    \n",
    "    inf_df['url_friendly_theme'] = inf_df.theme.apply(\n",
    "        lambda s: re.sub(\"(.*?)_([a-zA-Z])\",\"\\g<1> \\g<2>\",s).replace('prob', '').strip().title().replace(' ',''))\n",
    "\n",
    "    inf_df['theme'] = inf_df.url_friendly_theme.apply(lambda s: re.sub(\"([a-z])([A-Z])\",\"\\g<1> \\g<2>\",s))\n",
    "    inf_df.reset_index(inplace=True)\n",
    "    \n",
    "    # 2. ensemble forward and backwards models\n",
    "    preds_fwd_sent, probs_fwd_is_example = _get_verbatims_ulmfit_standard_themes_meta(inf_df,\n",
    "                                                                                      learn_exports_fpath, \n",
    "                                                                                      m_suf=m_suf, \n",
    "                                                                                      backwards=False,\n",
    "                                                                                      corpus_cols=corpus_cols,\n",
    "                                                                                      device=device)\n",
    "    \n",
    "    preds_bwd_sent, probs_bwd_is_example = _get_verbatims_ulmfit_standard_themes_meta(inf_df,\n",
    "                                                                                      learn_exports_fpath, \n",
    "                                                                                      m_suf=m_suf, \n",
    "                                                                                      backwards=True,\n",
    "                                                                                      corpus_cols=corpus_cols,\n",
    "                                                                                      device=device)\n",
    "\n",
    "    preds_final_sent = (preds_fwd_sent + preds_bwd_sent) / 2\n",
    "    probs_final_is_example = torch.softmax((probs_fwd_is_example + probs_bwd_is_example) / 2, dim=-1)[:,1]\n",
    "    \n",
    "    # add the probabilities of each label\n",
    "    combined_probs = np.concatenate((preds_final_sent.numpy(), probs_final_is_example.numpy()[:,None]), axis=1)\n",
    "    \n",
    "    col_labels = ['pred_sentiment', 'prob_is_example']\n",
    "    probs_df = pd.DataFrame(combined_probs, columns=col_labels)\n",
    "    final_df = pd.concat([inf_df, probs_df], axis=1)\n",
    "    \n",
    "    # add metadata specific thresholds, accuracies, and combined loss\n",
    "    with open(learn_exports_fpath/'model_results.json') as f: model_results = json.load(f)\n",
    "    \n",
    "    final_df['is_example_threshold_f05'] = model_results['is_example_threshold_f05']\n",
    "    final_df['is_example_threshold_f1'] = model_results['is_example_threshold_f1']\n",
    "    final_df['is_example_threshold_f2'] = model_results['is_example_threshold_f2']\n",
    "\n",
    "    final_df['is_example_accuracy_f05'] = model_results['val_acc_f05']\n",
    "    final_df['is_example_accuracy_f1'] = model_results['val_acc_f1']\n",
    "    final_df['is_example_accuracy_f2'] = model_results['val_acc_f2']\n",
    "    \n",
    "    final_df['sentiment_mae'] = model_results['sentiment_mae']\n",
    "    final_df['sentiment_mse'] = model_results['sentiment_mse']\n",
    "    final_df['sentiment_rmse'] = model_results['sentiment_rmse']\n",
    "    \n",
    "    final_df['val_loss_metadata'] = model_results['final_valid_loss']\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = json.loads((RAW_DATA_PATH/'verbatim-inference.json').read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_run_id</th>\n",
       "      <th>survey_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_type_id</th>\n",
       "      <th>model_type_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>396</td>\n",
       "      <td>5</td>\n",
       "      <td>20200511-ulmfit-verbatim-standard-themes-saw</td>\n",
       "      <td>4</td>\n",
       "      <td>verbatim-classification-saw-themes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>396</td>\n",
       "      <td>4</td>\n",
       "      <td>20200511-ulmfit-verbatim-sent</td>\n",
       "      <td>2</td>\n",
       "      <td>verbatim-classification-sentiment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_run_id  survey_id  model_id  \\\n",
       "0           124        396         5   \n",
       "1           125        396         4   \n",
       "\n",
       "                                     model_name  model_type_id  \\\n",
       "0  20200511-ulmfit-verbatim-standard-themes-saw              4   \n",
       "1                 20200511-ulmfit-verbatim-sent              2   \n",
       "\n",
       "                      model_type_name  \n",
       "0  verbatim-classification-saw-themes  \n",
       "1   verbatim-classification-sentiment  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df = pd.DataFrame(f['models'])\n",
    "models_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698\n"
     ]
    }
   ],
   "source": [
    "inf_df = pd.DataFrame(f['data'])\n",
    "print(len(inf_df));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "yyyymmdd = datetime.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698\n",
      "torch.Size([698, 1200]) torch.Size([698, 400])\n",
      "torch.Size([698, 1200]) torch.Size([698, 400])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey_id</th>\n",
       "      <th>question_ans_id</th>\n",
       "      <th>rsp_id</th>\n",
       "      <th>question_category_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_text_non_english</th>\n",
       "      <th>language</th>\n",
       "      <th>survey_type_id</th>\n",
       "      <th>...</th>\n",
       "      <th>group_level8_code</th>\n",
       "      <th>group_level8_name</th>\n",
       "      <th>prob_is_very_positive</th>\n",
       "      <th>prob_is_positive</th>\n",
       "      <th>prob_is_very_negative</th>\n",
       "      <th>prob_is_negative</th>\n",
       "      <th>prob_is_suggestion</th>\n",
       "      <th>prob_feels_threatened</th>\n",
       "      <th>prob_has_profanity</th>\n",
       "      <th>prob_is_nonsense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>660404</td>\n",
       "      <td>396</td>\n",
       "      <td>93069</td>\n",
       "      <td>480447</td>\n",
       "      <td>1141</td>\n",
       "      <td>6988</td>\n",
       "      <td>I believe ANR leadership is completely disconnected from the work of campus-based specialists. When I am responding regarding \"my department\" in this survey it is my campus department I am evaluating, not an ANR department.</td>\n",
       "      <td>None</td>\n",
       "      <td>English</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>0.102388</td>\n",
       "      <td>0.911618</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.010853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>659993</td>\n",
       "      <td>396</td>\n",
       "      <td>92963</td>\n",
       "      <td>480435</td>\n",
       "      <td>1155</td>\n",
       "      <td>6958</td>\n",
       "      <td>Lorena Hoyos\\r\\nUCCE SAN JOAQUIN COUNTY\\r\\nUC CALFRESH</td>\n",
       "      <td>None</td>\n",
       "      <td>English</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.012533</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.005406</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.045634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  survey_id  question_ans_id  rsp_id  question_category_id  group_id  \\\n",
       "0  660404        396            93069  480447                  1141      6988   \n",
       "1  659993        396            92963  480435                  1155      6958   \n",
       "\n",
       "                                                                                                                                                                                                                       answer_text  \\\n",
       "0  I believe ANR leadership is completely disconnected from the work of campus-based specialists. When I am responding regarding \"my department\" in this survey it is my campus department I am evaluating, not an ANR department.   \n",
       "1                                                                                                                                                                           Lorena Hoyos\\r\\nUCCE SAN JOAQUIN COUNTY\\r\\nUC CALFRESH   \n",
       "\n",
       "  answer_text_non_english language  survey_type_id  ... group_level8_code  \\\n",
       "0                    None  English              47  ...              None   \n",
       "1                    None  English              47  ...              None   \n",
       "\n",
       "  group_level8_name prob_is_very_positive prob_is_positive  \\\n",
       "0              None              0.000215         0.006649   \n",
       "1              None              0.012533         0.017884   \n",
       "\n",
       "  prob_is_very_negative prob_is_negative prob_is_suggestion  \\\n",
       "0              0.102388         0.911618           0.006636   \n",
       "1              0.002087         0.001468           0.005406   \n",
       "\n",
       "  prob_feels_threatened prob_has_profanity prob_is_nonsense  \n",
       "0              0.000759           0.000005         0.010853  \n",
       "1              0.000027           0.000016         0.045634  \n",
       "\n",
       "[2 rows x 47 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = get_sentiment_preds(inf_df, device=device)\n",
    "\n",
    "print(len(res[0]))\n",
    "print(res[3].shape, res[1].shape)\n",
    "print(res[4].shape, res[2].shape)\n",
    "\n",
    "res[0].head(2)\n",
    "# res[0].to_csv(f'~/inf_X_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Themes - S@W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698\n",
      "torch.Size([698, 1200]) torch.Size([698, 400])\n",
      "torch.Size([698, 1200]) torch.Size([698, 400])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey_id</th>\n",
       "      <th>question_ans_id</th>\n",
       "      <th>rsp_id</th>\n",
       "      <th>question_category_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_text_non_english</th>\n",
       "      <th>language</th>\n",
       "      <th>survey_type_id</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_salary_pay</th>\n",
       "      <th>prob_satisfied_with_diversity_progams</th>\n",
       "      <th>prob_supervisor_effectiveness_resolves_staff_issues</th>\n",
       "      <th>threshold_f05</th>\n",
       "      <th>threshold_f1</th>\n",
       "      <th>threshold_f2</th>\n",
       "      <th>val_acc_f05</th>\n",
       "      <th>val_acc_f1</th>\n",
       "      <th>val_acc_f2</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>660404</td>\n",
       "      <td>396</td>\n",
       "      <td>93069</td>\n",
       "      <td>480447</td>\n",
       "      <td>1141</td>\n",
       "      <td>6988</td>\n",
       "      <td>I believe ANR leadership is completely disconnected from the work of campus-based specialists. When I am responding regarding \"my department\" in this survey it is my campus department I am evaluating, not an ANR department.</td>\n",
       "      <td>None</td>\n",
       "      <td>English</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011179</td>\n",
       "      <td>0.026293</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.976194</td>\n",
       "      <td>0.976055</td>\n",
       "      <td>0.966021</td>\n",
       "      <td>0.096622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>659993</td>\n",
       "      <td>396</td>\n",
       "      <td>92963</td>\n",
       "      <td>480435</td>\n",
       "      <td>1155</td>\n",
       "      <td>6958</td>\n",
       "      <td>Lorena Hoyos\\r\\nUCCE SAN JOAQUIN COUNTY\\r\\nUC CALFRESH</td>\n",
       "      <td>None</td>\n",
       "      <td>English</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>0.093966</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.976194</td>\n",
       "      <td>0.976055</td>\n",
       "      <td>0.966021</td>\n",
       "      <td>0.096622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  survey_id  question_ans_id  rsp_id  question_category_id  group_id  \\\n",
       "0  660404        396            93069  480447                  1141      6988   \n",
       "1  659993        396            92963  480435                  1155      6958   \n",
       "\n",
       "                                                                                                                                                                                                                       answer_text  \\\n",
       "0  I believe ANR leadership is completely disconnected from the work of campus-based specialists. When I am responding regarding \"my department\" in this survey it is my campus department I am evaluating, not an ANR department.   \n",
       "1                                                                                                                                                                           Lorena Hoyos\\r\\nUCCE SAN JOAQUIN COUNTY\\r\\nUC CALFRESH   \n",
       "\n",
       "  answer_text_non_english language  survey_type_id  ... prob_salary_pay  \\\n",
       "0                    None  English              47  ...        0.011179   \n",
       "1                    None  English              47  ...        0.001565   \n",
       "\n",
       "  prob_satisfied_with_diversity_progams  \\\n",
       "0                              0.026293   \n",
       "1                              0.005855   \n",
       "\n",
       "  prob_supervisor_effectiveness_resolves_staff_issues threshold_f05  \\\n",
       "0                                            0.000754          0.49   \n",
       "1                                            0.093966          0.49   \n",
       "\n",
       "  threshold_f1 threshold_f2 val_acc_f05 val_acc_f1 val_acc_f2  val_loss  \n",
       "0         0.44         0.27    0.976194   0.976055   0.966021  0.096622  \n",
       "1         0.44         0.27    0.976194   0.976055   0.966021  0.096622  \n",
       "\n",
       "[2 rows x 71 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = get_standard_theme_saw_preds(inf_df, device=device)\n",
    "\n",
    "print(len(res[0]))\n",
    "print(res[3].shape, res[1].shape)\n",
    "print(res[4].shape, res[2].shape)\n",
    "\n",
    "res[0].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Themes Metadata - S@W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1246\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>question_ans_id</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_text_non_english</th>\n",
       "      <th>language</th>\n",
       "      <th>survey_id</th>\n",
       "      <th>survey_type_id</th>\n",
       "      <th>benchmark_survey_type</th>\n",
       "      <th>client_id</th>\n",
       "      <th>...</th>\n",
       "      <th>is_example_threshold_f05</th>\n",
       "      <th>is_example_threshold_f1</th>\n",
       "      <th>is_example_threshold_f2</th>\n",
       "      <th>is_example_accuracy_f05</th>\n",
       "      <th>is_example_accuracy_f1</th>\n",
       "      <th>is_example_accuracy_f2</th>\n",
       "      <th>sentiment_mae</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>sentiment_rmse</th>\n",
       "      <th>val_loss_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>659998</td>\n",
       "      <td>92963</td>\n",
       "      <td>Anna Martin at NPI is an absolute joy to work for. She makes an effort to show us her appreciation for everything we do, even the \"behind-the-scenes\" work that can easily go unrecognized. She routinely asks about our capacity and workloads. Lorrene Richie and other staff (namely Anna) have turned NPI into a model for flexibility and work-life balance. It's no secret our program is female-dominated, many of those being mothers of young children. Lorrene always champions our efforts and it's encourgaing to stay in the workforce.</td>\n",
       "      <td>None</td>\n",
       "      <td>English</td>\n",
       "      <td>396</td>\n",
       "      <td>47</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCANR</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.976298</td>\n",
       "      <td>0.976298</td>\n",
       "      <td>0.976298</td>\n",
       "      <td>0.458426</td>\n",
       "      <td>0.383636</td>\n",
       "      <td>0.619384</td>\n",
       "      <td>0.498877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>660413</td>\n",
       "      <td>93069</td>\n",
       "      <td>While our department has a good work environment as a whole there are several area's that are a major issues.\\r\\n1) We have zero leadership, we have no direct managers over us. While we are able to manage our own work, we have very little real direction or support and it directly ties into other issues here.\\r\\n2) There is a Lone Ranger in our department. This employee has control over the servers without oversight and without transparency. This person has taken advantage of their role and privileged access to assert authority over others when this person has none. There is no collaboratio...</td>\n",
       "      <td>None</td>\n",
       "      <td>English</td>\n",
       "      <td>396</td>\n",
       "      <td>47</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCANR</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.976298</td>\n",
       "      <td>0.976298</td>\n",
       "      <td>0.976298</td>\n",
       "      <td>0.458426</td>\n",
       "      <td>0.383636</td>\n",
       "      <td>0.619384</td>\n",
       "      <td>0.498877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id  question_ans_id  \\\n",
       "0     11  659998            92963   \n",
       "1     18  660413            93069   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               answer_text  \\\n",
       "0                                                                     Anna Martin at NPI is an absolute joy to work for. She makes an effort to show us her appreciation for everything we do, even the \"behind-the-scenes\" work that can easily go unrecognized. She routinely asks about our capacity and workloads. Lorrene Richie and other staff (namely Anna) have turned NPI into a model for flexibility and work-life balance. It's no secret our program is female-dominated, many of those being mothers of young children. Lorrene always champions our efforts and it's encourgaing to stay in the workforce.   \n",
       "1  While our department has a good work environment as a whole there are several area's that are a major issues.\\r\\n1) We have zero leadership, we have no direct managers over us. While we are able to manage our own work, we have very little real direction or support and it directly ties into other issues here.\\r\\n2) There is a Lone Ranger in our department. This employee has control over the servers without oversight and without transparency. This person has taken advantage of their role and privileged access to assert authority over others when this person has none. There is no collaboratio...   \n",
       "\n",
       "  answer_text_non_english language  survey_id  survey_type_id  \\\n",
       "0                    None  English        396              47   \n",
       "1                    None  English        396              47   \n",
       "\n",
       "  benchmark_survey_type client_id  ...  is_example_threshold_f05  \\\n",
       "0                   SAW     UCANR  ...                      0.57   \n",
       "1                   SAW     UCANR  ...                      0.57   \n",
       "\n",
       "  is_example_threshold_f1 is_example_threshold_f2 is_example_accuracy_f05  \\\n",
       "0                    0.57                    0.57                0.976298   \n",
       "1                    0.57                    0.57                0.976298   \n",
       "\n",
       "   is_example_accuracy_f1 is_example_accuracy_f2 sentiment_mae sentiment_mse  \\\n",
       "0                0.976298               0.976298      0.458426      0.383636   \n",
       "1                0.976298               0.976298      0.458426      0.383636   \n",
       "\n",
       "  sentiment_rmse val_loss_metadata  \n",
       "0       0.619384          0.498877  \n",
       "1       0.619384          0.498877  \n",
       "\n",
       "[2 rows x 61 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "themes_df = get_standard_theme_saw_preds(inf_df, device=device, with_doc_vecs=False)\n",
    "\n",
    "res = get_standard_theme_preds(themes_df, device=device)\n",
    "\n",
    "print(len(res))\n",
    "res.head(2)\n",
    "# res.to_csv(f'~/inf_X_standard_themes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While our department has a good work environment as a whole there are several area's that are a major issues.\\r\\n1) We have zero leadership, we have no direct managers over us. While we are able to manage our own work, we have very little real direction or support and it directly ties into other issues here.\\r\\n2) There is a Lone Ranger in our department. This employee has control over the servers without oversight and without transparency. This person has taken advantage of their role and privileged access to assert authority over others when this person has none. There is no collaboration with others. This person may destroy ANR IT completely, causing many to desire to leave and find work elsewhere. There are MANY other serious issues which I will not share here...\\r\\n3) As an independent business unit. ANR seeks to bring on additional services which require entire teams to be hired. Yet the prospect seems like little growth for teams already over capacity.\\r\\n4) We are unable to take advantage of the latest technologies. Again due to the Lone Ranger's control.\\r\\n\\r\\nI am encouraged by the prospect of being able to work from home. I hope leadership decides to adopt this permanently.\n",
      "1                                                    Adequate Staffing\n",
      "258     Ethical Conduct Perform Responsibilities Spirit Of Cooperation\n",
      "1000                    Supervisor Effectiveness Resolves Staff Issues\n",
      "Name: theme, dtype: object\n",
      "1       1.766437\n",
      "258     1.712865\n",
      "1000    1.713691\n",
      "Name: pred_sentiment, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print(res[res.id == 660413].answer_text.values[0])\n",
    "print(res[res.id == 660413].theme)\n",
    "print(res[res.id == 660413].pred_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 99_inference.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
