{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp verbatims/standard_themes_meta/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Meta Themes - Training\n",
    "\n",
    "> This module contains all the bits required to train and evaluate meta standard theme models.  These are models which, for a given verbatim related to a standard tehem, predicts the sentiment relative to *that* theme and whether it should be used as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os, datetime, gc\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "import optuna\n",
    "\n",
    "from fastai import metrics as fa_metrics\n",
    "from fastai.text.all import *\n",
    "from transformers import *\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *\n",
    "from blurr.modeling.all import MultiTargetLoss\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from tritonlytics_ai.utils import *\n",
    "from tritonlytics_ai.verbatims.core import *\n",
    "\n",
    "from transformers import logging as hf_logging\n",
    "hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "# pandas and plotting config\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9,6)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.6.0\n",
      "Using fastai 2.0.16\n",
      "Using transformers 3.3.1\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "\n",
    "pretrained_model_name = 'facebook/bart-base' #\"bert-base-cased\" #\"bert-base-uncased\" #\"roberta-base\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.attention_probs_dropout_prob = 0.1 * 2\n",
    "config.hidden_dropout_prob = 0.1 * 2\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_meta_standard_theme_train_data(train_config=train_config)\n",
    "train_df, valid_df = df[df.is_valid == False], df[df.is_valid == True]\n",
    "\n",
    "set_seed(TL_RAND_SEED)\n",
    "dls = get_meta_standard_theme_train_dls(df, hf_arch, hf_tokenizer, train_config=train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([8, 468]), torch.Size([8]), torch.Size([8]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), b[0]['input_ids'].shape, b[1].shape, b[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pre = f'exp_{m_pre_standard_themes_meta}'\n",
    "m_suf = m_suf_standard_themes_meta\n",
    "base_model_name = base_model_name_standard_themes_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure our **metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# define metrics\n",
    "def sentiment_mse(preds, *targs):\n",
    "    return fa_metrics.mse(preds[0], targs[0])\n",
    "\n",
    "def is_example_acc(preds, *targs):\n",
    "    return fa_metrics.accuracy(preds[1], targs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_metrics(train_config={}):\n",
    "    config = {**meta_standard_themes_train_config, **train_config}\n",
    "    return [ sentiment_mse, is_example_acc ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure our **loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 148.02469135802468]\n"
     ]
    }
   ],
   "source": [
    "is_example_weights = list(np.max(train_df.is_example.value_counts()) /train_df.is_example.value_counts())\n",
    "print(is_example_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our custom multi-target loss\n",
    "loss_func = MultiTargetLoss(loss_classes=[MSELossFlat, CrossEntropyLossFlat],\n",
    "                            loss_classes_kwargs=[{}, {'weight': FloatTensor(is_example_weights).to('cuda:1')}],\n",
    "                            weights=[1, 0.1], \n",
    "                            reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_loss_func(dls, train_df=None, use_weighted=False):\n",
    "    loss_classes_kwargs = [{}, {}]\n",
    "    \n",
    "    if (use_weighted and train_df is not None):\n",
    "        is_example_weights = list(np.max(train_df.is_example.value_counts()) /train_df.is_example.value_counts())\n",
    "        loss_classes_kwargs[1] = {'weight': FloatTensor(is_example_weights).to(dls.device)}\n",
    "    \n",
    "    loss_func = MultiTargetLoss(loss_classes=[MSELossFlat, CrossEntropyLossFlat],\n",
    "                                loss_classes_kwargs=loss_classes_kwargs,\n",
    "                                weights=[1, 0.1], \n",
    "                                reduction='mean')\n",
    "        \n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_loss_func = get_loss_func(dls, train_df, use_weighted=False)\n",
    "test_is(type(tst_loss_func), MultiTargetLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_loss_func = get_loss_func(dls, train_df, use_weighted=True)\n",
    "test_is(type(tst_loss_func), MultiTargetLoss)\n",
    "test_eq(len(tst_loss_func.loss_funcs[1].func.weight), len(dls.c))\n",
    "test_eq(dls.device, tst_loss_func.loss_funcs[1].func.weight.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure our **callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Meta_MM_HF_BaseModelCallback(HF_BaseModelCallback):\n",
    "    def __init__(self, cls_idx=0):\n",
    "        super().__init__()\n",
    "        self.cls_idx = cls_idx\n",
    "        \n",
    "    def after_pred(self):\n",
    "        super().after_pred()\n",
    "        if (self.learn.pred[0].dim() == 3):\n",
    "            self.learn.pred = (self.learn.pred[0][:,self.cls_idx,:], self.learn.pred[1][:,self.cls_idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_cb = SaveModelCallback(monitor='valid_loss', \n",
    "                                  comp=np.less, \n",
    "                                  reset_on_fit=False,\n",
    "                                  fname=f'{m_pre}{base_model_name}{m_suf}_bestmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_cbs(train_config={}, add_save_model_cb=True):\n",
    "    config = {**meta_standard_themes_train_config, **train_config}\n",
    "    fit_cbs = []\n",
    "    \n",
    "    best_model_cb = SaveModelCallback(monitor=config['save_model_monitor'], \n",
    "                                      comp=config['save_model_comp'], \n",
    "                                      fname=config['save_model_filename'],\n",
    "                                      reset_on_fit=False)\n",
    "    \n",
    "    if (add_save_model_cb): fit_cbs.append(best_model_cb)\n",
    "    \n",
    "    return [Meta_MM_HF_BaseModelCallback], fit_cbs # (learn_cbs, fit_cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure our **final model** by updating our hf_model.classifier for multi-modal tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "# class Meta_MM(Module):\n",
    "#     def __init__(self, in_features=768, inner_dim=768, p=0.0): \n",
    "#         super().__init__()\n",
    "#         self.dense = nn.Linear(in_features, inner_dim)\n",
    "#         self.dropout = nn.Dropout(p=p)\n",
    "#         self.pred_is_example = nn.Linear(inner_dim, 2, bias=False)\n",
    "#         self.pred_avg_sentiment = nn.Linear(inner_dim, 1, bias=False)\n",
    "#         self.pred_avg_sent_range = SigmoidRange(1., 5.1)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.dense(x)\n",
    "#         x = torch.tanh(x)\n",
    "#         x = self.dropout(x)\n",
    "#         is_example = self.pred_is_example(x)\n",
    "#         avg_sentiment = self.pred_avg_sent_range(self.pred_avg_sentiment(x))\n",
    "        \n",
    "#         return avg_sentiment, is_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Meta_MM(Module):\n",
    "    def __init__(self, in_features=50): \n",
    "        super().__init__()\n",
    "        self.pred_is_example = nn.Linear(in_features, 2, bias=False)\n",
    "        self.pred_avg_sentiment = nn.Linear(in_features, 1, bias=False)\n",
    "        self.pred_avg_sent_range = SigmoidRange(1., 5.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        is_example = self.pred_is_example(x)\n",
    "        avg_sentiment = self.pred_avg_sent_range(self.pred_avg_sentiment(x))\n",
    "        \n",
    "        return avg_sentiment, is_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = list(hf_model.named_children())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classification_head'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer_name = last_layer[0]; last_layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_features = hf_model._modules[last_layer_name].dense.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model._modules[last_layer_name] = Meta_MM(in_features=in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# in_features = list(last_layer[1].children())[0].in_features; in_features\n",
    "# mm_model = nn.Sequential(list(hf_model.named_children())[:-1][0][1])\n",
    "# mm_model.add_module(name='classifier', module=MM(in_features=768))\n",
    "# hf_model._modules['classifier'] = hf_model._modules.pop(last_layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the **Learner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn\n",
    "except: pass\n",
    "finally: gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_metrics = [sentiment_mse, is_example_acc]\n",
    "\n",
    "learn_cbs = [Meta_MM_HF_BaseModelCallback]\n",
    "fit_cbs = [best_model_cb]\n",
    "\n",
    "# build learner\n",
    "model =HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "set_seed(TL_RAND_SEED)\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, mom=0.9, sqr_mom=0.98, eps=1e-6, weight_decay=0.1),\n",
    "                loss_func=loss_func,\n",
    "                metrics=learn_metrics,\n",
    "                cbs=learn_cbs,\n",
    "                splitter=hf_splitter,\n",
    "                path=STANDARD_THEME_META_PATH)\n",
    "\n",
    "learn.create_opt() # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Run this to test the model and comment out afterwards as it needlessly contributes to GPU RAM utilization :(\n",
    "# preds = model(b[0]); preds[0][0].shape, preds[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_learner(hf_model, dls, train_df=None, use_weighted_loss=False, use_fp16=True,\n",
    "                opt_func=partial(Adam, mom=0.9, sqr_mom=0.98, eps=1e-6, weight_decay=0.1),\n",
    "                add_save_model_cb=True, train_config={}):\n",
    "    config = {**meta_standard_themes_train_config, **train_config}\n",
    "    \n",
    "    # swap out classifier for our Meta_MM module\n",
    "    last_layer = list(hf_model.named_children())[-1]\n",
    "    last_layer_name = last_layer[0]\n",
    "    in_features = hf_model._modules[last_layer_name].dense.in_features\n",
    "    hf_model._modules[last_layer_name] = Meta_MM(in_features=in_features)\n",
    "    \n",
    "    # build learner\n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    loss_func = get_loss_func(dls, train_df, use_weighted_loss)\n",
    "    learn_cbs, fit_cbs = get_cbs(config, add_save_model_cb=add_save_model_cb)\n",
    "    learn_metrics = get_metrics(config)\n",
    "\n",
    "    set_seed(TL_RAND_SEED)\n",
    "    learn = Learner(dls, model, loss_func=loss_func, opt_func=opt_func, \n",
    "                    metrics=learn_metrics, cbs=learn_cbs, splitter=hf_splitter, path=config['learner_path'])\n",
    "    \n",
    "    if (use_fp16): learn = learn.to_fp16()\n",
    "    learn.create_opt() # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.freeze()\n",
    "    \n",
    "    return learn, fit_cbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(9.999999747378752e-07, 1.3182567499825382e-06)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_min, lr_steep = learn.lr_find(); lr_min, lr_steep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>is_example_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.929812</td>\n",
       "      <td>0.943785</td>\n",
       "      <td>0.908603</td>\n",
       "      <td>0.981888</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.9437850117683411.\n"
     ]
    }
   ],
   "source": [
    "set_seed(TL_RAND_SEED)\n",
    "learn.fit_one_cycle(1, lr_max=lr_min, cbs=fit_cbs)\n",
    "# learn.fit_flat_cos(10, lr_max=lr_min, cbs=fit_cbs, pct_start=0.72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1.0964781722577755e-07, 9.12010818865383e-07)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "lr_min, lr_steep = learn.lr_find(); lr_min, lr_steep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>is_example_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.911631</td>\n",
       "      <td>0.918890</td>\n",
       "      <td>0.884714</td>\n",
       "      <td>0.984747</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.978143</td>\n",
       "      <td>0.841289</td>\n",
       "      <td>0.810555</td>\n",
       "      <td>0.991420</td>\n",
       "      <td>03:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.804809</td>\n",
       "      <td>0.775611</td>\n",
       "      <td>0.748013</td>\n",
       "      <td>0.991420</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.744287</td>\n",
       "      <td>0.729382</td>\n",
       "      <td>0.703372</td>\n",
       "      <td>0.991420</td>\n",
       "      <td>03:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.795165</td>\n",
       "      <td>0.693655</td>\n",
       "      <td>0.668524</td>\n",
       "      <td>0.991420</td>\n",
       "      <td>03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.702241</td>\n",
       "      <td>0.668064</td>\n",
       "      <td>0.643372</td>\n",
       "      <td>0.991420</td>\n",
       "      <td>03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.710689</td>\n",
       "      <td>0.651300</td>\n",
       "      <td>0.626834</td>\n",
       "      <td>0.991420</td>\n",
       "      <td>03:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.721196</td>\n",
       "      <td>0.643052</td>\n",
       "      <td>0.618704</td>\n",
       "      <td>0.991420</td>\n",
       "      <td>03:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.695299</td>\n",
       "      <td>0.640770</td>\n",
       "      <td>0.616453</td>\n",
       "      <td>0.991420</td>\n",
       "      <td>03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.655520</td>\n",
       "      <td>0.640692</td>\n",
       "      <td>0.616377</td>\n",
       "      <td>0.991420</td>\n",
       "      <td>03:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.9188904166221619.\n",
      "Better model found at epoch 1 with valid_loss value: 0.8412891030311584.\n",
      "Better model found at epoch 2 with valid_loss value: 0.7756107449531555.\n",
      "Better model found at epoch 3 with valid_loss value: 0.7293819189071655.\n",
      "Better model found at epoch 4 with valid_loss value: 0.6936553716659546.\n",
      "Better model found at epoch 5 with valid_loss value: 0.668064296245575.\n",
      "Better model found at epoch 6 with valid_loss value: 0.6512995958328247.\n",
      "Better model found at epoch 7 with valid_loss value: 0.6430519223213196.\n",
      "Better model found at epoch 8 with valid_loss value: 0.6407696604728699.\n",
      "Better model found at epoch 9 with valid_loss value: 0.6406921148300171.\n"
     ]
    }
   ],
   "source": [
    "set_seed(TL_RAND_SEED)\n",
    "learn.fit_one_cycle(10, lr_max=slice(lr_min/10, lr_min), cbs=fit_cbs)\n",
    "# learn.fit_flat_cos(5, lr_max=slice(lr_min/10, lr_min), cbs=fit_cbs, pct_start=0.72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('data/classification/standard_themes/meta/models/exp_verbatim_standard_theme_meta_multitask_hf.pth')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save(f'{m_pre}{base_model_name}{m_suf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname=f'{m_pre}{base_model_name}{m_suf}_export.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'valid_loss': 0.6406921148300171,\n",
       " 'sentiment_mse': 0.6163774132728577,\n",
       " 'is_example_acc': 0.9914203882217407}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = dict(zip(learn.recorder.metric_names[2:], learn.validate())); scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "      <th>category</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>theme: Have Voice within my Institution/Valued Member of my Institution comment: Staff no longer receive COLAs, like the faculty do--we are instead told that our COLA is a merit increase and expected to believe this.\\r\\n\\r\\nThis is incredibly demoralizing and many talented staff with institutional longevity are considered leaving UCSD for higher compensation elsewhere, at least as far as I am able to report by personal conversation. The turnover loss to the department if this were to happen would be substantial. Experienced career staff have knowledge that they can generalize from to solve the unique problems that arise frequently in the university setting. New staff cannot always provide these solutions to faculty.\\r\\n\\r\\nFurther our'merit increases' were not announced in a timely manner and apparently do not include July, that is, they are effective Aug 1. I do not think our faculty would accept this!  It is true that the faculty attract fee-paying students to campus but the institution truly is a three legged stool--charitably I do not think our department could be run with faculty alone.\\r\\n\\r\\nAsides from compensation, which is an UCOP / EVCAA issue, Mathematics is a good department to work. \\r\\n\\r\\nThe MSO (which I am not) should receive more credit for proactive solutions to pending / future problems but since these problems do not materialize when solved it is not often that the faculty recognize this.\\r\\n\\r\\nSupervisors are generally good. \\r\\n\\r\\nThis department has lots of room for growth and additionally a significant amount of room for process improvement in many domain areas.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>(2.3660523891448975,)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>theme: Have Voice within my Institution/Valued Member of my Institution comment: My team colleagues frequently gossip, talk, laugh around me (and I can hear them).  They also frequently withhold information necessary for team work and for me to successfully do my job.  They also complain their work which furthers a negative environment. This team is oriented towards dysfunctional individuals, not on the team or service for customers.  This has caused problem with anxiety and insomnia which has been very difficult for me.  I've had to spend a lot of time personally taking care of myself to offset the negative impact this has created.  I am a service oriented, transparent individual and pride myself on treating others with kindness regardless of their position.\\r\\n\\r\\nOccasionally I've had mobility issues and brought ADA compliance issues to team members' attention like no elevator access due to a mechanical issue and the only option was climbing 3 flights of stairs one way.  Instead of this being addressed as an ADA issued, I was targeted spoken to with increased volume and told I could call Facilities Management myself if I didn't like the response or blown off like I was un-useful because I couldn't assist with a request requiring mobility when this is not an issue caused by me.  This is completely unacceptable.  \\r\\n\\r\\nAlthough I am not old, I've also experienced ageism because I have senior level experience in position.  I've also been mocked by 2 colleges because I'm a grandparent. This is completely unacceptable. This survey does not include age discrimination.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>(2.1806387901306152,)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use it for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_learn = load_learner(STANDARD_THEME_META_PATH/f'{m_pre}{base_model_name}{m_suf}_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(((2.4098987579345703), '0'), tensor([[2.4099]]), tensor([[2.4099]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn.blurr_predict('theme: Benefits comment: We are not paid enough and the benefits are horrible')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review final validation loss for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.9456282258033752\n"
     ]
    }
   ],
   "source": [
    "learn = learn.load(f'{m_pre}{base_model_name}{m_suf}_bestmodel')\n",
    "probs, targs, loss = learn.get_preds(dl=dls.valid, with_loss=True)\n",
    "\n",
    "print(f'Validation Loss: {loss.mean()}')\n",
    "# print(f'Validation Loss (per label): {loss.mean(dim=0)}') # ... no longer works (see forum comment from sylvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3317]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9597]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1157]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4783]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3356]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2869]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3826]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3202]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4539]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0743]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2604]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4032]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0880]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3007]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0287]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9187]) tensor(4.5000) tensor(0) tensor(0)\n",
      "tensor([2.8316]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4760]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4113]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5720]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4291]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6700]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1678]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4636]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4746]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7480]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5651]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1166]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4030]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1472]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.5103]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([3.1984]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.5678]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2226]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8385]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([3.0598]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.0734]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.7614]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7458]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7480]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9707]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.6923]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4415]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1927]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4614]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3792]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1860]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.2133]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.3967]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2365]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0486]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0624]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3483]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2198]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3778]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1000]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2547]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9481]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.5161]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.5290]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8290]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0855]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5344]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0340]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4863]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.7603]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8836]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3579]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8333]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.6409]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7290]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8152]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3499]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0970]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.6943]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.2634]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7518]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.6507]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.6170]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.0618]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1553]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.0919]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.0860]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2400]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1957]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7783]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1221]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2803]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3967]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.5872]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.7662]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4434]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1123]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.3758]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([1.8721]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7695]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2365]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6732]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5040]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0338]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4548]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1567]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0514]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7068]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2236]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.1788]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1846]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.3636]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([1.9265]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3320]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6184]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3702]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3673]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.8400]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9729]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6470]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.3616]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.0016]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5955]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9558]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2004]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2712]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0858]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5485]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1806]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.7133]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0896]) tensor(4.5000) tensor(0) tensor(0)\n",
      "tensor([2.4675]) tensor(2.) tensor(0) tensor(1)\n",
      "tensor([2.4442]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7359]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5667]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6592]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7486]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3261]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3718]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1713]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9203]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.7532]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7534]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1478]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7668]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.1196]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.8140]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1704]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.4171]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.0734]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.8954]) tensor(1.) tensor(0) tensor(1)\n",
      "tensor([2.0772]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3004]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5679]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7446]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1510]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8171]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2155]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7339]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0947]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6923]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9342]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5740]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0573]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.8193]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3867]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3923]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3851]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6084]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7540]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3875]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.0582]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2203]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0357]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3877]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5799]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4522]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2549]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9200]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4030]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6714]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2857]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8028]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5626]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6218]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5148]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6186]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6394]) tensor(2.5000) tensor(0) tensor(1)\n",
      "tensor([2.3032]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6874]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9515]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([3.1158]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0594]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3417]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1738]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7413]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8961]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5624]) tensor(2.) tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2611]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.2810]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.1253]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6276]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1111]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2938]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1013]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8457]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8007]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4261]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.7473]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8915]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4613]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9193]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.1941]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.9374]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3709]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7377]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.7756]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.5674]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0624]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.1644]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8147]) tensor(3.) tensor(0) tensor(1)\n",
      "tensor([2.3127]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.1573]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2137]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9442]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6479]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8390]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4616]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.1756]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.2874]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1721]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8083]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9898]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7965]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.8035]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6929]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5343]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4208]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9074]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7192]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1639]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6883]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2098]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4654]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3584]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6473]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0571]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4306]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4560]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3164]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9934]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4725]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8242]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9536]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1125]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2515]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4551]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4513]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0643]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8203]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.9045]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7159]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4193]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.3877]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8276]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3669]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3771]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4531]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1267]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2220]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.5799]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7272]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0912]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.9750]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.8432]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.3388]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3969]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2379]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.3357]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5171]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4335]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0931]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2020]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5788]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5959]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3306]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3357]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0492]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.2492]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.7054]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4997]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1601]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2037]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2847]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.0690]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7534]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.6254]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7050]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3236]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3557]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6175]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.5517]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3858]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1820]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6138]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.0448]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3643]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4318]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0676]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.9547]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.2451]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2529]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.9810]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8382]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3851]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5795]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4132]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.7393]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5500]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2496]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4446]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([1.9715]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8222]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6793]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1800]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([1.8992]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2017]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4208]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5905]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2504]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6736]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1623]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.3192]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4126]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8473]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.2953]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6079]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1913]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5222]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3060]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8648]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4448]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5920]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9229]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2408]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.5642]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4000]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9384]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6480]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.3737]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8339]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5763]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6976]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7727]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.2397]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.6156]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1324]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4734]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4487]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8594]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9591]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4038]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9841]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1724]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([3.2362]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4138]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1844]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.5529]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.0925]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2953]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1800]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8134]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5346]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1578]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6847]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2450]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.3577]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4176]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3599]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0831]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.6761]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7746]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0245]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4357]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0424]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2251]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4493]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.2644]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7807]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1636]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4967]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.8184]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2529]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8929]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4568]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8465]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3313]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7125]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5300]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6674]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9819]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.2325]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8014]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.0931]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.2172]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3568]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8277]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8094]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7283]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5727]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1888]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4255]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3024]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1170]) tensor(2.) tensor(0) tensor(1)\n",
      "tensor([3.0621]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.5301]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2525]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.0228]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8480]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6511]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7008]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0355]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7414]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3093]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0485]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4438]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.3578]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4030]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5676]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0581]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0545]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0905]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4631]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7723]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2065]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0983]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3273]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3486]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([3.0854]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.5335]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.2171]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.3890]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2673]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9975]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5035]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5123]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2157]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4606]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6850]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.7496]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4075]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0378]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3239]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2512]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.3352]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2767]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6088]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.3327]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.5324]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9645]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0117]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.5352]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.1498]) tensor(2.) tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1517]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3853]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8793]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9415]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.5673]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9706]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.1851]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8777]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8124]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9635]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2016]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3320]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9803]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4295]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4070]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4788]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9780]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1912]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8525]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3454]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7161]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1673]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1587]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2982]) tensor(2.) tensor(0) tensor(1)\n",
      "tensor([2.5733]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.6042]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1526]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0283]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2168]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3614]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1636]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6924]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2316]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9035]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2081]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9819]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4147]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2374]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2219]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7107]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8753]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5130]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9509]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.8798]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3956]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4020]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4498]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8938]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4708]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6298]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9082]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.7004]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5865]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5558]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2148]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4958]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2850]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6151]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9833]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4289]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8017]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1993]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5850]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2860]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5595]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3887]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6036]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4206]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6577]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4416]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9499]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4059]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8524]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.9494]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.0304]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9202]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.1333]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1431]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2093]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1201]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2013]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.4683]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9541]) tensor(3.5000) tensor(0) tensor(0)\n",
      "tensor([1.9923]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6791]) tensor(2.5000) tensor(0) tensor(1)\n",
      "tensor([2.3402]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1975]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.5075]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0281]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7172]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4138]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7617]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3372]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9305]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.0680]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5698]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4463]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7266]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5603]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.4073]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.5456]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.4742]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0343]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9348]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.0850]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4993]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.9294]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1423]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.7714]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3850]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5083]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1849]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3804]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5246]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0089]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0028]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0943]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3816]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.9887]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.5897]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.8559]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0869]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.3550]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.3858]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.2024]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4398]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5272]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.0526]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.6397]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6845]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2962]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1871]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1504]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.6217]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.2245]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2496]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4094]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2335]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4440]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2211]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1202]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0813]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.0438]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.9134]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2784]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.6663]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2418]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4594]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5178]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6592]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8113]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1858]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4479]) tensor(4.5000) tensor(0) tensor(0)\n",
      "tensor([2.6733]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6384]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1382]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2969]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1165]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8724]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3960]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8802]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1150]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7946]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2185]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2362]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.3381]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3600]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3233]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.7037]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4920]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8098]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2889]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1459]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2725]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([3.0867]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.6933]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0389]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.8991]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4414]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3572]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1981]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3596]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4437]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2310]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.5020]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8485]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1697]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9386]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.8406]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8158]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.5877]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4851]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3936]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2704]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.7982]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4531]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9326]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1198]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4860]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0110]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.6623]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.7581]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4651]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8032]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.7140]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4249]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.5297]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6595]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2854]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1561]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0536]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5738]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8843]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2266]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1069]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.2080]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.1286]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3852]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0193]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5010]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7511]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6123]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0893]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.7037]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4443]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6449]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1463]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5681]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5264]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9563]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7264]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.3437]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4873]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9020]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8744]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0359]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6108]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4398]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4726]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1175]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8382]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8969]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.7279]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4165]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3569]) tensor(2.) tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9452]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.3235]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5567]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2000]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4249]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1752]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9505]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1278]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3028]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8414]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8395]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9722]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.0643]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0356]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.0989]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6866]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5287]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6104]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.2854]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3993]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.7755]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3281]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3008]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3506]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4841]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6020]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4815]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7239]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9712]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9612]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4140]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2310]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4405]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.8601]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.6396]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9614]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4594]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7171]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9363]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4871]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1140]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1992]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3380]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8383]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1940]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5631]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7574]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.4344]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3093]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2341]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.6089]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4302]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8351]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5965]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0845]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7112]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2363]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8926]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4957]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.2415]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.3832]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.1593]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8841]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([1.9076]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2240]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1126]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9261]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3087]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9834]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3704]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0960]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8813]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.0632]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4280]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1699]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.2644]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.1662]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9725]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.6023]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2684]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6346]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2820]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1760]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2684]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3698]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2585]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.2085]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9161]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0803]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1775]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0054]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.1842]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7664]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2126]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2835]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9386]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0447]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4336]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4837]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.2405]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.6777]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7151]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4240]) tensor(2.) tensor(0) tensor(1)\n",
      "tensor([2.5380]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5999]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5149]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9915]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([3.2498]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.6773]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4366]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4272]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7498]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9795]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.3202]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6281]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5911]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2617]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0884]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2862]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4922]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0775]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9757]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4494]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([3.1309]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.4159]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6681]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5487]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2731]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.6098]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2612]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([3.1995]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.2180]) tensor(4.5000) tensor(0) tensor(0)\n",
      "tensor([2.2322]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3012]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5759]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7897]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2407]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7140]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5037]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.5764]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6110]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0320]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1232]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.2779]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3398]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.0474]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.5816]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0977]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0724]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9576]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9609]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.3802]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9697]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.6211]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.5659]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.2237]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1463]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.7667]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6760]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7395]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.8117]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.5465]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4288]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1175]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5229]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3862]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2553]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4230]) tensor(4.5000) tensor(0) tensor(0)\n",
      "tensor([2.7425]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6027]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6451]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4227]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.5853]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4478]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.3832]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.5782]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6315]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.6780]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2952]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.7147]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9323]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.0941]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.6392]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.4604]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.4522]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3932]) tensor(3.5000) tensor(0) tensor(0)\n",
      "tensor([2.8528]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.7584]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.5437]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.0897]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.3661]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.1552]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1000]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5560]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0603]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.9473]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8552]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9867]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2118]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3279]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7200]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2442]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9859]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4529]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2452]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1253]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.3968]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0648]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.9873]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5234]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([1.9073]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0572]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2265]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0349]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.4930]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.0954]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4278]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5518]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8846]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4992]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4886]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1093]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.1260]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1269]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3008]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3330]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1820]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2746]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3541]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6622]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0620]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9056]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3870]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5765]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4113]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.2619]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5275]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2708]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9164]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8791]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2418]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9578]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3661]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5529]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6242]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.3272]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.5912]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7566]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.1903]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5133]) tensor(2.) tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0866]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4637]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5325]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3414]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1559]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0532]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.1589]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.3712]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4159]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0382]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6093]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.5619]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3124]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0492]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0245]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5384]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5946]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.8453]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5471]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4035]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.0961]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4383]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.0077]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0115]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0247]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.4685]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3310]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.7519]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3735]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2957]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.3172]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0953]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3964]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.9459]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4155]) tensor(1.5000) tensor(0) tensor(0)\n",
      "tensor([2.9470]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5532]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.3069]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.8416]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9212]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.2151]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.7353]) tensor(2.5000) tensor(0) tensor(0)\n",
      "tensor([2.3289]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.4314]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.3195]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.6849]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1591]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6207]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([1.8815]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6846]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3386]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1501]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.3271]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([3.0042]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.7314]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5560]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4550]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.9913]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.7788]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([1.8573]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9307]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([3.1405]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([3.6531]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([2.3935]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3090]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.1572]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9766]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3700]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([1.8265]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.1152]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2449]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2193]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4410]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.5170]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.4247]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9371]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([3.0700]) tensor(5.) tensor(0) tensor(0)\n",
      "tensor([1.9908]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1663]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.2066]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([3.0318]) tensor(4.) tensor(0) tensor(0)\n",
      "tensor([2.8461]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.3479]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.5640]) tensor(3.) tensor(0) tensor(0)\n",
      "tensor([2.1167]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.2466]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3754]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3525]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.6890]) tensor(1.5000) tensor(0) tensor(1)\n",
      "tensor([2.2047]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.9305]) tensor(1.) tensor(0) tensor(0)\n",
      "tensor([2.5904]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.3358]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([2.0389]) tensor(2.) tensor(0) tensor(0)\n",
      "tensor([1.9464]) tensor(3.) tensor(0) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for prob_sent, prob_example, targ_sent, targ_example in zip(*probs,*targs):\n",
    "    print(prob_sent, targ_sent, torch.argmax(prob_example, dim=-1), targ_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adequate_staffing',\n",
       " 'advancement_and_training_opportunities',\n",
       " 'appropriate_stress_work_assigned_equitably',\n",
       " 'benefits',\n",
       " 'better_ways_recognized_participate_in_decisions']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STANDARD_THEME_SAW_LABELS[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(((2.6881637573242188), '0'), tensor([[2.6882]]), tensor([[2.6882]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"theme: Adequate Staffing comment: We don't have enough people to get the job done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try: del learn\n",
    "except: pass\n",
    "finally: gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1049, 1]),\n",
       " torch.Size([1049, 2]),\n",
       " torch.Size([1049]),\n",
       " torch.Size([1049]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions for a single model using the learner's model and data loaders\n",
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "\n",
    "pretrained_model_name = 'facebook/bart-base' #\"bert-base-cased\" #\"bert-base-uncased\" #\"roberta-base\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.attention_probs_dropout_prob = 0.1 * 2\n",
    "config.hidden_dropout_prob = 0.1 * 2\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)\n",
    "\n",
    "set_seed(TL_RAND_SEED)\n",
    "learn, fit_cbs = get_learner(hf_model, \n",
    "                             dls, \n",
    "                             train_df=train_df, \n",
    "                             use_weighted_loss=False, \n",
    "                             use_fp16=True,\n",
    "                             train_config={})\n",
    "\n",
    "learn = learn.load(f'{m_pre}{base_model_name}{m_suf}_bestmodel')\n",
    "learn.model.cuda(1)\n",
    "probs, targs  = learn.get_preds()\n",
    "\n",
    "probs[0].shape, probs[1].shape, targs[0].shape, targs[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Lets look at validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_example_prob_true = torch.softmax(probs[1], dim=-1)[:,1]\n",
    "# is_example_prob_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "f05 = OptimalMultiThresholdMetrics(beta=0.5, start=0.05, end=.5, sigmoid=False, \n",
    "                                   average='binary', sample_weight=None)\n",
    "f1 = OptimalMultiThresholdMetrics(beta=1, start=0.05, end=.5, sigmoid=False, \n",
    "                                   average='binary', sample_weight=None)\n",
    "f2 = OptimalMultiThresholdMetrics(beta=2, start=0.05, end=.5, sigmoid=False, \n",
    "                                   average='binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29000000000000004, 0.29000000000000004, 0.29000000000000004)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_f05 = f05.opt_th(is_example_prob_true, targs[1])\n",
    "threshold_f1 = f1.opt_th(is_example_prob_true, targs[1])\n",
    "threshold_f2 = f2.opt_th(is_example_prob_true, targs[1])\n",
    "\n",
    "threshold_f05, threshold_f1, threshold_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.011180124223602485, 0.017769002961500496, 0.043269230769230775)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f05_score = f05.opt_fscore(is_example_prob_true, targs[1])\n",
    "f1_score = f1.opt_fscore(is_example_prob_true, targs[1])\n",
    "f2_score = f2.opt_fscore(is_example_prob_true, targs[1])\n",
    "\n",
    "f05_score, f1_score, f2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011180124223602485"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure we are getting the same f1 score as sklearn\n",
    "res = skm.fbeta_score(targs[1], (is_example_prob_true > threshold_f05), beta=.5, \n",
    "                      average='binary', sample_weight=None, zero_division=False)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9914203882217407, 0.9914203882217407, 0.9914203882217407)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine accuracy based on optimal threshold\n",
    "val_acc_f05 = accuracy_multi(torch.argmax(probs[1], dim=-1), targs[1], threshold_f05, sigmoid=False).item()\n",
    "val_acc_f1 = accuracy_multi(torch.argmax(probs[1], dim=-1), targs[1], threshold_f1, sigmoid=False).item()\n",
    "val_acc_f2 = accuracy_multi(torch.argmax(probs[1], dim=-1), targs[1], threshold_f2, sigmoid=False).item()\n",
    "\n",
    "val_acc_f05, val_acc_f1, val_acc_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.051477596163749695"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure we are getting the same f1 accuracy\n",
    "preds = ((is_example_prob_true > threshold_f05).byte() == targs[1].byte()).float().mean()\n",
    "preds.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Overall metrics - is_example_prob_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eval_targs = targs[1].flatten() # targs[:,0]\n",
    "eval_probs = is_example_prob_true.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Classification Accuracy\n",
    "\n",
    "The percentage of correct predictions.  Answers the question, *\"Overall, how often is the classifier correct?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05147759771210677\n"
     ]
    }
   ],
   "source": [
    "print(skm.accuracy_score(eval_targs, (is_example_prob_true > threshold_f05).float(), sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Null Accuracy\n",
    " \n",
    "The accuracy achieved by always predicting the most frequent class.  Answers the question, *\"What would the accuracy be by always predicting the most frequent case?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1040\n"
     ]
    }
   ],
   "source": [
    "u_classes, u_counts = np.unique(eval_targs, return_counts=True)\n",
    "most_freq_class, most_freq_class_count = u_classes[np.argmax(u_counts)], np.max(u_counts)\n",
    "print(most_freq_class, most_freq_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9914204003813155"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq_class_count / len(eval_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Cohen's kappa\n",
    "\n",
    "This measure is intended to compare labelings by different human annotators (not a classifier vs. ground truth)\n",
    "\n",
    "Kappa socres are between -1 and 1 ( >= .8 is generally considered good agreement; <= 0 means no agreement ... e.g., practically random labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007754424090410383\n"
     ]
    }
   ],
   "source": [
    "print(skm.cohen_kappa_score(eval_targs, (eval_probs > threshold_f05).float(), \n",
    "                            weights=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "Describes the performance of a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, \n",
    "                          title='Confusion matrix', cmap=plt.cm.Blues, print_info=False):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        if (print_info): print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        if (print_info): print('Confusion matrix, without normalization')\n",
    "\n",
    "    if (print_info): print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cm = skm.confusion_matrix(eval_targs, (eval_probs > threshold_f05).float(), sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_confusion_matrix(cm, classes=u_classes,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_confusion_matrix(cm, classes=u_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.08      1040\n",
      "           1       0.01      1.00      0.02         9\n",
      "\n",
      "    accuracy                           0.05      1049\n",
      "   macro avg       0.50      0.52      0.05      1049\n",
      "weighted avg       0.99      0.05      0.08      1049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skm.classification_report(eval_targs, (eval_probs > threshold_f05).float(), \n",
    "                                labels=[0,1], \n",
    "                                sample_weight=None, \n",
    "                                zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Raw probability distribution\n",
    "\n",
    "Useful to see how the threshold can be adjusted to increase sensitivity or specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(eval_probs, bins=10)\n",
    "# plt.xlim(0,1)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability of Labels')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### ROC curves and Area Under the Curve (AUC)\n",
    "\n",
    "***ROC Curve*** answers the question, *\"How would sensitivity and specificity be affected by various thresholds without changing the threshold?\"*  It is a way **to visualize the performance of a binary classifier.**\n",
    "\n",
    "The ROC curve can help you **choose a threshold** that balances sensitivity and specificity based on your particular business case.\n",
    "\n",
    "ROC curves visualize all possible classification thresholds whereas misclassification rate only represents your error rate for a single threshold.\n",
    "\n",
    "A classifier that does a good job at separating the classes will have a ROC curve that hugs the upper left corner of the plot.  Converseley, a classifier the does a poor job separating the classes will have a ROC curve that is close to the diagonal line (0,0 -> 1,1).  That diagonal line represents a classifier that does no better than random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = skm.roc_curve(eval_targs, eval_probs, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAGDCAYAAADu/IALAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deVhU9f4H8PcAgqAoQjqQeu26k1pQiSuQKBLLiAtYXn9aN82yXFK7bimZaS6lptdyScPrVtdcQ3BFBXPBcAkXuoqKK4y7sg7MzPn9gUxOMM4IzJkzzPv1PD4xM2fO+cz3TPL2ez7nHJkgCAKIiIiIJMbO0gUQERERlYchhYiIiCSJIYWIiIgkiSGFiIiIJIkhhYiIiCSJIYWIiIgkiSGFiCRDEARMmjQJ7du3R1RUlNm3N3HiRCxYsAAAkJKSgoCAAIPLtmrVCleuXDG6zuvXr6NVq1ZQq9XPXE9l3ktUHTlYugAiWxcUFIQ7d+7A3t4eLi4u8Pf3x9SpU1GrVi3dMidOnMA333yD06dPw87ODu3bt8cnn3yC5s2b65bJzc3FwoULsWfPHjx8+BAeHh7o1q0bhg8fDnd3d0t8tGd2/PhxHDp0CElJSXBxcbF0OURkYZxJIZKApUuX4uTJk9i6dSvOnTuH5cuX6147efIkhgwZgu7du+PgwYNITExEq1atMGDAAFy7dg0AUFRUhLfffhsZGRlYsWIFjh8/jv/+979wc3PD6dOnzVZ3Vf+L/8aNG2jYsGGFAgpnH4iqH4YUIgmpX78+unbtivT0dN1zX331FSIjI/H222+jdu3acHNzw5gxY/Dyyy/j3//+NwBg27ZtyMrKwuLFi9G8eXPY2dnBw8MDH330EQIDA8vd1oULF/DPf/4Tfn5+6Ny5M5YuXQpA/xAIUPYwSFBQEJYvXw6FQgEfHx8sX74co0aN0lv3jBkzMGPGDABATk4OJk+ejK5du8Lf3x8LFiyARqMpU8/PP/+MKVOm4NSpU/D19cWiRYsAABs2bEBwcDD8/PzwwQcfQKlU6t7TqlUrrFu3Dj179kTPnj3L/ZyjRo1Cly5d8Oqrr2LgwIG4cOGC4R1gogMHDqB379545ZVXEBgYqNsPT9q0aRO6du2Krl27YuXKlbrntVotli9fjh49eqBDhw4YPXo0Hjx4UO52Nm/ejO7du8PX1xdBQUH45ZdfKl07kTVhSCGSkOzsbBw8eBB/+9vfAAAFBQU4efIk3njjjTLLhoaG4vDhwwCAw4cPw9/fX+8Q0dPk5ubin//8J/z9/XHw4EHs3r0bnTp1MrnO+Ph4LF++HKmpqQgPD0dSUhJyc3MBABqNBjt37kRERASAktDj4OCA3bt3Y+vWrTh06BB+/vnnMuuMjo7G559/Dh8fH5w8eRKjRo3CkSNHMG/ePHzzzTf49ddf0bBhQ4wdO1bvfXv37sWGDRuQkJBQbq0BAQHYtWsXjhw5ghdffBGffPKJyZ/TEGdnZ8yZMwepqalYtmwZfvzxR+zdu1dvmZSUFOzevRsrV67E999/r9tXa9aswd69e7F27VocPHgQdevWxfTp08tsIz8/HzNmzMD333+PkydP4qeffoK3t3elayeyJgwpRBLw0UcfwdfXF4GBgXB3d9fNTDx8+BBarRb169cv85769evj/v37AIAHDx6Uu4whBw4cwHPPPYd3330XTk5OqF27Nl5++WWT3z9o0CB4eXmhZs2aaNiwIV588UXdL+mjR4+iZs2a8PHxwZ07d5CUlITJkyfDxcUFHh4eeOeddxAfH2/SduLi4tCvXz+0adMGjo6OGDt2LE6dOoXr16/rlhk2bBjc3NxQs2bNctcRFRWF2rVrw9HRESNHjsQff/yBnJwckz9reTp06IBWrVrBzs4OrVu3Rnh4OI4dO6a3zEcffQQXFxe0atUKffv2xfbt2wEAP/30E8aMGQNPT084OjpixIgR2LVrV7mHq+zs7HDhwgUUFhaiQYMGaNGiRaXqJrI2bJwlkoBvv/0WnTt3xrFjxzBu3Djcv38fderUQZ06dWBnZ4fbt2+jWbNmeu+5ffs26tWrBwBwc3PD7du3Td5eVlaWbramIry8vPQeR0REYPv27ejduze2b9+um0W5efMm1Go1unbtqltWq9WWeb8ht27dQps2bXSPa9WqBTc3NyiVSjRq1KjcWp6k0WiwYMEC7Ny5E/fu3YOdXcm/y+7fvw9XV1fTPmw5fv/9d3z99de4cOECiouLUVRUVGa268m6GjZsiPPnzwMoGZOPPvpIVwtQEkbu3r2r934XFxcsWLAAP/zwAz799FO88sormDBhQpnvAVF1xpkUIgnx8/ND3759MWfOHAAlv6h8fHywc+fOMsvu2LEDHTt2BAB07twZv/76K/Lz803ajpeXl67p9q+cnZ1RWFioe3znzp0yy8hkMr3HoaGhOHbsGLKzs7Fnzx4oFAoA0M0WHD16FKmpqUhNTcWJEydMnklp0KABbty4oXucn5+PBw8eQC6XG6zlSXFxcUhMTERsbCyOHz+Offv2ASg51bkyxo0bh+7duyMpKQnHjx/HW2+9VWadWVlZup9v3ryJBg0aACgZk++//143HqmpqTh9+rTeZyrl7++P2NhY/Prrr2jatCmmTp1aqbqJrA1DCpHEvP322zh8+DD++OMPACW/ELdu3YrVq1cjNzcXDx8+xIIFC3Dq1CmMGDECABAZGQlPT0+MHDkSFy9ehFarxf3797F06VIkJSWV2cbrr7+O27dvY9WqVSgqKkJubi5+//13AIC3tzeSkpLw4MED3L59G//5z3+M1uzu7g4/Pz9MmjQJjRo10v1rv0GDBujSpQtmz56N3NxcaLVaXL16tcyhEUMiIiKwefNmpKeno6ioCPPnz8dLL72km0UxJi8vD46OjqhXrx4KCgowf/58k95nynrr1q0LJycnpKWl6Q7lPOm7775DQUEBLly4gM2bNyMsLAwAMGDAAHzzzTe68HXv3r0y/SxASTjcu3cv8vPz4ejoCBcXF73ZFyJbwG88kcS4u7sjMjIS3377LQDgtddew4oVK7Bnzx74+/ujW7duSE9Px/r16/HCCy8AABwdHbFq1So0bdoU7777Ll599VVER0fj/v37eOmll8pso3bt2vjhhx+wf/9+dOnSBSEhIUhJSQFQEnhat26NoKAgvPvuu7pfrsZERETg8OHDukM9pebOnYvi4mKEhYWhffv2GDVqlMmHpjp37ozRo0dj5MiR6Nq1K65du6Z35pExvXv3xvPPPw9/f3+Eh4fDx8fH5Pc+zWeffYZFixbB19cX3377LUJDQ8ss4+fnh+DgYLzzzjt49913dYe8Bg8erBtbX19f9O/fH2lpaWXer9VqsWrVKvj7+8PPzw+//fYbpk2bViX1E1kLmVDZeU8iIiIiM+BMChEREUkSQwoRERFJEkMKERERSRJDChEREUkSQwoRERFJktVdcfbUqVNwcnIyy7pVKpXZ1k36ONbi4niLh2MtHo61eMw51iqVyuDlAawupDg5OZntJlvp6em8gZdIONbi4niLh2MtHo61eMw51k/e9f2veLiHiIiIJIkhhYiIiCSJIYWIiIgkiSGFiIiIJIkhhYiIiCSJIYWIiIgkiSGFiIiIJIkhhYiIiCSJIYWIiIgkyWwhZdKkSejUqRMiIiLKfV0QBMyYMQPBwcFQKBQ4e/asuUohIiIiK2S2kNK3b1+sWLHC4OvJycnIzMzE7t278cUXX2DatGnmKoWIiIiskNnu3dO+fXtcv37d4OuJiYno3bs3ZDIZfHx88OjRI9y6dQsNGjQwV0lERERW7/r9fFy4lSvqNnPuqmCJuyRZ7AaDSqUSnp6euseenp5QKpVGQ4pKpXrqzYgqo7Cw0GzrJn0ca3FxvMXDsRaPrY71qO3XceFukajblAGoX8sBbjXtRd0u74L8BN5RUzwca3FxvMXDsRaPrY61Ol4J/xZ1MDa4pWjbvJd1DZ1825pl3U8LmhYLKXK5HNnZ2brH2dnZkMvlliqHiIjIKqi1WtSv7QTfv9UTbZvpednGFzIDi52CHBQUhK1bt0IQBJw6dQqurq7sRyEiIjJCqwXs7GSWLkMUZptJGTt2LI4dO4b79+8jICAAI0eOhFqtBgAMGDAAgYGBSEpKQnBwMJydnfHll1+aqxQiIqJqQ63Vwl7GkFIp8+fPf+rrMpkMn332mbk2T0REVC1ptIC9vW2EFF5xloiIyIpoBcFmZlIYUoiIiKyIWqOFvY30pDCkEBERWRGtAIYUIiIikh61VgsHhhQiIiKSGls6BZkhhYiIyIrY0inIDClERERWQhAE9qQQERGR9GiFkv8ypBAREZGkqLVaAAwpREREJDGPMwpDChEREUmLbiaFjbNEREQkJZxJISIiIknSCCWdswwpREREJClsnCUiIiJJ4uEeIiIikiQ2zhIREZEkcSaFiIiIJIk9KURERCRJWp7dQ0RERFKk4eEeIiIikiIe7iEiIiJJ0jXO8uweIiIikhLOpBAREZEksXGWiIiIJImNs0RERCRJtna4x8HSBRARET2LXJUayedv4+q1XGQU3bR0OaL6X3YOAIYUIiIiSVpz5Arm7Pzj8aNbFq3FUuq5OFq6BFEwpBARkVXJVRXD3k6G7xQN0axZU0uXI7paTg7wquts6TJEwZBCRERWpUithaO9Hf7m5ojmDVwtXQ6ZERtniYjIqhSptXB04K8vW8C9TEREVqVIw5BiK7iXiYjIqqgeH+6h6o97mYiIrEqRWgsnzqTYBO5lIiKyKsUaLWpwJsUmcC8TEZFVYeOs7eBeJiIiq8LGWdvBvUxERFaliI2zNoN7mYiIrAoP99gO7mUiIrIqKoYUm8G9TEREVqVYw8M9toJ7mYiIrAobZ20H9zIREVkVNs7aDu5lIiKyKmyctR3cy0REZFUYUmwH9zIREVkV9qTYDu5lIiKyGoIgoFgj8N49NoJ7mYiIrEaRRgsAvAuyjeBeJiIiq1GkLgkpPLvHNnAvExGR1dCFFM6k2ASz7uXk5GSEhIQgODgYy5cvL/P6zZs3MWjQIPTu3RsKhQJJSUnmLIeIiKxc6eEehhTb4GCuFWs0GkyfPh2xsbGQy+WIiopCUFAQmjdvrltmyZIlCA0NxT/+8Q9kZGRg2LBh2Ldvn7lKIiIiK1c6k8LGWdtg8l7Oz8+HRqMxecVpaWlo0qQJGjduDEdHR4SHhyMxMVFvGZlMhtzcXABATk4OGjRoYPL6iYjI9hRzJsWmGJxJ0Wq1iI+PR1xcHE6fPg1HR0cUFRWhXr16CAwMxFtvvYUmTZoYXLFSqYSnp6fusVwuR1pamt4yI0aMwJAhQ7B27VoUFBQgNja2Cj4SERFVVyo2ztoUgyFl8ODB6NSpE8aOHYuWLVvCzq7kC/HgwQOkpKTg66+/Ro8ePRAZGVnhjcfHx6NPnz549913cfLkSYwfPx7bt2/Xbas8KpUK6enpFd7m0xQWFppt3aSPYy0ujrd4ONbmdf52IQBAmXUD8ufsONYisdT32mBIiY2NRY0aNco87+bmhpCQEISEhKC4uNjgiuVyObKzs3WPlUol5HK53jIbN27EihUrAAC+vr5QqVS4f/8+PDw8DK7XyckJ3t7ehj9RJaSnp5tt3aSPYy0ujrd4ONbm9cjpLoCbaP73JqhZfJtjLRJzfq+fFn4MTlnk5eXhwYMHBv8AKDfElGrXrh0yMzNx7do1FBUVIT4+HkFBQXrLeHl54ciRIwCAixcvQqVSwd3d/Zk+HBER2Q6e3WNbDM6k9O3bFzKZDIIglHlNJpOVaYIts2IHB8TExGDo0KHQaDTo168fWrRogYULF6Jt27bo3r07Jk6ciClTpmDVqlWQyWSYPXs2ZDJZ5T8VERFVSzy7x7YYDClVcSpwYGAgAgMD9Z4bPXq07ufmzZvjp59+qvR2iIjINujO7mFIsQkGQ8rZs2ef+sY2bdpUeTFERESGaLQCNh6/AaDkcI/hrkiqLgyGlNmzZxt8k0wmw+rVq81SEBERUXlOXbuPvelKAIBHLUdk37VwQWR2BkPKmjVrxKyDiIjoqQqKSg71/PDOa6hXyxHZRpYn62fSZfHPnz+PjIwMFBUV6Z7r3bu32YoiIiL6K83jEznqOhs+s5SqF6MhZfHixUhJScHFixcRGBiI5ORkvPrqqwwpREQkKo22ZCbF/ikX/KTqxeie3rVrF/7zn//gueeew6xZs7Bt2zbk5OSIURsREZHO4xN7YM9LVdgMoyHFyckJdnZ2cHBwQG5uLjw8PJCVlSVGbURERDoabcnhHns7hhRbYfRwT9u2bfHo0SNER0ejb9++cHFxga+vrxi1ERER6TCk2B6jIWXatGkAgAEDBsDf3x+5ublo3bq1uesiIiLSU9o4y+u42Q6ju3rPnj26HpRGjRrh+eefx969e81eGBER0ZPYOGt7jO7pxYsXw9XVVfe4Tp06WLx4sVmLIiIi+is2ztoeoyFF+zi5Pkmj0ZilGCIiIkO0pT0p9gwptsJoSGnbti1mzZqFq1ev4urVq5g1axbv20NERKJTl4YUzqTYDKMhZerUqahRowY+/vhjjBkzBk5OToiJiRGjNiIiIp3Sxlm2pNgOo2f3uLi44JNPPkF+fj5cXFzEqImIiKgMzeOmFAemFJthdE+fOHECYWFhCAsLAwD88ccfutOSiYiIxKIpmUjh4R4bYjSkzJo1CytXroSbmxsAoHXr1khNTTV7YURERE/SnYLMxlmbYdKcmZeXl/6bONVGREQi4ynItsdoT4qXlxdOnDgBmUyG4uJirF69Gs2aNROjNiIiIh0tG2dtjtFdPW3aNKxbtw5KpRIBAQFIT0/HZ599JkZtREREOurHTSlsnLUdRmdS3N3dMW/ePN3jhw8fYv369Rg+fLhZCyMiInqS7hRkHu2xGQbjaFZWFqZOnYr3338fP//8M/Lz8zFnzhy88cYbuHv3rpg1EhERQaPVwt5OBhl7UmyGwZmU8ePHw8/PDz179sTBgwfRr18/eHt745dffkH9+vXFrJGIiAgaLZtmbY3BkPLw4UOMHDkSAODv74+AgAB8/fXXPLOHiIgsQisIbJq1MU/tSXn48CGEx8cA3dzckJOTo/eYiIhILGqNwKZZG2MwpOTm5qJPnz56z5U+lslkSExMNG9lRERET9AKAptmbYzBkLJr1y7UqFFDzFqIiIgMUmu1cLDnTIotMRhS3nzzTXh6esLf3x/+/v5o1KiRmHURERHp0WgBOzbO2hSDIWXz5s24fv06Dh48iC+//BJKpRKvvvoqAgIC4OfnB0dHRzHrJCIiG1dyCrKlqyAxPbVxtlGjRhgwYAAGDBiA4uJipKam4uDBg/jmm2/g7u6O5cuXi1UnERHZOI2WV5u1NUavOLtv3z68/vrrqFGjBjp16oROnToBAJRKpdmLIyIiKsVTkG2P0d2dkJCAnj17Yu7cubh48aLueblcbtbCiIiInqTW8hRkW2N0JuXrr79Gbm4utm/fjkmTJkEmk6Fv374IDw9H7dq1xaiRiIgIWi1PQbY1RkMKANSuXRshISEoLCzE6tWrsWfPHqxcuRKDBg3CoEGDzF0jERFVEwmns3DjfkGF3ptxKxf2TCk2xWhI2bt3L7Zs2YKrV68iMjISP//8Mzw8PFBQUIDw8HCGFCIiMkl+kRofrjtRqXX08GargS0xGlL27NmDd955B+3bt9d73tnZGTNnzjRbYUREVL0Uq0tuqzLhjdYY1KlJhdbhUsO+KksiiTPagfTcc8+VCShfffUVAOjO9CEiIjJG8/jeby6O9qjt5FChP3Y83GNTjIaUw4cPl3kuOTnZLMUQEVH1pdZqAYB9JWQyg4d71q9fjx9//BFXr16FQqHQPZ+Xl4dXXnlFlOKIiKj6eJxRGFLIZAZDikKhQEBAAObPn49x48bpnq9Vqxbc3NxEKY6IiKoP3UwK779DJjIYUmQyGRo1aoSYmJgyrz148IBBhYiInglnUuhZGQwp48aNw7Jly9C3b1/IZDIIjxuegJIAk5iYKEqBRERUPZQ2zjKkkKkMhpRly5YBKLl3DxERUWVp2DhLz8jo2T0ffPABtm/fjoKCil0hkIiICCi5izHAkEKmMxpS3n33XaSmpiIsLAyjRo3Czp07oVKpxKiNiIiqkdLGWTs2zpKJjF5x1s/PD35+ftBoNDh69Cg2bNiAyZMn48SJyl3amIiIbEtp46wDZ1LIRCbdYLCwsBD79u3Djh07cPbsWfTp08fcdRERUTXDxll6VkZDyujRo3H69Gl07doVAwcOhJ+fH+zsjB4lIiIi0sPGWXpWRkNKVFQU5s+fD3t73tSJiIgqjo2z9KwMhpQjR46gU6dOKCgoKPeaKD179jRrYUREVL3w3j30rAyGlN9++w2dOnXC/v37y32dIYWIiJ4FrzhLz8pgSBk1ahQA4MMPP0Tjxo31Xrt27ZpJK09OTsbMmTOh1WoRHR2NYcOGlVkmISEBixcvhkwmQ+vWrTFv3rxnqZ+IiKwET0GmZ2W0A7Y0rDxp9OjRRles0Wgwffp0rFixAvHx8di+fTsyMjL0lsnMzMTy5cvx448/Ij4+HpMnT36G0omIyJpoH5/dw1OQyVQGZ1IuXryIjIwM5OTkYPfu3brnc3NzTbqYW1paGpo0aaKbhQkPD0diYiKaN2+uW2bDhg0YOHAg6tatCwDw8PCo8AchIiJpY+MsPSuDIeXy5cs4cOAAcnJy9PpSatWqhS+++MLoipVKJTw9PXWP5XI50tLS9JbJzMwEALz11lvQarUYMWIEAgICnrpelUqF9PR0o9uviMLCQrOtm/RxrMXF8RYPx9qwK1fzAABXMy/D/pFTpdfHsRaPpcbaYEjp0aMHevTogZMnT8LX19csG9doNLhy5QrWrFmD7Oxs/N///R/i4uJQp04dg+9xcnKCt7e3WepJT08327pJH8daXBxv8XCsDbtUnAVAiebNm6Gl3LXS6+NYi8ecY/208GMwpHz//fd47733sH37dsTHx5d5fcqUKU/dqFwuR3Z2tu6xUqmEXC4vs8zLL7+MGjVqoHHjxnjhhReQmZmJl1566anrJiIi68PGWXpWBkNKs2bNAABt27at0IrbtWuHzMxMXLt2DXK5HPHx8WXO3OnRowfi4+PRr18/3Lt3D5mZmWXOJCIiouqBjbP0rAyGlKCgIADQu0+PVqtFfn4+ateubXzFDg6IiYnB0KFDodFo0K9fP7Ro0QILFy5E27Zt0b17d/j7++PQoUMICwuDvb09xo8fj3r16lXBxyIiIqlh4yw9K6OXxR83bhw+//xz2NnZISoqCrm5uRg8eDCGDh1qdOWBgYEIDAzUe+7J05dlMhkmTZqESZMmVaB0IiKyJrx3Dz0ro9dJycjIQO3atbF3714EBAQgMTER27ZtE6M2IiKqRjiTQs/KaEhRq9UoLi7G3r17ERQUhBo1akDGpiciInpGnEmhZ2U0pLz55psICgpCQUEB2rdvjxs3bpjUk0JERPQkjbakcdae/9AlExntSRk8eDAGDx6se9ywYUOsXr3arEUREVH1o34cUuw4k0ImMhpSioqKsGvXLty4cQNqtVr3/IgRI8xaGBERVS88BZmeldGQMnz4cLi6uqJNmzZwdHQUoyYiIqqG2DhLz8poSFEqlVi5cqUYtRARkZmtS7kC5SPjN4k1h98u3wPAkEKmMxpSfH198b///Q+tWrUSox4iIjKT2zkqfLrljEVraFq/Fg/3kMmMhpTjx49jy5YtaNiwod7hnri4OLMWRkREVav48fGWOf3a4c32f7NwNUTGGQ0p33//vRh1EBGRmZWeAswb/JG1MHqdlIYNGyIrKwtHjx5Fw4YN4ezsDO3jC/IQEZH1KA0pDvYMKWQdjIaUxYsXY8WKFVi+fDkAoLi4GP/617/MXhgREVUtjcCZFLIuRkPKnj17sGTJEjg7OwMA5HI58vLyzF4YERFVLd1Mip3Rv/qJJMHoN7X0Xj2l9+vJz883e1FERFT1dJelZ0YhK2G0cTY0NBQxMTF49OgRNmzYgE2bNqF///5i1EZERFWIjbNkbYyGlCFDhuDQoUOoVasWLl++jFGjRqFLly5i1EZERFWIjbNkbYyGFADo0qULXnzxRaSmpqJu3brmromIiMyAjbNkbQwemXz//fdx/vx5AMCtW7egUCiwadMmjB8/HqtWrRKrPiIiqiJsnCVrY/Cbev36dbRs2RIAsHnzZnTu3BlLly7V9aUQEZF10fWkMKOQlTD4VXVw+PNI0JEjRxAYGAgAqF27Nuz4DScisjq6s3t4uIeshMGeFC8vL6xZswaenp44d+4c/P39AQCFhYVQq9WiFUhERFWDjbNkbQxOicycORMXLlzA5s2bsWDBAtSpUwcAcOrUKfTt21e0AomIqGrwFGSyNgZnUjw8PDB9+vQyz3fs2BEdO3Y0a1FERFT12DhL1sbgN3XKlCm6s3v+Kj8/Hxs3bsQvv/xitsKIiKhq6U5BZkYhK2FwJmXgwIH49ttvcf78ebRo0QLu7u5QqVS4cuUKcnNz0a9fP/Tq1UvMWomIqBI4k0LWxmBI8fb2xsKFC5GXl4czZ87g9u3bqFmzJpo2bYqmTZuKWSMREVUB3ruHrI3RK87WqlULHTp0EKMWIiIyIzbOkrVhniYishE83EPWht9UIiIbwcZZsjYmf1ULCgrMWQcREZkZZ1LI2hj9pp44cQJhYWEIDQ0FAPzxxx+YNm2auesiIqIqxnv3kLUx+lWdNWsWVq5cCTc3NwBA69atkZqaavbCiIioavHePWRtTMrTXl5e+m9iDCcisjo83EPWxugpyF5eXjhx4gRkMhmKi4uxevVqNGvWTIzaiIioCmnZOEtWxuhXddq0aVi3bh2USiUCAgKQnp6Ozz77TIzaiIioCqk5k0JWxuhMyuXLlzFv3jy9544fP45XX33VbEUREVHVY+MsWRujX9UZM2aY9BwREUkbe1LI2hicSTl58iROnjyJe/fuITY2Vvd8bm4uNBqNKMUREVHV+fOy+BYuhMhEBkNKcXEx8vPzodFokJeXp3u+du3aWLRokSjFERFR1dFoBdjJAF0DW48AACAASURBVBlPQSYrYTCk+Pn5wc/PD3369EHDhg3FrImISHSrDl3G1XuVv7L2vXt34Z5xrgoqqnrHr9zjoR6yKkYbZ52dnTFnzhxkZGRApVLpnl+9erVZCyMiEktBkQbT4s7B0cEOTvaV+yWu0Wpgb5dfRZVVvVeauFm6BCKTGQ0pn3zyCUJDQ3HgwAF8/vnn2LJlC9zd3cWojYhIFMVaLQBgfEgrDPVvWql1paenw9vbuyrKIrJ5Rv/J8ODBA0RHR8PBwQF+fn6YNWsWjh49KkZtRESi0GhKz3phrwaRlBidSXFwKFmkQYMGOHDgABo0aICHDx+avTAiIrFoHl+J1Z4hhUhSjIaU4cOHIycnBxMmTMAXX3yBvLw8TJ48WYzaiIhE8edFzhhSiKTEaEjp1q0bAMDV1RVr1qwBUHLFWSKi6uLPi5wxpBBJicGQotFosGPHDiiVSvj7+6Nly5bYv38/li1bhsLCQmzdulXMOomIzObPi5wxpBBJicGQ8umnnyIrKwsvvfQSZsyYgQYNGuDMmTP45JNP0KNHDzFrJCIyK91Mij1DCpGUGAwpZ86cwS+//AI7OzuoVCp06dIFe/bsQb169cSsj4jI7EobZzmTQiQtBk9BrlGjBuweX5nQyckJjRs3ZkAhomqpdCaFZ/cQSYvBmZRLly5BoVDoHl+9elXvcVxcnNGVJycnY+bMmdBqtYiOjsawYcPKXW7Xrl0YNWoUNm7ciHbt2j1L/URElcbGWSJpMhhSEhISKrVijUaD6dOnIzY2FnK5HFFRUQgKCkLz5s31lsvNzcXq1avx8ssvV2p7REQVxcZZImkyGFIqe1PBtLQ0NGnSBI0bNwYAhIeHIzExsUxIWbhwId577z2sXLmyUtsjIqooNs4SSZPR66RUlFKphKenp+6xXC5HWlqa3jJnz55FdnY2Xn/9dZNDikqlQnp6epXWWqqwsNBs6yZ9HGtxcbyf7uLtQgDAjevXkS7cq9S6ONbi4ViLx1JjbbaQYoxWq8Xs2bMxa9asZ3qfk5OT2W7exRuDiYdjLS6O99PlOt8DcBN/b9IE3i2eq9S6ONbi4ViLx5xj/bTwY9I9yQsLC3Hp0qVn2qhcLkd2drbusVKphFwu1z3Oy8vD+fPnMXjwYAQFBeHUqVMYPnw4Tp8+/UzbISKqrD8vi2/hQohIj9H/Jfft24fIyEgMHToUQEni+eCDD4yuuF27dsjMzMS1a9dQVFSE+Ph4BAUF6V53dXVFSkoK9u3bh3379sHHxwdLlizh2T1EJDrdKchsnCWSFKMhZfHixdi4cSPq1KkDAPD29saNGzeMrtjBwQExMTEYOnQowsLCEBoaihYtWmDhwoVITEysfOVERFWEjbNE0mS0J8XBwQGurq4VWnlgYCACAwP1nhs9enS5y5bevJCISGy84iyRNBkNKc2bN0dcXBw0Gg0yMzOxZs0a+Pr6ilEbEZEoNJrSi7mxKYVISoz+Hzl16lRkZGTA0dER48aNQ+3atfHpp5+KURsRkSh0MynMKESSYnQm5dKlSxgzZgzGjBkjRj1ERKLjvXuIpMloSJk9ezbu3LmDkJAQhIWFoWXLlmLURUQkGt67h0iajIaUNWvW4Pbt29ixYwdiYmKQl5eH0NBQfPjhh2LUR0Rkdlo2zhJJkklHYOvXr4/Bgwfj888/R+vWrfHdd9+Zuy4iItGo2ThLJElGZ1IuXryIhIQE7N69G25ubggNDcXEiRPFqI2ISBRsnCWSJqMhZfLkyQgNDcWKFSv0LmtPRFRd/NmTwpRCJCVGQ8p///tfMeogIrIY3ruHSJoMhpTRo0dj4cKFUCgU5b4eFxdntqKIiMTEe/cQSZPBkFJ6wbalS5eKVgwRkSXwcA+RNBn8P7JBgwYAgPXr16Nhw4Z6f9avXy9agURE5qZl4yyRJBn9X/Lw4cNlnktOTjZLMURElqDmTAqRJBk83LN+/Xr8+OOPuHbtml5fSl5eHl555RVRiiMi+iutVsC8Pf/D7RxVla0zPSsHAGdSiKTGYEhRKBQICAjA/PnzMW7cON3ztWrVgpubmyjFERH9VdajQny7/yLqOteAi6N9la23czMPONozpRBJicGQIpPJ0KhRI8TExJR57cGDBwwqRGQRmsdXh50a8SKiXm1k4WqIyJwMhpRx48Zh2bJl6Nu3L2QyGYTHjWVASYBJTEwUpUAioieptVoAvBkgkS0wGFKWLVsGANi3b59oxRARGfPnmTgMKUTVndEDsMePH0d+fj4AYNu2bZg1axZu3rxp9sKIiMrz55k4DClE1Z3RkDJt2jQ4Ozvjjz/+QGxsLP72t79h/PjxYtRGRFSG7hL2vDosUbVnNKQ4ODhAJpNh7969GDhwIAYOHIi8vDwxaiMiKkN3CXvOpBBVe0ZDSq1atbBs2TL88ssveP3116HVaqFWq8WojYioDA0P9xDZDKMhZcGCBXB0dMSXX36J+vXrIzs7G0OGDBGjNiKiMtg4S2Q7jIaU+vXrQ6FQICcnB/v374eTkxN69+4tRm1ERGWoNZxJIbIVRkNKQkICoqOjsXPnTuzYsUP3MxGRJWgENs4S2QqD10kptXTpUmzcuBEeHh4AgHv37uGdd97BG2+8YfbiiIj+io2zRLbD6EyKIAi6gAIAbm5uelefJSISE0MKke0wOpPStWtXDBkyBOHh4QBKDv8EBASYvTAiovKUNs4ypBBVf0ZDyoQJE7B7924cP34cAPDmm28iODjY7IUREZWHjbNEtsNgSMnMzMScOXNw7do1tGzZEhMmTIBcLhezNiKiMrRsnCWyGQZ7UiZPnoxu3bph0aJFaNOmDb744gsx6yIiKpfu3j32DClE1Z3BmZS8vDz0798fANC0aVP06dNHtKKIiAzhvXuIbIfBkKJSqXDu3DndmTyFhYV6j9u0aSNOhURET+DZPUS2w2BIqV+/PmbNmqV7/Nxzz+key2QyrF692vzVERH9Be/dQ2Q7DIaUNWvWiFkHEZFJeO8eItth9GJuRERSouZMCpHNYEghIquiZeMskc1gSCEiq6Jm4yyRzTDp3j3btm3D4sWLAQA3b95EWlqa2QsjIioPz+4hsh1GQ8q0adNw6tQpxMfHAwBq1aqFzz//3OyFERGVh/fuIbIdRkNKWloaPvvsMzg5OQEA6tati+LiYrMXRkRUHjbOEtkOoyHFwcEBGo0GssdNavfu3YOdHVtZiMgy2DhLZDuM3gV50KBB+Oijj3D37l0sWLAAO3fuxMcffyxGbUREZXAmhch2GA0pvXr1Qps2bXD06FEIgoDvvvsOzZo1E6M2IqIydDMpDClE1Z7RkHLz5k04OzujW7dues89//zzZi2MiKg8aq3AplkiG2E0pLz//vu6n1UqFa5fv46///3vurN9iIjEpBEYUohshdGQEhcXp/f47NmzWL9+vdkKIhLTmiOZOHLprqXLMLtHj3JQ50S+pcuoEn9k5cCeTbNENsFoSPmrNm3a8GJuVG2s+PUy7uUWwbNuTUuXYlYqVRGcCnItXUaVsLeTIbSdp6XLICIRGA0psbGxup+1Wi3OnTuHBg0amLUoIjF1926Ab97ytXQZZpWeng5vb29Ll0FE9EyMhpS8vDzdz/b29ggMDERISIhZiyIiIiJ6akjRaDTIy8vDhAkTKrTy5ORkzJw5E1qtFtHR0Rg2bJje67Gxsfj5559hb28Pd3d3fPnll2jYsGGFtkVERETVi8FLx6rVatjb2+PEiRMVWrFGo8H06dOxYsUKxMfHY/v27cjIyNBbxtvbG5s2bUJcXBxCQkLw1VdfVWhbREREVP0YDCnR0dEAgNatW+ODDz7A1q1bsXv3bt0fY9LS0tCkSRM0btwYjo6OCA8PR2Jiot4yHTt2hLOzMwDAx8cH2dnZlfksREREVI0Y7UkpKipCvXr1kJKSovd8z549n/o+pVIJT88/O/DlcvlTzwrauHEjAgICjJVDRERENsJgSLl79y5iY2PRokULyGQyCI9vjw5Ad7PBqrJt2zacOXMGa9euNbqsSqVCenp6lW6/VGFhodnWTfqkMtZFRUV4+OiRJGoxJ6mMty3gWIuHYy0eS421wZCi1Wr1zux5VnK5XO/wjVKphFwuL7Pc4cOHsXTpUqxduxaOjo5G1+vk5GS2Uyl5mqZ4pDLWjo7ZqFunjiRqMSepjLct4FiLh2MtHnOO9dPCj8GQUr9+fYwYMaLCG23Xrh0yMzNx7do1yOVyxMfHY968eXrLnDt3DjExMVixYgU8PDwqvC0iIiKqfgyGlCcP71RoxQ4OiImJwdChQ6HRaNCvXz+0aNECCxcuRNu2bdG9e3fMnTsX+fn5GD16NADAy8sLS5curdR2iYiIqHowGFJWrVpV6ZUHBgYiMDBQ77nSQFJV2yAiIqLqyeApyG5ubmLWQURERKTHYEghIiIisiSGFCIiIpIkhhQiIiKSJIYUIiIikiSGFCIiIpIkhhQiIiKSJIYUIiIikiSGFCIiIpIkhhQiIiKSJIYUIiIikiSGFCIiIpIkhhQiIiKSJIYUIiIikiSGFCIiIpIkhhQiIiKSJIYUIiIikiSGFCIiIpIkhhQiIiKSJIYUIiIikiQHSxdA5rPp+HVsPXXD0mWUKy8vD7UOP7J0Gch+WAg0tnQVRERUHoaUamzLyRs4efU+Wnq6WrqUMgqKtRBUakuXgRefr4Pu3nJLl0FEROVgSKnmWnvVwabhnS1dRhnp6enw9va2dBlERCRh7EkhIiIiSWJIISIiIkliSCEiIiJJYkghIiIiSWJIISIiIkliSCEiIiJJYkghIiIiSWJIISIiIkliSCEiIiJJYkghIiIiSWJIISIiIkliSCEiIiJJYkghIiIiSWJIISIiIkliSCEiIiJJYkghIiIiSWJIISIiIkliSCEiIiJJYkghIiIiSWJIISIiIkliSCEiIiJJYkghIiIiSWJIISIiIkliSCEiIiJJYkghIiIiSWJIISIiIkliSCEiIiJJYkghIiIiSTJrSElOTkZISAiCg4OxfPnyMq8XFRXh448/RnBwMKKjo3H9+nVzlkNERERWxGwhRaPRYPr06VixYgXi4+Oxfft2ZGRk6C3z888/o06dOtizZw/eeecdfP311+Yqh4iIiKyMg7lWnJaWhiZNmqBx48YAgPDwcCQmJqJ58+a6Zfbt24cRI0YAAEJCQjB9+nQIggCZTGausgxamnQRW1NvwHn/PdG3bS4Zyly09HS1dBlEREQVYraQolQq4enpqXssl8uRlpZWZhkvL6+SQhwc4Orqivv378Pd3d3gelUqFdLT06u83kf3HqKmPSBTq6p83ZbSwqMGujxvb5bxqqzCwkJJ1lVdcbzFw7EWD8daPJYaa7OFFHNxcnKCt7d3la/X2xtIT083y7qpLI61uDje4uFYi4djLR5zjvXTwo/ZelLkcjmys7N1j5VKJeRyeZllsrKyAABqtRo5OTmoV6+euUoiIiIiK2K2kNKuXTtkZmbi2rVrKCoqQnx8PIKCgvSWCQoKwpYtWwAAu3btQseOHS3Sj0JERETSY7bDPQ4ODoiJicHQoUOh0WjQr18/tGjRAgsXLkTbtm3RvXt3REVF4V//+heCg4NRt25dLFiwwFzlEBERkZUxa09KYGAgAgMD9Z4bPXq07mcnJycsWrTInCUQERGRleIVZ4mIiEiSGFKIiIhIkhhSiIiISJIYUoiIiEiSGFKIiIhIkhhSiIiISJIYUoiIiEiSGFKIiIhIkhhSiIiISJJkgiAIli7iWZw6dQpOTk6WLoOIiIiqgEqlgo+PT7mvWV1IISIiItvAwz1EREQkSQwpREREJEkMKURERCRJDClEREQkSQwpREREJEk2GVKSk5MREhKC4OBgLF++vMzrRUVF+PjjjxEcHIzo6Ghcv37dAlVWD8bGOjY2FmFhYVAoFHj77bdx48YNC1RZPRgb61K7du1Cq1atcPr0aRGrq35MGe+EhASEhYUhPDwc48aNE7nC6sPYWN+8eRODBg1C7969oVAokJSUZIEqq4dJkyahU6dOiIiIKPd1QRAwY8YMBAcHQ6FQ4OzZs+YtSLAxarVa6N69u3D16lVBpVIJCoVCuHDhgt4ya9euFaZOnSoIgiBs375dGD16tCVKtXqmjPWRI0eE/Px8QRAEYd26dRzrCjJlrAVBEHJycoR//OMfQnR0tJCWlmaBSqsHU8b78uXLQmRkpPDgwQNBEAThzp07lijV6pky1lOmTBHWrVsnCIIgXLhwQejWrZslSq0Wjh07Jpw5c0YIDw8v9/UDBw4IQ4YMEbRarXDy5EkhKirKrPXY3ExKWloamjRpgsaNG8PR0RHh4eFITEzUW2bfvn3o06cPACAkJARHjhyBwMvJPDNTxrpjx45wdnYGAPj4+CA7O9sSpVo9U8YaABYuXIj33nuPF0SsJFPGe8OGDRg4cCDq1q0LAPDw8LBEqVbPlLGWyWTIzc0FAOTk5KBBgwaWKLVaaN++ve47W57ExET07t0bMpkMPj4+ePToEW7dumW2emwupCiVSnh6euoey+VyKJXKMst4eXkBABwcHODq6or79++LWmd1YMpYP2njxo0ICAgQo7Rqx5SxPnv2LLKzs/H666+LXF31Y8p4Z2Zm4vLly3jrrbfQv39/JCcni11mtWDKWI8YMQJxcXEICAjAsGHDMGXKFLHLtBl/3R+enp5P/Xu9smwupJA0bdu2DWfOnMHQoUMtXUq1pNVqMXv2bEyYMMHSpdgMjUaDK1euYM2aNZg3bx6mTp2KR48eWbqsaik+Ph59+vRBcnIyli9fjvHjx0Or1Vq6LKoCNhdS5HK53iEFpVIJuVxeZpmsrCwAgFqtRk5ODurVqydqndWBKWMNAIcPH8bSpUuxZMkSODo6illitWFsrPPy8nD+/HkMHjwYQUFBOHXqFIYPH87m2Qoy9e+RoKAg1KhRA40bN8YLL7yAzMxMkSu1fqaM9caNGxEaGgoA8PX1hUql4uy3mfx1f2RnZ5f793pVsbmQ0q5dO2RmZuLatWsoKipCfHw8goKC9JYJCgrCli1bAJScCdGxY0fIZDJLlGvVTBnrc+fOISYmBkuWLOEx+0owNtaurq5ISUnBvn37sG/fPvj4+GDJkiVo166dBau2XqZ8t3v06IFjx44BAO7du4fMzEw0btzYEuVaNVPG2svLC0eOHAEAXLx4ESqVCu7u7pYot9oLCgrC1q1bIQgCTp06BVdXV7P2ADmYbc0S5eDggJiYGAwdOhQajQb9+vVDixYtsHDhQrRt2xbdu3dHVFQU/vWvfyE4OBh169bFggULLF22VTJlrOfOnYv8/HyMHj0aQMlfNkuXLrVw5dbHlLGmqmPKePv7++PQoUMICwuDvb09xo8fzxnZCjBlrCdOnIgpU6Zg1apVkMlkmD17Nv9hWUFjx47FsWPHcP/+fQQEBGDkyJFQq9UAgAEDBiAwMBBJSUkIDg6Gs7MzvvzyS7PWw7sgExERkSTZ3OEeIiIisg4MKURERCRJDClEREQkSQwpREREJEkMKURERCRJDClEVcDb2xuRkZG6P0+7c7avr2+ltzdx4kQEBQUhMjISffr0wcmTJ595HZ9++ikyMjIAoMxp32+99ValawT+HJeIiAh88MEHRq+4mp6eXqE72N66dQvvv/8+AOD+/fsYNGgQfH19MX369ArVvWTJEoSHh0OhUCAyMhK///57hdZjyHvvvacbi9WrVyM0NBTjxo1DYmLiU+9gDfy5b65fv464uDij29q/fz8WLlxY+aKJLMGsty8kshE+Pj5mWdaQCRMmCDt27BAEQRAOHjwoREREVGp9VVGTsfWOHz9e+O677566/KZNm4TPP//8mbcze/ZsYc+ePYIgCEJeXp7w22+/CevXr6/Quk6cOCH0799fUKlUgiAIwt27d4Xs7OxnXo+pQkJChKysrGd+39GjR4Vhw4YZXU6r1QqRkZG6u40TWRPOpBCZQV5eHt5++2306dMHCoUCe/fuLbPMrVu3MHDgQN1MQ2pqKgDg119/xZtvvok+ffpg1KhRyMvLe+q22rdvj6tXrwIAYmNjERERgYiICKxatQoAkJ+fj2HDhqFXr16IiIhAQkICAGDQoEE4ffo0vv76axQWFiIyMhLjxo0D8Odsz5gxY3DgwAHdtiZOnIidO3dCo9Fgzpw56NevHxQKBX766SejY+Lj46O7EVlaWhrefPNN9O7dG2+99RYuXbqEoqIiLFq0CAkJCYiMjERCQgLy8/MxadIkREVFoXfv3uWOIwDs3r1bd3NKFxcXvPbaaxW+0/Pt27dRr1493S0a3N3ddZf9DgoKwty5c6FQKBAVFYUrV64AKLmi7MiRI9GvXz/069cPx48fB1DyPZg0aRIUCgUUCgV27dqlW8+9e/cQExOD69ev47333sOqVauwefNm3ezPnTt38NFHH6FXr17o1asXTpw4AeDPfTNv3jykpqYiMjISq1atwsCBA5Genq77HAMGDMAff/wBmUwGPz8/7N+/v0LjQWRRlk5JRNVB69athV69egm9evUSPvzwQ6G4uFjIyckRBKHkX+I9evQQtFqtIAh/zi6sXLlSN7OgVquFnJwc4e7du8I//vEPIS8vTxAEQVi2bJnw73//u8z2npxJSUhIEKKiooTTp08LERERQl5enpCbmyuEhYUJZ8+eFXbu3Cl8+umnuvc+evRIEARB+L//+z8hLS1Nr6ZSpY93794tjB8/XhAEQVCpVEJAQIBQUFAg/PTTT8K3336re75Pnz7C1atXy9RZuh61Wi2MHDlSSEpKEgRBEHJycoTi4mJBEATh0KFDwogRIwRBKDuTMm/ePGHr1q2CIAjCw4cPhZ49e+rGptTVq1eFPn36lNl2RWdlcnNzhV69egk9e/YUPvvsMyElJUX3Wrdu3XT7bMuWLbqZjLFjxwq//fabIAiCcOPGDeGNN94QBEEQ5s6dK8yYMUP3/gcPHujWc/fu3TI/P1nz6NGjhdjYWEEQSsavdL+VjulfZ1I2b96s29alS5f0xmTbtm3C9OnTn3ksiCzN5i6LT2QONWvWxLZt23SPi4uLMX/+fPz222+ws7ODUqnEnTt3UL9+fd0y7dq1w+TJk6FWq9GjRw94e3tj//79yMjIwIABA3Tr8fHxKXebc+fOxZIlS+Du7o6ZM2fiyJEj6NGjB1xcXAAAwcHBSE1Nhb+/P+bMmYOvvvoK3bp1w2uvvWby5woICMDMmTNRVFSE5ORkvPbaa6hZsyYOHTqE//3vf7qZgZycHFy5cqXMvWlKZ2iUSiWaNWuGLl266JafMGECrly5AplMhuLi4nK3/+uvv2Lfvn344YcfAAAqlQpZWVlo1qyZbpnSmY+qUqtWLWzevBmpqalISUnBmDFjMG7cOPTt2xcAEBERAQAIDw/HrFmzAJTcJLO0vwcAcnNzkZeXhyNHjmD+/Pm65+vWrWtyHUePHsXcuXMBAPb29nB1dX3q8m+88Qa+++47jB8/Hps2bdLVCwAeHh64deuWydsmkgqGFCIziIuLw71797B582bUqFEDQUFBUKlUesu0b98ea9euRVJSEiZOnIh//vOfqFOnDrp06aL3i82Q8ePH44033tA9Lr3B2l/9/e9/x+bNm5GUlIRvvvkGHTt2xIgRI0z6HE5OTvDz88PBgwexY8cOhIWFAQAEQcCUKVPg7+//1PeXhreCggIMGTIE69atw+DBg7Fw4UJ06NAB3377La5fv47BgwcbXMeiRYvQtGnTp26jqKjIpM9T6vfff0dMTAwAYNSoUWXubWRvb48OHTqgQ4cOaNmyJbZu3ar3S/+vtFotNmzYUOFDTFXB2dkZnTt3RmJiInbs2IHNmzfrXlOpVBatjaii2JNCZAY5OTnw8PBAjRo1cPToUdy4caPMMjdu3MBzzz2H/v37Izo6GmfPnoWPjw9OnDih63XIz8/H5cuXTdrma6+9hr1796KgoAD5+fnYu3cvXnvtNSiVSjg7OyMyMhJDhgzBuXPnyrzXwcHB4GxGWFiYbmahNJR07doVP/74o+49ly9fRn5+vsHanJ2dMWXKFMTGxkKtViMnJ0fX51F6x3GgZBbjyR6crl27Yu3atRAe32KsvNpfeOGFcsf3aV5++WVs27YN27ZtKxNQLl26hMzMTN3j9PR0PP/887rHO3bsAAAkJCTo+kO6du2KNWvW6L0HADp37ox169bpnn/48KHJNXbq1Anr168HAGg0GuTk5Oi9/texAoDo6GjMmDED7dq105u1yczMRMuWLU3eNpFUMKQQmYFCocCZM2egUCiwbdu2cmcCjh07hsjISPTu3RsJCQkYPHgw3N3dMWvWLIwdOxYKhQJvvvkmLl26ZNI227Rpg759+yI6Ohr9+/dHVFQUXnzxRZw/fx5RUVGIjIzE4sWLMXz48DLv7d+/P3r16qVrnH1Sly5d8Ntvv6Fz5866ZtLo6Gg0b94cffv2RUREBGJiYqDRaJ5a34svvohWrVph+/btGDp0KObPn4/evXvr7rAKAB06dEBGRoaucfbDDz+EWq1Gr169EB4eXu6ptC4uLmjcuLEu2AEljamzZ8/Gli1bEBAQoHcoxpj8/HxMnDgRYWFhUCgUuHjxot7M08OHD6FQKLB69WpMmjQJQMnp3KX7OywsDD/++CMAYPjw4Xj06BEiIiLQq1cvpKSkmFzHp59+ipSUFCgUCvTt27fMZ2jVqhXs7OzQq1cvXZN027ZtUbt27TKzPikpKQgMDDR520RSwbsgE5HV27NnD86cOYMxY8aYdTtBQUHYuHEj3N3dzbqdilIqlRg8eDB27NgBO7uSf4PeuXMH48aNw3/+8x8LV0f07DiTQkRWLzg4GI0aNbJ0GRa1detW9O/fHx9//LEuoADAzZs3MXHiRAtWRlRxnEkhIiIiSeJMChEREUkSQwoRERFJVuxBpwAAACNJREFUEkMKERERSRJDChEREUkSQwoRERFJEkMKERERSdL/A+eSKKUFBBD4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.xlim = ([0.0, 1.0])\n",
    "plt.ylim = ([0.0, 1.0])\n",
    "plt.title('ROC curve for all labels')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity/Recall)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***AUC*** = the percentage of the ROC plot that is underneath the curve.  \n",
    "\n",
    "AUC summarizes the performance of a classifier in a **single number**.  It says, *\"If you randomly chose one positive and one negative observation, what is the likelihood that your classifier will assign a higher predicted probability to the positive observation.\"*\n",
    "\n",
    "**An AUC of ~ 0.8 is very good while an AUC of ~ 0.5 represents a poor classifier.**\n",
    "\n",
    "The ROC curve and AUC are insensitive to whether your predicted probabilities are properly calibrated to actually represent probabilities of class membership (e.g., it works if predicted probs range from 0.9 to 1 instead of 0 to 1).  All the AUC metric cares about is how well your classifier separated the two classes\n",
    "\n",
    "Notes:\n",
    "1.  AUC is useful even when there is **high class imbalance** (unlike classification accuracy)\n",
    "2.  AUC is useful even when predicted probabilities are not properly calibrated (e.g., not between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3948717948717949\n"
     ]
    }
   ],
   "source": [
    "print(skm.roc_auc_score(eval_targs, eval_probs, average='weighted', sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Overall metrics - is_example_prob_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62583274"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mse\n",
    "skm.mean_squared_error(targs[0], probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7910959085295265"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rmse\n",
    "math.sqrt(skm.mean_squared_error(targs[0], probs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6270062"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mae\n",
    "skm.mean_absolute_error(targs[0], probs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try: del inf_learn\n",
    "except: pass\n",
    "finally: gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "inf_learn = load_learner(STANDARD_THEME_META_PATH/f'{m_pre}{base_model_name}{m_suf}_export.pkl')\n",
    "inf_learn.loss_func.loss_funcs[1].func.weight = inf_learn.loss_func.loss_funcs[1].func.weight.to(dls.device)\n",
    "dls = get_meta_standard_theme_train_dls(df, hf_arch, hf_tokenizer)\n",
    "inf_learn.dls = dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probs, targs, losses = inf_learn.get_preds(with_loss=True, reorder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "f05 = OptimalMultiThresholdMetrics(beta=0.5, start=0.05, end=.9, sigmoid=False, average='binary', sample_weight=None)\n",
    "f1 = OptimalMultiThresholdMetrics(beta=1, start=0.05, end=.9, sigmoid=False, average='binary', sample_weight=None)\n",
    "f2 = OptimalMultiThresholdMetrics(beta=2, start=0.05, end=.9, sigmoid=False, average='binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_example_prob_true = torch.softmax(probs[1], dim=-1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29000000000000004 0.29000000000000004 0.29000000000000004\n",
      "Fowards Only\n",
      "-------------\n",
      "f05:\tOptimal threshold = 0.29000000000000004\t(Accuracy = 0.061010487377643585)\n",
      "f1:\tOptimal threshold = 0.29000000000000004\t(Accuracy = 0.061010487377643585)\n",
      "f2:\tOptimal threshold = 0.29000000000000004\t(Accuracy = 0.061010487377643585)\n",
      "\n",
      "Accuracy: 0.9914203882217407\n"
     ]
    }
   ],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "threshold_f05 = f05.opt_th(is_example_prob_true, targs[1])\n",
    "threshold_f1 = f1.opt_th(is_example_prob_true, targs[1])\n",
    "threshold_f2 = f2.opt_th(is_example_prob_true, targs[1])\n",
    "\n",
    "print(threshold_f05, threshold_f1, threshold_f2)\n",
    "\n",
    "# determine accuracy based on optimal threshold\n",
    "val_acc_f05 = accuracy_multi(is_example_prob_true, targs[1], threshold_f05, sigmoid=False).item()\n",
    "val_acc_f1 = accuracy_multi(is_example_prob_true, targs[1], threshold_f1, sigmoid=False).item()\n",
    "val_acc_f2 = accuracy_multi(is_example_prob_true, targs[1], threshold_f2, sigmoid=False).item()\n",
    "\n",
    "print('Fowards Only\\n-------------')\n",
    "print(f'f05:\\tOptimal threshold = {threshold_f05}\\t(Accuracy = {val_acc_f05})')\n",
    "print(f'f1:\\tOptimal threshold = {threshold_f1}\\t(Accuracy = {val_acc_f1})')\n",
    "print(f'f2:\\tOptimal threshold = {threshold_f2}\\t(Accuracy = {val_acc_f2})')\n",
    "\n",
    "print(f'\\nAccuracy: {accuracy_multi(is_example_prob_true, targs[1], sigmoid=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6238375, 0.61637735, 0.7850970345557375)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = skm.mean_absolute_error(targs[0], probs[0])\n",
    "mse = skm.mean_squared_error(targs[0], probs[0])\n",
    "rmse = math.sqrt(skm.mean_squared_error(targs[0], probs[0]))\n",
    "\n",
    "mae, mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9456282258033752"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_valid_loss = losses.mean().item(); final_valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build our training loop for hyperparam optimization and final training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; del dls\n",
    "except: pass\n",
    "finally: gc.collect(); torch.cuda.empty_cache()\n",
    "    \n",
    "yyyymmdd = datetime.today().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastAIPruningCallbackv2(TrackerCallback):\n",
    "    def __init__(self, trial, monitor='valid_loss', **kwargs) -> None:\n",
    "        super().__init__(monitor=monitor, **kwargs)\n",
    "        self._trial = trial\n",
    "\n",
    "    def after_epoch(self) -> None:\n",
    "        super().after_epoch()\n",
    "        \n",
    "        value = self.recorder.values[-1][self.idx]\n",
    "        if value is None: return\n",
    "\n",
    "        self._trial.report(float(value), step=self.epoch)\n",
    "        if self._trial.should_prune():\n",
    "            message = \"Trial was pruned at epoch {}.\".format(self.epoch)\n",
    "            raise optuna.TrialPruned(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train(params, trial=None, train_config={}):\n",
    "          \n",
    "    config = {**meta_standard_themes_train_config, **train_config}    \n",
    "    m_pre, m_suf, base_model_name = config['m_pre'], config['m_suf'], config['base_model_name']\n",
    "    full_model_name = f'{m_pre}{base_model_name}{m_suf}'\n",
    "    \n",
    "    # 1. grab our huggingface objects\n",
    "    task = HF_TASKS_AUTO.SequenceClassification\n",
    "    hf_config = AutoConfig.from_pretrained(params[\"pretrained_model_name\"])\n",
    "\n",
    "    if (f'{params[\"pretrained_model_name\"]}_config_overrides' in params):\n",
    "        hf_config.update(params[f'{params[\"pretrained_model_name\"]}_config_overrides'])\n",
    "    else:\n",
    "        config_overrides = { k:v for k,v in params.items() if (k in hf_config.to_dict()) }\n",
    "        hf_config.update(config_overrides)\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(params[\"pretrained_model_name\"], \n",
    "                                                                                   task=task, \n",
    "                                                                                   config=hf_config)\n",
    "    \n",
    "    # 2. build our dls and learner\n",
    "    df = get_meta_standard_theme_train_data(train_config=config)\n",
    "    train_df, valid_df = df[df.is_valid == False], df[df.is_valid == True]\n",
    "    \n",
    "    set_seed(TL_RAND_SEED)\n",
    "    dls = get_meta_standard_theme_train_dls(df, hf_arch, hf_tokenizer, train_config=config, use_cache=False)\n",
    "    \n",
    "    set_seed(TL_RAND_SEED)\n",
    "    learn, fit_cbs = get_learner(hf_model, \n",
    "                                 dls, \n",
    "                                 train_df=None, \n",
    "                                 use_weighted_loss=params[\"use_weighted_loss\"], \n",
    "                                 use_fp16=params[\"use_fp16\"],\n",
    "                                 add_save_model_cb=params['save_model'],\n",
    "                                 train_config=config)\n",
    "    \n",
    "    if (trial is not None): learn.add_cb(FastAIPruningCallbackv2(trial=trial, monitor=params['optimize_for']))\n",
    "    \n",
    "    # 3. train\n",
    "    with learn.no_logging(): \n",
    "        set_seed(TL_RAND_SEED)\n",
    "        learn.fit_one_cycle(params[\"n_frozen_epochs\"], lr_max=params[\"frozen_lr\"], cbs=fit_cbs)\n",
    "        \n",
    "        learn.unfreeze()\n",
    "        set_seed(TL_RAND_SEED)\n",
    "        learn.fit_one_cycle(params[\"n_unfrozen_epochs\"], \n",
    "                            lr_max=slice(params[\"unfrozen_lr_min\"], params[\"unfrozen_lr_max\"]), \n",
    "                            cbs=fit_cbs)\n",
    "        \n",
    "        # export model for inference (SavedModelCallback already saves the best model if save_mode=True)\n",
    "        if (trial is None): learn.export(fname=f\"{yyyymmdd}_{config['export_filename']}\")\n",
    "        \n",
    "    # 4. evaluate\n",
    "    scores = dict(zip(learn.recorder.metric_names[2:], learn.validate()))\n",
    "    \n",
    "    try:\n",
    "        if (trial is not None): return scores[params['optimize_for']]\n",
    "        \n",
    "        probs, targs, losses = learn.get_preds(dl=dls.valid, with_loss=True)\n",
    "    \n",
    "        # determine optimal threshold based on desired f-score\n",
    "        average, sample_weight = config['opt_beta_average'], config['opt_beta_sample_weight']\n",
    "\n",
    "        f05 = OptimalMultiThresholdMetrics(beta=0.5, start=0.05, end=.5, sigmoid=False, \n",
    "                                           average=average, sample_weight=sample_weight)\n",
    "        f1 = OptimalMultiThresholdMetrics(beta=1, start=0.05, end=.5, sigmoid=False, \n",
    "                                           average=average, sample_weight=sample_weight)\n",
    "        f2 = OptimalMultiThresholdMetrics(beta=2, start=0.05, end=.5, sigmoid=False, \n",
    "                                           average=average, sample_weight=sample_weight)\n",
    "\n",
    "        is_example_prob_true = torch.softmax(probs[1], dim=-1)[:,1]\n",
    "        scores['is_example_f05'], scores['is_example_f1'], scores['is_example_f2'] = {}, {}, {}\n",
    "\n",
    "        scores['is_example_f05']['threshold'] = f05.opt_th(is_example_prob_true, targs[1])\n",
    "        scores['is_example_f1']['threshold'] = f1.opt_th(is_example_prob_true, targs[1])\n",
    "        scores['is_example_f2']['threshold'] = f2.opt_th(is_example_prob_true, targs[1])\n",
    "\n",
    "        scores['is_example_f05']['score'] = f05.opt_fscore(is_example_prob_true, targs[1])\n",
    "        scores['is_example_f1']['score'] = f1.opt_fscore(is_example_prob_true, targs[1])\n",
    "        scores['is_example_f2']['score'] = f2.opt_fscore(is_example_prob_true, targs[1])\n",
    "\n",
    "        scores['sentiment'] = {\n",
    "            'mae': skm.mean_absolute_error(targs[0], probs[0]).item(),\n",
    "            'mse': skm.mean_squared_error(targs[0], probs[0]).item(),\n",
    "            'rmse': math.sqrt(skm.mean_squared_error(targs[0], probs[0]).item())\n",
    "        }\n",
    "        \n",
    "        # save scores from validation set if mode == training\n",
    "        with open(f\"{config['learner_path']}/{yyyymmdd}_{full_model_name}_train_scores.json\", 'w') as f:\n",
    "            json.dump(scores, f, indent=4)\n",
    "        \n",
    "        # save train/validation probs, targs, losses for review\n",
    "        test_dl = dls.test_dl(df, with_labels=True)\n",
    "        probs, targs, losses = learn.get_preds(dl=test_dl, with_loss=True)\n",
    "        is_example_prob_true = torch.softmax(probs[1], dim=-1)[:,1]\n",
    "\n",
    "        probs_df = pd.DataFrame(np.concatenate((probs[0].numpy(), is_example_prob_true[:,None]), axis=-1), \n",
    "                                columns=['pred_sentiment', 'prob_is_example'])\n",
    "        targs_df = pd.DataFrame(np.concatenate((targs[0].numpy()[:,None], targs[1].numpy()[:,None]), axis=-1), \n",
    "                                columns= ['targ_sentiment', 'targ_is_example'])\n",
    "        losses_df = pd.DataFrame(losses.numpy(), columns=['loss'])\n",
    "        final_df = pd.concat([df.reset_index(), probs_df, targs_df, losses_df], axis=1)\n",
    "\n",
    "        final_df.to_csv(f\"{config['learner_path']}/{yyyymmdd}_{full_model_name}_train_results.csv\", index=False)\n",
    "        return scores, final_df\n",
    "    \n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; del dls \n",
    "        del hf_arch; del hf_config; del hf_tokenizer; del hf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_trial_cleanup(study, trial):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def objective(trial, train_config={}):\n",
    "    opt_params = {\n",
    "        'pretrained_model_name': trial.suggest_categorical(\"pretrained_model_name\", [\"facebook/bart-base\"]),\n",
    "        \n",
    "        'save_model': trial.suggest_categorical(\"save_model\", [True, False]), \n",
    "        'use_weighted_loss': trial.suggest_categorical(\"use_weighted_loss\", [True, False]),\n",
    "        'use_fp16': trial.suggest_categorical(\"use_fp16\", [True]),\n",
    "        'n_frozen_epochs': trial.suggest_int(\"n_frozen_epochs\", 1, 3),\n",
    "        'n_unfrozen_epochs': trial.suggest_int(\"n_unfrozen_epochs\", 0, 10),\n",
    "        'frozen_lr': trial.suggest_loguniform(\"frozen_lr\", 1e-7, 1e-6),\n",
    "        'unfrozen_lr_max': trial.suggest_loguniform(\"unfrozen_lr_max\", 1e-7, 1e-6),\n",
    "        'unfrozen_lr_min': trial.suggest_loguniform(\"unfrozen_lr_min\", 1e-9, 1e-7),\n",
    "        'optimize_for': 'valid_loss',\n",
    "        \n",
    "        'facebook/bart-base_config_overrides': {\n",
    "            'activation_dropout': trial.suggest_discrete_uniform('activation_dropout', 0.0, 0.3, 0.05),\n",
    "            'attention_dropout': trial.suggest_discrete_uniform('attention_dropout', 0.0, 0.3, 0.05),\n",
    "            'classif_dropout': trial.suggest_discrete_uniform('classif_dropout', 0.0, 0.3, 0.05),\n",
    "            'dropout': trial.suggest_discrete_uniform('dropout', 0.0, 0.3, 0.05)\n",
    "        },\n",
    "        'roberta-base_config_overrides': {\n",
    "            'attention_probs_dropout_prob': trial.suggest_discrete_uniform('attention_probs_dropout_prob', 0.0, 0.3, 0.05),\n",
    "            'hidden_dropout_prob': trial.suggest_discrete_uniform('hidden_dropout_prob', 0.0, 0.3, 0.05)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    score = train(opt_params, trial=trial, train_config=train_config)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 14:30:18,915]\u001b[0m A new study created in memory with name: no-name-266e576d-2864-4abb-a372-460765a7d15b\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 15:06:08,327]\u001b[0m Trial 0 finished with value: 0.8463168144226074 and parameters: {'pretrained_model_name': 'facebook/bart-base', 'save_model': False, 'use_weighted_loss': True, 'use_fp16': True, 'n_frozen_epochs': 3, 'n_unfrozen_epochs': 4, 'frozen_lr': 9.608787525580437e-07, 'unfrozen_lr_max': 1.5176809730352162e-07, 'unfrozen_lr_min': 2.1603317617807016e-09, 'activation_dropout': 0.05, 'attention_dropout': 0.25, 'classif_dropout': 0.1, 'dropout': 0.0, 'attention_probs_dropout_prob': 0.25, 'hidden_dropout_prob': 0.05}. Best is trial 0 with value: 0.8463168144226074.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 16:15:19,368]\u001b[0m Trial 1 finished with value: 0.8286561369895935 and parameters: {'pretrained_model_name': 'facebook/bart-base', 'save_model': False, 'use_weighted_loss': True, 'use_fp16': True, 'n_frozen_epochs': 2, 'n_unfrozen_epochs': 10, 'frozen_lr': 1.037154980319414e-07, 'unfrozen_lr_max': 3.3728652659690133e-07, 'unfrozen_lr_min': 1.7036045413727217e-09, 'activation_dropout': 0.1, 'attention_dropout': 0.05, 'classif_dropout': 0.15000000000000002, 'dropout': 0.25, 'attention_probs_dropout_prob': 0.1, 'hidden_dropout_prob': 0.2}. Best is trial 1 with value: 0.8286561369895935.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 17:21:11,279]\u001b[0m Trial 2 finished with value: 0.5142017006874084 and parameters: {'pretrained_model_name': 'facebook/bart-base', 'save_model': False, 'use_weighted_loss': True, 'use_fp16': True, 'n_frozen_epochs': 1, 'n_unfrozen_epochs': 10, 'frozen_lr': 2.8975082862096726e-07, 'unfrozen_lr_max': 6.047836536557682e-07, 'unfrozen_lr_min': 8.352912294717834e-09, 'activation_dropout': 0.05, 'attention_dropout': 0.25, 'classif_dropout': 0.05, 'dropout': 0.05, 'attention_probs_dropout_prob': 0.3, 'hidden_dropout_prob': 0.05}. Best is trial 2 with value: 0.5142017006874084.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 18:05:37,329]\u001b[0m Trial 3 finished with value: 0.7450684309005737 and parameters: {'pretrained_model_name': 'facebook/bart-base', 'save_model': False, 'use_weighted_loss': False, 'use_fp16': True, 'n_frozen_epochs': 2, 'n_unfrozen_epochs': 6, 'frozen_lr': 1.3036298035395868e-07, 'unfrozen_lr_max': 4.5649242542479813e-07, 'unfrozen_lr_min': 2.0418090525359005e-09, 'activation_dropout': 0.05, 'attention_dropout': 0.2, 'classif_dropout': 0.2, 'dropout': 0.1, 'attention_probs_dropout_prob': 0.3, 'hidden_dropout_prob': 0.05}. Best is trial 2 with value: 0.5142017006874084.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 1.0800162553787231.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 1.040364384651184.\n",
      "Better model found at epoch 1 with valid_loss value: 0.9689270853996277.\n",
      "Better model found at epoch 2 with valid_loss value: 0.9109830856323242.\n",
      "Better model found at epoch 3 with valid_loss value: 0.8772831559181213.\n",
      "Better model found at epoch 4 with valid_loss value: 0.8545389175415039.\n",
      "Better model found at epoch 5 with valid_loss value: 0.8443712592124939.\n",
      "Better model found at epoch 6 with valid_loss value: 0.8385421633720398.\n",
      "Better model found at epoch 7 with valid_loss value: 0.8384924530982971.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 18:59:15,870]\u001b[0m Trial 4 finished with value: 0.8384924530982971 and parameters: {'pretrained_model_name': 'facebook/bart-base', 'save_model': True, 'use_weighted_loss': False, 'use_fp16': True, 'n_frozen_epochs': 1, 'n_unfrozen_epochs': 8, 'frozen_lr': 5.932025964460386e-07, 'unfrozen_lr_max': 1.1597602061403688e-07, 'unfrozen_lr_min': 1.5523029535853615e-08, 'activation_dropout': 0.15000000000000002, 'attention_dropout': 0.05, 'classif_dropout': 0.15000000000000002, 'dropout': 0.2, 'attention_probs_dropout_prob': 0.3, 'hidden_dropout_prob': 0.05}. Best is trial 2 with value: 0.5142017006874084.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 19:03:05,033]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 1.0700973272323608.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 19:10:21,663]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 19:14:08,472]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 1.0755170583724976.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 19:21:19,823]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 19:25:08,519]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 19:28:54,848]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 19:32:44,380]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 19:36:33,040]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 19:43:42,695]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 19:47:29,863]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 19:51:18,386]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 20:13:48,393]\u001b[0m Trial 16 finished with value: 0.7891263365745544 and parameters: {'pretrained_model_name': 'facebook/bart-base', 'save_model': False, 'use_weighted_loss': True, 'use_fp16': True, 'n_frozen_epochs': 1, 'n_unfrozen_epochs': 3, 'frozen_lr': 3.832521670248291e-07, 'unfrozen_lr_max': 9.794250031931575e-07, 'unfrozen_lr_min': 1.0381649907231264e-09, 'activation_dropout': 0.05, 'attention_dropout': 0.2, 'classif_dropout': 0.2, 'dropout': 0.05, 'attention_probs_dropout_prob': 0.2, 'hidden_dropout_prob': 0.15000000000000002}. Best is trial 2 with value: 0.5142017006874084.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 20:17:38,173]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 20:24:43,591]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 21:23:57,044]\u001b[0m Trial 19 finished with value: 0.48531827330589294 and parameters: {'pretrained_model_name': 'facebook/bart-base', 'save_model': False, 'use_weighted_loss': True, 'use_fp16': True, 'n_frozen_epochs': 1, 'n_unfrozen_epochs': 9, 'frozen_lr': 3.59035624977803e-07, 'unfrozen_lr_max': 4.536997497390868e-07, 'unfrozen_lr_min': 3.319391395922754e-08, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'classif_dropout': 0.25, 'dropout': 0.05, 'attention_probs_dropout_prob': 0.05, 'hidden_dropout_prob': 0.1}. Best is trial 19 with value: 0.48531827330589294.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 21:27:42,859]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 22:27:18,803]\u001b[0m Trial 21 finished with value: 0.5074304938316345 and parameters: {'pretrained_model_name': 'facebook/bart-base', 'save_model': False, 'use_weighted_loss': True, 'use_fp16': True, 'n_frozen_epochs': 1, 'n_unfrozen_epochs': 9, 'frozen_lr': 5.168028886721787e-07, 'unfrozen_lr_max': 4.3717155566199714e-07, 'unfrozen_lr_min': 3.995614325830728e-08, 'activation_dropout': 0.1, 'attention_dropout': 0.15000000000000002, 'classif_dropout': 0.2, 'dropout': 0.1, 'attention_probs_dropout_prob': 0.05, 'hidden_dropout_prob': 0.1}. Best is trial 19 with value: 0.48531827330589294.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-10-24 23:26:27,740]\u001b[0m Trial 22 finished with value: 0.48361992835998535 and parameters: {'pretrained_model_name': 'facebook/bart-base', 'save_model': False, 'use_weighted_loss': True, 'use_fp16': True, 'n_frozen_epochs': 1, 'n_unfrozen_epochs': 9, 'frozen_lr': 4.984951751388225e-07, 'unfrozen_lr_max': 3.983005882258453e-07, 'unfrozen_lr_min': 4.19121116765796e-08, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'classif_dropout': 0.25, 'dropout': 0.05, 'attention_probs_dropout_prob': 0.05, 'hidden_dropout_prob': 0.1}. Best is trial 22 with value: 0.48361992835998535.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\u001b[32m[I 2020-10-25 00:19:19,583]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 7.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='732' class='' max='1508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      48.54% [732/1508 01:34<01:40 1.0973]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      12.50% [1/8 06:07<42:55]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1325' class='' max='1508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      87.86% [1325/1508 05:14<00:43 0.9448]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner() if True else optuna.pruners.NopPruner()\n",
    "study = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
    "\n",
    "train_config = {}\n",
    "study.optimize(partial(objective, train_config=train_config), \n",
    "               n_trials=30, \n",
    "               callbacks=[after_trial_cleanup])#, timeout=600)\n",
    "\n",
    "end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  30\n",
      "  Number of pruned trials:  18\n",
      "  Number of complete trials:  12\n",
      "Best trial:\n",
      "  Value:  0.4500029683113098\n",
      "  Params: \n",
      "    pretrained_model_name: facebook/bart-base\n",
      "    save_model: False\n",
      "    use_weighted_loss: True\n",
      "    use_fp16: True\n",
      "    n_frozen_epochs: 1\n",
      "    n_unfrozen_epochs: 9\n",
      "    frozen_lr: 9.825921309111008e-07\n",
      "    unfrozen_lr_max: 3.7739081992270234e-07\n",
      "    unfrozen_lr_min: 9.947900697659808e-08\n",
      "    activation_dropout: 0.1\n",
      "    attention_dropout: 0.1\n",
      "    classif_dropout: 0.25\n",
      "    dropout: 0.0\n",
      "    attention_probs_dropout_prob: 0.05\n",
      "    hidden_dropout_prob: 0.1\n",
      "  User attrs:\n",
      "total time is 47775.509564 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/tritonlytics-ai/lib/python3.7/site-packages/optuna/structs.py:21: FutureWarning: `structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "  warnings.warn(_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "m_pre, m_suf = meta_standard_themes_train_config['m_pre'], meta_standard_themes_train_config['m_suf']\n",
    "full_model_name = f\"{m_pre}{meta_standard_themes_train_config['base_model_name']}{m_suf}\"\n",
    "\n",
    "pruned_trials = [ t for t in study.trials if t.state == optuna.structs.TrialState.PRUNED ]\n",
    "complete_trials = [ t for t in study.trials if t.state == optuna.structs.TrialState.COMPLETE ]\n",
    "\n",
    "print('Study statistics: ')\n",
    "print('  Number of finished trials: ', len(study.trials))\n",
    "print('  Number of pruned trials: ', len(pruned_trials))\n",
    "print('  Number of complete trials: ', len(complete_trials))\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print('  Value: ', trial.value)\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items(): print('    {}: {}'.format(key, value))\n",
    "print('  User attrs:')\n",
    "for key, value in trial.user_attrs.items(): print('    {}: {}'.format(key, value))\n",
    "    \n",
    "best_params = study.best_params\n",
    "best_params['valid_loss'] = study.best_value\n",
    "\n",
    "with open(f\"{meta_standard_themes_train_config['learner_path']}/{yyyymmdd}_{full_model_name}_best_trial_params.json\", 'w') as f:\n",
    "    json.dump(best_params, f, indent=4)\n",
    "\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_df.to_csv(f\"{meta_standard_themes_train_config['learner_path']}/{yyyymmdd}_{full_model_name}_trial_results.csv\", \n",
    "                 index=False)\n",
    "\n",
    "print(f'total time is {(end - start).total_seconds()} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_pre, m_suf = meta_standard_themes_train_config['m_pre'], meta_standard_themes_train_config['m_suf']\n",
    "full_model_name = f\"{m_pre}{meta_standard_themes_train_config['base_model_name']}{m_suf}\"\n",
    "\n",
    "with open(f\"{meta_standard_themes_train_config['learner_path']}/20201024_{full_model_name}_best_trial_params.json\") as f: \n",
    "    best_params = json.load(f)\n",
    "    \n",
    "scores, train_res_df = train(params=best_params, train_config={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid_loss': 0.4500029683113098,\n",
       " 'sentiment_mse': 0.4458562731742859,\n",
       " 'is_example_acc': 0.9932935833930969,\n",
       " 'is_example_f05': {'threshold': 0.05, 'score': 0.008368978984563884},\n",
       " 'is_example_f1': {'threshold': 0.05, 'score': 0.013323464100666173},\n",
       " 'is_example_f2': {'threshold': 0.05, 'score': 0.03265602322206096},\n",
       " 'sentiment': {'mae': 0.5019305944442749,\n",
       "  'mse': 0.4458564519882202,\n",
       "  'rmse': 0.6677248325382397}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>question_ans_id</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_text_non_english</th>\n",
       "      <th>language</th>\n",
       "      <th>survey_id</th>\n",
       "      <th>survey_type_id</th>\n",
       "      <th>benchmark_survey_type</th>\n",
       "      <th>client_id</th>\n",
       "      <th>rsp_id</th>\n",
       "      <th>question_category_abbr</th>\n",
       "      <th>question_text</th>\n",
       "      <th>question_class</th>\n",
       "      <th>question_category_id</th>\n",
       "      <th>question_report_abbr</th>\n",
       "      <th>question_category_label</th>\n",
       "      <th>benchmark_level1</th>\n",
       "      <th>benchmark_level2</th>\n",
       "      <th>benchmark_level3</th>\n",
       "      <th>client_benchmark_level</th>\n",
       "      <th>group_code</th>\n",
       "      <th>group_id</th>\n",
       "      <th>group_level1_code</th>\n",
       "      <th>group_level1_name</th>\n",
       "      <th>group_level2_code</th>\n",
       "      <th>group_level2_name</th>\n",
       "      <th>group_level3_code</th>\n",
       "      <th>group_level3_name</th>\n",
       "      <th>group_level4_code</th>\n",
       "      <th>group_level4_name</th>\n",
       "      <th>group_level5_code</th>\n",
       "      <th>group_level5_name</th>\n",
       "      <th>group_level6_code</th>\n",
       "      <th>group_level6_name</th>\n",
       "      <th>group_level7_code</th>\n",
       "      <th>group_level7_name</th>\n",
       "      <th>group_level8_code</th>\n",
       "      <th>group_level8_name</th>\n",
       "      <th>standard_theme_id</th>\n",
       "      <th>theme</th>\n",
       "      <th>url_friendly_theme</th>\n",
       "      <th>theme_display_order</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>is_example</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>pred_sentiment</th>\n",
       "      <th>prob_is_example</th>\n",
       "      <th>targ_sentiment</th>\n",
       "      <th>targ_is_example</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>660454</td>\n",
       "      <td>93069</td>\n",
       "      <td>\"Academics at UC ANR value my contributions.\"\\r\\n\"Staff members at UC ANR value my contributions...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>396</td>\n",
       "      <td>47</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCANR</td>\n",
       "      <td>480552</td>\n",
       "      <td>None</td>\n",
       "      <td>Please provide any additional feedback regarding the work environment at UC ANR. Your comments w...</td>\n",
       "      <td>Verbatim-Comments</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>Comments re Work Environment at UC ANR</td>\n",
       "      <td>Comments</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>250400.0</td>\n",
       "      <td>6984</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC Agriculture &amp; Natural Resources</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>AVP Programs and Initiatives</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>Strategic Institutes and Statewide Programs</td>\n",
       "      <td>250400.0</td>\n",
       "      <td>Statewide IPM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>Have Voice within my Institution/Valued Member of my Institution</td>\n",
       "      <td>HaveVoiceWithinMyInstitutionValuedMemberOfMyInstitution</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.867188</td>\n",
       "      <td>0.274594</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>589692</td>\n",
       "      <td>2576</td>\n",
       "      <td>*The MSO of this department consistently takes unfair advantage of power dynamics to intimidate ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>447156</td>\n",
       "      <td>C&amp;B</td>\n",
       "      <td>If you would like to elaborate on any of your answers to the conduct and behavioral questions ab...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>Conduct &amp; Behavioral - Comments</td>\n",
       "      <td>Conduct &amp; Behavioral</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10104.0</td>\n",
       "      <td>3437</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>ACADEMIC AFFAIRS</td>\n",
       "      <td>10002.0</td>\n",
       "      <td>DIVISIONS/SCHOOLS</td>\n",
       "      <td>10003.0</td>\n",
       "      <td>ARTS &amp; HUMANITIES</td>\n",
       "      <td>10104.0</td>\n",
       "      <td>MUSIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>Supervisor Effectiveness/Resolves Staff Issues</td>\n",
       "      <td>SupervisorEffectivenessResolvesStaffIssues</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.519531</td>\n",
       "      <td>0.275446</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>589041</td>\n",
       "      <td>1877</td>\n",
       "      <td>Hiring and staffing pools in the research administration series have been very weak and it is di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>449832</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99119.0</td>\n",
       "      <td>4731</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>VICE CHANCELLOR HEALTH SCIENCES</td>\n",
       "      <td>93000.0</td>\n",
       "      <td>SCHOOL OF MEDICINE</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>DEAN'S OFFICE</td>\n",
       "      <td>99119.0</td>\n",
       "      <td>VC OPERATIONS LEADERSHIP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Internal Processes Effective</td>\n",
       "      <td>InternalProcessesEffective</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.973633</td>\n",
       "      <td>0.272035</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>683498</td>\n",
       "      <td>1877</td>\n",
       "      <td>My supervisor is great but her supervisors are not. Our department is not respectful of the need...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>401</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>495891</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>700001.0</td>\n",
       "      <td>3828</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>ADVANCEMENT</td>\n",
       "      <td>700019.0</td>\n",
       "      <td>ALUMNI</td>\n",
       "      <td>700001.0</td>\n",
       "      <td>ALUMNI RELATIONS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>Supervisor Effectiveness/Resolves Staff Issues</td>\n",
       "      <td>SupervisorEffectivenessResolvesStaffIssues</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.929688</td>\n",
       "      <td>0.271702</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>683028</td>\n",
       "      <td>1877</td>\n",
       "      <td>The inefficiencies and chronic shortages of resources (IT/computer related/eqipment) is so frust...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>401</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>494058</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90920.0</td>\n",
       "      <td>3665</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>VICE CHANCELLOR HEALTH SCIENCES</td>\n",
       "      <td>93000.0</td>\n",
       "      <td>SCHOOL OF MEDICINE</td>\n",
       "      <td>90900.0</td>\n",
       "      <td>NEUROSCIENCES</td>\n",
       "      <td>90920.0</td>\n",
       "      <td>ALZHEIMERS DISEASE RESEARCH CENTER (ADRC)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Internal Processes Effective</td>\n",
       "      <td>InternalProcessesEffective</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>0.273544</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id  question_ans_id                                                                                          answer_text  answer_text_non_english language  survey_id  survey_type_id benchmark_survey_type client_id  rsp_id question_category_abbr                                                                                        question_text     question_class  question_category_id                    question_report_abbr         question_category_label benchmark_level1 benchmark_level2 benchmark_level3  client_benchmark_level  group_code  group_id  group_level1_code                   group_level1_name  group_level2_code                group_level2_name  group_level3_code                            group_level3_name  group_level4_code  group_level4_name  group_level5_code                          group_level5_name  group_level6_code group_level6_name  group_level7_code group_level7_name  group_level8_code  group_level8_name  standard_theme_id  \\\n",
       "0      0  660454            93069  \"Academics at UC ANR value my contributions.\"\\r\\n\"Staff members at UC ANR value my contributions...                      NaN  English        396              47                   SAW     UCANR  480552                   None  Please provide any additional feedback regarding the work environment at UC ANR. Your comments w...  Verbatim-Comments                1141.0  Comments re Work Environment at UC ANR                        Comments             None             None             None                     3.0    250400.0      6984           999999.0  UC Agriculture & Natural Resources           200000.0     AVP Programs and Initiatives           250000.0  Strategic Institutes and Statewide Programs           250400.0      Statewide IPM                NaN                                        NaN                NaN               NaN                NaN               NaN                NaN                NaN                 10   \n",
       "1      1  589692             2576  *The MSO of this department consistently takes unfair advantage of power dynamics to intimidate ...                      NaN  English        212               9                   SAW      UCSD  447156                    C&B  If you would like to elaborate on any of your answers to the conduct and behavioral questions ab...           Verbatim                1240.0         Conduct & Behavioral - Comments            Conduct & Behavioral             None             None             None                     3.0     10104.0      3437           999999.0                        UC San Diego            10000.0                 ACADEMIC AFFAIRS            10002.0                            DIVISIONS/SCHOOLS            10003.0  ARTS & HUMANITIES            10104.0                                      MUSIC                NaN               NaN                NaN               NaN                NaN                NaN                 19   \n",
       "2      2  589041             1877  Hiring and staffing pools in the research administration series have been very weak and it is di...                      NaN  English        212               9                   SAW      UCSD  449832                    SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...           Verbatim                 114.0    Comments re Work Environment at UCSD  Satisfaction with UC San Diego             None             None             None                     1.0     99119.0      4731           999999.0                        UC San Diego            90000.0  VICE CHANCELLOR HEALTH SCIENCES            93000.0                           SCHOOL OF MEDICINE            96000.0      DEAN'S OFFICE            99119.0                   VC OPERATIONS LEADERSHIP                NaN               NaN                NaN               NaN                NaN                NaN                 45   \n",
       "3      3  683498             1877  My supervisor is great but her supervisors are not. Our department is not respectful of the need...                      NaN  English        401               9                   SAW      UCSD  495891                    SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...           Verbatim                 114.0    Comments re Work Environment at UCSD  Satisfaction with UC San Diego             None             None             None                     1.0    700001.0      3828           999999.0                        UC San Diego           700000.0                      ADVANCEMENT           700019.0                                       ALUMNI           700001.0   ALUMNI RELATIONS                NaN                                        NaN                NaN               NaN                NaN               NaN                NaN                NaN                 19   \n",
       "4      4  683028             1877  The inefficiencies and chronic shortages of resources (IT/computer related/eqipment) is so frust...                      NaN  English        401               9                   SAW      UCSD  494058                    SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...           Verbatim                 114.0    Comments re Work Environment at UCSD  Satisfaction with UC San Diego             None             None             None                     1.0     90920.0      3665           999999.0                        UC San Diego            90000.0  VICE CHANCELLOR HEALTH SCIENCES            93000.0                           SCHOOL OF MEDICINE            90900.0      NEUROSCIENCES            90920.0  ALZHEIMERS DISEASE RESEARCH CENTER (ADRC)                NaN               NaN                NaN               NaN                NaN                NaN                 45   \n",
       "\n",
       "                                                              theme                                       url_friendly_theme  theme_display_order  avg_sentiment  is_example  is_valid  pred_sentiment  prob_is_example  targ_sentiment  targ_is_example      loss  \n",
       "0  Have Voice within my Institution/Valued Member of my Institution  HaveVoiceWithinMyInstitutionValuedMemberOfMyInstitution                    1            2.0           0     False        1.867188         0.274594             2.0              0.0  0.019078  \n",
       "1                    Supervisor Effectiveness/Resolves Staff Issues               SupervisorEffectivenessResolvesStaffIssues                    1            1.0           0     False        1.519531         0.275446             1.0              0.0  0.271568  \n",
       "2                                      Internal Processes Effective                               InternalProcessesEffective                    1            2.0           0     False        1.973633         0.272035             2.0              0.0  0.001482  \n",
       "3                    Supervisor Effectiveness/Resolves Staff Issues               SupervisorEffectivenessResolvesStaffIssues                    1            2.0           0     False        1.929688         0.271702             2.0              0.0  0.005646  \n",
       "4                                      Internal Processes Effective                               InternalProcessesEffective                    1            2.0           0     False        1.953125         0.273544             2.0              0.0  0.003368  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid_loss': 0.4500029683113098,\n",
       " 'sentiment_mse': 0.4458562731742859,\n",
       " 'is_example_acc': 0.9932935833930969,\n",
       " 'is_example_f05': {'threshold': 0.05, 'score': 0.008368978984563884},\n",
       " 'is_example_f1': {'threshold': 0.05, 'score': 0.013323464100666173},\n",
       " 'is_example_f2': {'threshold': 0.05, 'score': 0.03265602322206096},\n",
       " 'sentiment': {'mae': 0.5019305944442749,\n",
       "  'mse': 0.4458564519882202,\n",
       "  'rmse': 0.6677248325382397}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load scores\n",
    "m_pre, m_suf = meta_standard_themes_train_config['m_pre'], meta_standard_themes_train_config['m_suf']\n",
    "full_model_name = f\"{m_pre}{meta_standard_themes_train_config['base_model_name']}{m_suf}\"\n",
    "\n",
    "with open(STANDARD_THEME_META_PATH/f'20201025_{full_model_name}_train_scores.json') as f: \n",
    "    training_results = json.load(f)\n",
    "    \n",
    "training_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((2.2841796875,), '0'), tensor([[2.2842]]), tensor([[2.2842]]))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((3.7602927684783936,), '0'), tensor([[3.7603]]), tensor([[3.7603]]))\n"
     ]
    }
   ],
   "source": [
    "inf_learn = load_learner(STANDARD_THEME_META_PATH/f'{yyyymmdd}_{full_model_name}_export.pkl')\n",
    "print(inf_learn.blurr_predict('theme: Benefits comment: We are not paid enough and the benefits are horrible'))\n",
    "print(inf_learn.blurr_predict(\"theme: Benfits comment: The faculty really support us well!!! I feel valued\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference (ad-hoc documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adequate_staffing', 'advancement_and_training_opportunities', 'appropriate_stress_work_assigned_equitably', 'benefits', 'better_ways_recognized_participate_in_decisions']\n"
     ]
    }
   ],
   "source": [
    "print(STANDARD_THEME_SAW_LABELS[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(HF_BaseInput([    0,  4782,    35,  1664, 30769,  1129,    35,  1491,  1199,   615,\n",
      "            4,     2]), ((2.0957260131835938,), '0'), tensor([[2.0957]]), tensor([[2.0957]]))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(HF_BaseInput([    0,  4782,    35,  1664, 30769,  1129,    35,    38,   524, 10028,\n",
      "           19,   127,  1795,     8,    52,    33,   615,    82,    11,   127,\n",
      "         1494,     4,    20,  7998,    16,  1266,     7,   162,     4,     2]), ((2.7463250160217285,), '0'), tensor([[2.7463]]), tensor([[2.7463]]))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(HF_BaseInput([    0,  4782,    35,  1664, 30769,  1129,    35,    38,   657, 10017,\n",
      "            2]), ((3.2796902656555176,), '0'), tensor([[3.2797]]), tensor([[3.2797]]))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(HF_BaseInput([    0,  4782,    35,  1664, 30769,  1129,    35,    38,    64,   393,\n",
      "          465,    10,  2932,  1514,     4,    20,  2572,    90,  1634,    32,\n",
      "           45,    15,    86,     4, 10310,     2]), ((2.199773073196411,), '0'), tensor([[2.1998]]), tensor([[2.1998]]))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(HF_BaseInput([    0,  4782,    35,  1664, 30769,  1129,    35,    38,    21,   269,\n",
      "         9800,     7,  5486,   127,  2979, 16506,     2]), ((2.502875804901123,), '0'), tensor([[2.5029]]), tensor([[2.5029]]))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(HF_BaseInput([    0,  4782,    35,  1664, 30769,  1129,    35,  2321,  8914,   890,\n",
      "           16,    41,  9297,   884,     4,  1437,    91,    34,  1613,  1065,\n",
      "            8,  1684,     7,  1045,    10,  1313,   447,  1737,     8,   694,\n",
      "          434,  1616,     4,  1437,   832,  2720,     7,    39,   165,    16,\n",
      "          542, 27978,   196,     8, 19781,   868,     4, 37457,   338, 37457,\n",
      "          282, 37457,   338, 37457,   282, 38334,  3144,  5302,  2478,    16,\n",
      "           10,  1421,     9, 12757,  1673,    13,  6919,     8, 37513,  1630,\n",
      "         2617,  1820,     4,  1437,   264,    34,  2208,     5,  2098,     9,\n",
      "          167,    79,  3315,   149,  5322,  4358,     6, 17805,     6,     8,\n",
      "        13557,  9434,     4,     2]), ((4.005021095275879,), '0'), tensor([[4.0050]]), tensor([[4.0050]]))\n"
     ]
    }
   ],
   "source": [
    "test_comments = [\n",
    "    'theme: Benfits comment: Not paid enough.',\n",
    "    'theme: Benfits comment: I am satisfied with my benefits and we have enough people in my department. The faculty is mean to me.',\n",
    "    'theme: Benfits comment: I love cats',\n",
    "    \"theme: Benfits comment: I can never find a parking spot. The shuttles are not on time. Help\",\n",
    "    \"theme: Benfits comment: I was really uncomfortable to express my opinion!!!\",\n",
    "    \"theme: Benfits comment: Jeff Wadell is an exceptional leader.  He has gone above and beyond to create a positive working environment and provide growth opportunities.  His commitment to his team is unrivaled and commendable.\\\\r\\\\n\\\\r\\\\nNikki Panza is a model of authentic leadership for Building and Custodial Services.  She has earned the respect of those she leads through honest communication, empathy, and ethical consultation.\"\n",
    "]\n",
    "\n",
    "for c in test_comments: print(inf_learn.blurr_predict(c, with_input=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference (batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_standard_theme_meta_preds(inf_df, learner_export_path=None, train_scores_path=None, yyyymmdd=None,\n",
    "                                  device=torch.device('cpu'), train_config={}):\n",
    "    \n",
    "    config = {**meta_standard_themes_train_config, **train_config}    \n",
    "    m_pre, m_suf, base_model_name = config['m_pre'], config['m_suf'], config['base_model_name']\n",
    "    full_model_name = f'{m_pre}{base_model_name}{m_suf}'\n",
    "    \n",
    "    if (yyyymmdd is None): yyyymmdd = datetime.today().strftime(\"%Y%m%d\")\n",
    "    \n",
    "    # 1. grab learner, procs, and data\n",
    "    cpu = device.type == 'cpu'\n",
    "    if (learner_export_path is None): \n",
    "        learner_export_path = f\"{config['learner_path']}/{yyyymmdd}_{config['export_filename']}\"\n",
    "    if (train_scores_path is None): \n",
    "        train_scores_path = f\"{config['learner_path']}/{yyyymmdd}_{full_model_name}_train_scores.json\"\n",
    "        \n",
    "    with open(train_scores_path) as f: training_results = json.load(f)\n",
    "        \n",
    "    inf_learn = load_learner(fname=learner_export_path, cpu=cpu)\n",
    "    inf_learn.model = inf_learn.model.to(device)\n",
    "    inf_learn.model = inf_learn.model.eval()\n",
    "    \n",
    "    # 2. define a suitable dataloader\n",
    "    inf_df.dropna(subset=config['corpus_cols'], inplace=True)\n",
    "    inf_df.reset_index(drop=True, inplace=True)\n",
    "    inf_dl = inf_learn.dls.test_dl(inf_df, rm_type_tfms=None, bs=16)\n",
    "\n",
    "    # 3. get probs and document vectors\n",
    "    test_probs_sent, test_probs_is_example = [], []\n",
    "    with torch.no_grad():\n",
    "        for index, b in enumerate(inf_dl):\n",
    "            if index % 1000 == 0:  print(index)\n",
    "\n",
    "            # note: even though there is no targets, each batch is a tuple!\n",
    "            probs = inf_learn.model(b[0])\n",
    "            \n",
    "            # why \"detach\"? the computation of gradients wrt the weights of netG can be fully \n",
    "            # avoided in the backward pass if the graph is detached where it is.\n",
    "            test_probs_sent.append(to_detach(probs[0][0]))\n",
    "            test_probs_is_example.append(to_detach(torch.softmax(probs[0][1], dim=-1)))\n",
    "\n",
    "    all_probs_sent = L(torch.cat(test_probs_sent))\n",
    "    all_probs_is_example = L(torch.cat(test_probs_is_example))\n",
    "\n",
    "    # 4. ensure results are returned in order\n",
    "    # test_dl.get_idxs() => unsorted/original order items\n",
    "    all_probs_sent = all_probs_sent[0][np.argsort(inf_dl.get_idxs())]\n",
    "    all_probs_is_example = all_probs_is_example[0][np.argsort(inf_dl.get_idxs())]\n",
    "        \n",
    "    # 5. add model scores\n",
    "    combined_probs = np.concatenate((all_probs_sent.numpy(), all_probs_is_example.numpy()[:,1][:,None]), axis=1)\n",
    "    prob_labels = ['prob_' + lbl for lbl in STANDARD_THEME_META_LABELS]\n",
    "    probs_df = pd.DataFrame(combined_probs, columns=prob_labels)\n",
    "    \n",
    "    for lbl in STANDARD_THEME_META_LABELS[1:]:\n",
    "        probs_df[f'pred_{lbl}'] = (probs_df[f'prob_{lbl}'] > training_results['is_example_f05']['threshold']).astype(np.int64)\n",
    "        \n",
    "    final_df = pd.concat([inf_df, probs_df], axis=1)\n",
    "    \n",
    "    final_df['valid_loss'] = training_results['valid_loss']\n",
    "    final_df['sentiment_mse'] = training_results['sentiment']['mse']\n",
    "    final_df['sentiment_mae'] = training_results['sentiment']['mae']\n",
    "    final_df['sentiment_rmse'] = training_results['sentiment']['rmse']\n",
    "    final_df['is_example_f05_threshold'] = training_results['is_example_f05']['threshold']\n",
    "    final_df['is_example_f05_score'] = training_results['is_example_f05']['score']\n",
    "    final_df['is_example_f1_threshold'] = training_results['is_example_f1']['threshold']\n",
    "    final_df['is_example_f1_score'] = training_results['is_example_f1']['score']\n",
    "    final_df['is_example_f2_threshold'] = training_results['is_example_f2']['threshold']\n",
    "    final_df['is_example_f2_score'] = training_results['is_example_f2']['score']\n",
    "\n",
    "    # cleanup\n",
    "    try: del inf_learn; del inf_dl\n",
    "    except: pass\n",
    "    finally: gc.collect(); torch.cuda.empty_cache()\n",
    "    \n",
    "    return final_df, all_probs_sent, all_probs_is_example, STANDARD_THEME_META_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4045 4045\n"
     ]
    }
   ],
   "source": [
    "verbatims_df = pd.read_csv(STANDARD_THEME_SAW_PATH/'20201024_test_predictions_multilabel_hf.csv', \n",
    "                           dtype={**TASK_LM_DTYPES}, parse_dates=[])\n",
    "\n",
    "inf_df = verbatims_df.copy() #verbatims_df[test_df.SurveyID == 130].copy()\n",
    "inf_df.reset_index(drop=True, inplace=True)\n",
    "print(len(verbatims_df), len(inf_df))\n",
    "\n",
    "corpus_cols = ['theme', 'AnswerText'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>QuestionAnsID</th>\n",
       "      <th>AnswerText</th>\n",
       "      <th>AnswerText_NonEnglish</th>\n",
       "      <th>Language</th>\n",
       "      <th>SurveyID</th>\n",
       "      <th>SurveyTypeID</th>\n",
       "      <th>BenchmarkSurveyType</th>\n",
       "      <th>ClientId</th>\n",
       "      <th>RspID</th>\n",
       "      <th>QuestionCategoryAbbr</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>QuestionClass</th>\n",
       "      <th>QuestionCategoryID</th>\n",
       "      <th>QuestionReportAbbr</th>\n",
       "      <th>QuestionCategoryLabel</th>\n",
       "      <th>BenchmarkLevel1</th>\n",
       "      <th>BenchmarkLevel2</th>\n",
       "      <th>BenchmarkLevel3</th>\n",
       "      <th>ClientBenchmarkLevel</th>\n",
       "      <th>GroupCode</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>GroupLevel1Code</th>\n",
       "      <th>GroupLevel1Name</th>\n",
       "      <th>GroupLevel2Code</th>\n",
       "      <th>GroupLevel2Name</th>\n",
       "      <th>GroupLevel3Code</th>\n",
       "      <th>GroupLevel3Name</th>\n",
       "      <th>GroupLevel4Code</th>\n",
       "      <th>GroupLevel4Name</th>\n",
       "      <th>GroupLevel5Code</th>\n",
       "      <th>GroupLevel5Name</th>\n",
       "      <th>GroupLevel6Code</th>\n",
       "      <th>GroupLevel6Name</th>\n",
       "      <th>GroupLevel7Code</th>\n",
       "      <th>GroupLevel7Name</th>\n",
       "      <th>GroupLevel8Code</th>\n",
       "      <th>GroupLevel8Name</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>prob_adequate_staffing</th>\n",
       "      <th>prob_advancement_and_training_opportunities</th>\n",
       "      <th>prob_appropriate_stress_work_assigned_equitably</th>\n",
       "      <th>prob_benefits</th>\n",
       "      <th>prob_better_ways_recognized_participate_in_decisions</th>\n",
       "      <th>prob_career_advancement</th>\n",
       "      <th>prob_committed_to_diversity</th>\n",
       "      <th>prob_communicates_essential_information</th>\n",
       "      <th>prob_ethical_conduct_perform_responsibilities_spirit_of_cooperation</th>\n",
       "      <th>prob_evaluated_fairly</th>\n",
       "      <th>prob_experienced_discrimination</th>\n",
       "      <th>prob_facilities_workspace_safety</th>\n",
       "      <th>prob_faculty_value_contributions</th>\n",
       "      <th>prob_favoritism_cliques</th>\n",
       "      <th>prob_fear_of_retaliation_negative_consequences</th>\n",
       "      <th>prob_feel_valued_by_department</th>\n",
       "      <th>prob_flexibility_work_life_balance</th>\n",
       "      <th>prob_good_use_of_skills</th>\n",
       "      <th>prob_have_necessary_tools</th>\n",
       "      <th>prob_have_voice_within_my_institution_valued_member_of_my_institution</th>\n",
       "      <th>prob_internal_processes_effective</th>\n",
       "      <th>prob_parking_transportation</th>\n",
       "      <th>prob_salary_pay</th>\n",
       "      <th>prob_satisfied_with_diversity_progams</th>\n",
       "      <th>prob_supervisor_effectiveness_resolves_staff_issues</th>\n",
       "      <th>pred_adequate_staffing</th>\n",
       "      <th>pred_advancement_and_training_opportunities</th>\n",
       "      <th>pred_appropriate_stress_work_assigned_equitably</th>\n",
       "      <th>pred_benefits</th>\n",
       "      <th>pred_better_ways_recognized_participate_in_decisions</th>\n",
       "      <th>pred_career_advancement</th>\n",
       "      <th>pred_committed_to_diversity</th>\n",
       "      <th>pred_communicates_essential_information</th>\n",
       "      <th>pred_ethical_conduct_perform_responsibilities_spirit_of_cooperation</th>\n",
       "      <th>pred_evaluated_fairly</th>\n",
       "      <th>pred_experienced_discrimination</th>\n",
       "      <th>pred_facilities_workspace_safety</th>\n",
       "      <th>pred_faculty_value_contributions</th>\n",
       "      <th>pred_favoritism_cliques</th>\n",
       "      <th>pred_fear_of_retaliation_negative_consequences</th>\n",
       "      <th>pred_feel_valued_by_department</th>\n",
       "      <th>pred_flexibility_work_life_balance</th>\n",
       "      <th>pred_good_use_of_skills</th>\n",
       "      <th>pred_have_necessary_tools</th>\n",
       "      <th>pred_have_voice_within_my_institution_valued_member_of_my_institution</th>\n",
       "      <th>pred_internal_processes_effective</th>\n",
       "      <th>pred_parking_transportation</th>\n",
       "      <th>pred_salary_pay</th>\n",
       "      <th>pred_satisfied_with_diversity_progams</th>\n",
       "      <th>pred_supervisor_effectiveness_resolves_staff_issues</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>opt_th</th>\n",
       "      <th>f05_threshold</th>\n",
       "      <th>f05_score</th>\n",
       "      <th>f1_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>f2_threshold</th>\n",
       "      <th>f2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>589996</td>\n",
       "      <td>2576</td>\n",
       "      <td>no, I do not want to elaborate on my answers out fear of reprisal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>451417</td>\n",
       "      <td>EDI</td>\n",
       "      <td>If you would like to elaborate on any of your answers to the conduct and behavioral questions ab...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Conduct &amp; Behavioral - Comments</td>\n",
       "      <td>EDI</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3729</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>VC-RESOURCE MANAGEMENT &amp; PLANNING</td>\n",
       "      <td>802.0</td>\n",
       "      <td>FACILITIES MANAGEMENT</td>\n",
       "      <td>17.0</td>\n",
       "      <td>FLEET SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no, I do not want to elaborate on my answers out fear of reprisal</td>\n",
       "      <td>0.004954</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>0.040012</td>\n",
       "      <td>0.066766</td>\n",
       "      <td>0.00265</td>\n",
       "      <td>0.053669</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.00452</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.020605</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.010666</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>0.00658</td>\n",
       "      <td>0.020697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159357</td>\n",
       "      <td>0.939489</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>0.597179</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>0.679538</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.523552</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.612663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  QuestionAnsID                                                         AnswerText AnswerText_NonEnglish Language  SurveyID  SurveyTypeID BenchmarkSurveyType ClientId   RspID QuestionCategoryAbbr                                                                                         QuestionText QuestionClass  QuestionCategoryID               QuestionReportAbbr QuestionCategoryLabel BenchmarkLevel1 BenchmarkLevel2 BenchmarkLevel3 ClientBenchmarkLevel  GroupCode GroupID  GroupLevel1Code GroupLevel1Name  GroupLevel2Code                    GroupLevel2Name  GroupLevel3Code        GroupLevel3Name  GroupLevel4Code GroupLevel4Name  GroupLevel5Code GroupLevel5Name  GroupLevel6Code GroupLevel6Name  GroupLevel7Code GroupLevel7Name  GroupLevel8Code GroupLevel8Name                                                        answer_text  prob_adequate_staffing  prob_advancement_and_training_opportunities  prob_appropriate_stress_work_assigned_equitably  prob_benefits  \\\n",
       "0  589996           2576  no, I do not want to elaborate on my answers out fear of reprisal                   NaN  English       212             9                 SAW     UCSD  451417                  EDI  If you would like to elaborate on any of your answers to the conduct and behavioral questions ab...      Verbatim               117.0  Conduct & Behavioral - Comments                   EDI            None            None            None                    1       17.0    3729         999999.0    UC San Diego          50000.0  VC-RESOURCE MANAGEMENT & PLANNING            802.0  FACILITIES MANAGEMENT             17.0  FLEET SERVICES              NaN             NaN              NaN             NaN              NaN             NaN              NaN             NaN  no, I do not want to elaborate on my answers out fear of reprisal                0.004954                                     0.005993                                         0.000977       0.000304   \n",
       "\n",
       "   prob_better_ways_recognized_participate_in_decisions  prob_career_advancement  prob_committed_to_diversity  prob_communicates_essential_information  prob_ethical_conduct_perform_responsibilities_spirit_of_cooperation  prob_evaluated_fairly  prob_experienced_discrimination  prob_facilities_workspace_safety  prob_faculty_value_contributions  prob_favoritism_cliques  prob_fear_of_retaliation_negative_consequences  prob_feel_valued_by_department  prob_flexibility_work_life_balance  prob_good_use_of_skills  prob_have_necessary_tools  prob_have_voice_within_my_institution_valued_member_of_my_institution  prob_internal_processes_effective  prob_parking_transportation  prob_salary_pay  prob_satisfied_with_diversity_progams  prob_supervisor_effectiveness_resolves_staff_issues  pred_adequate_staffing  pred_advancement_and_training_opportunities  pred_appropriate_stress_work_assigned_equitably  pred_benefits  pred_better_ways_recognized_participate_in_decisions  pred_career_advancement  \\\n",
       "0                                              0.008047                 0.004383                     0.005733                                 0.040012                                                             0.066766                0.00265                         0.053669                          0.005162                           0.00452                 0.004568                                        0.490196                        0.020605                            0.000227                 0.000874                   0.001234                                                               0.010666                           0.003131                     0.000303         0.009225                                0.00658                                             0.020697                       0                                            0                                                0              0                                                     0                        0   \n",
       "\n",
       "   pred_committed_to_diversity  pred_communicates_essential_information  pred_ethical_conduct_perform_responsibilities_spirit_of_cooperation  pred_evaluated_fairly  pred_experienced_discrimination  pred_facilities_workspace_safety  pred_faculty_value_contributions  pred_favoritism_cliques  pred_fear_of_retaliation_negative_consequences  pred_feel_valued_by_department  pred_flexibility_work_life_balance  pred_good_use_of_skills  pred_have_necessary_tools  pred_have_voice_within_my_institution_valued_member_of_my_institution  pred_internal_processes_effective  pred_parking_transportation  pred_salary_pay  pred_satisfied_with_diversity_progams  pred_supervisor_effectiveness_resolves_staff_issues  valid_loss  accuracy_multi  fbeta_score  precision_score  recall_score  roc_auc_score  opt_th  f05_threshold  f05_score  f1_threshold  f1_score  f2_threshold  f2_score  \n",
       "0                            0                                        0                                                                    0                      0                                0                                 0                                 0                        0                                               1                               0                                   0                        0                          0                                                                      0                                  0                            0                0                                      0                                                    0    0.159357        0.939489     0.521531         0.597179      0.383929       0.679538    0.42           0.42   0.521531           0.2  0.523552          0.13  0.612663  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_theme_cols = filter_col = [col for col in inf_df if col.startswith('prob_')]\n",
    "# prob_theme_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101125"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df = inf_df.melt(id_vars=list(TASK_LM_DTYPES.keys()), \n",
    "                     value_vars=prob_theme_cols, \n",
    "                     var_name='theme', \n",
    "                     value_name='theme_prob')\n",
    "len(inf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3649"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df = inf_df.loc[inf_df.theme_prob >= 0.42000000000000004]\n",
    "len(inf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_df['url_friendly_theme'] = inf_df.theme.apply(\n",
    "    lambda s: re.sub(\"(.*?)_([a-zA-Z])\",\"\\g<1> \\g<2>\",s).replace('prob', '').strip().title().replace(' ',''))\n",
    "\n",
    "inf_df['theme'] = inf_df.url_friendly_theme.apply(lambda s: re.sub(\"([a-z])([A-Z])\",\"\\g<1> \\g<2>\",s))\n",
    "inf_df['answer_text'] = inf_df['AnswerText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>QuestionAnsID</th>\n",
       "      <th>AnswerText</th>\n",
       "      <th>AnswerText_NonEnglish</th>\n",
       "      <th>Language</th>\n",
       "      <th>SurveyID</th>\n",
       "      <th>SurveyTypeID</th>\n",
       "      <th>BenchmarkSurveyType</th>\n",
       "      <th>ClientId</th>\n",
       "      <th>RspID</th>\n",
       "      <th>QuestionCategoryAbbr</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>QuestionClass</th>\n",
       "      <th>QuestionCategoryID</th>\n",
       "      <th>QuestionReportAbbr</th>\n",
       "      <th>QuestionCategoryLabel</th>\n",
       "      <th>BenchmarkLevel1</th>\n",
       "      <th>BenchmarkLevel2</th>\n",
       "      <th>BenchmarkLevel3</th>\n",
       "      <th>ClientBenchmarkLevel</th>\n",
       "      <th>GroupCode</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>GroupLevel1Code</th>\n",
       "      <th>GroupLevel1Name</th>\n",
       "      <th>GroupLevel2Code</th>\n",
       "      <th>GroupLevel2Name</th>\n",
       "      <th>GroupLevel3Code</th>\n",
       "      <th>GroupLevel3Name</th>\n",
       "      <th>GroupLevel4Code</th>\n",
       "      <th>GroupLevel4Name</th>\n",
       "      <th>GroupLevel5Code</th>\n",
       "      <th>GroupLevel5Name</th>\n",
       "      <th>GroupLevel6Code</th>\n",
       "      <th>GroupLevel6Name</th>\n",
       "      <th>GroupLevel7Code</th>\n",
       "      <th>GroupLevel7Name</th>\n",
       "      <th>GroupLevel8Code</th>\n",
       "      <th>GroupLevel8Name</th>\n",
       "      <th>theme</th>\n",
       "      <th>theme_prob</th>\n",
       "      <th>url_friendly_theme</th>\n",
       "      <th>answer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>589177</td>\n",
       "      <td>1877</td>\n",
       "      <td>Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>450625</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>31302.0</td>\n",
       "      <td>3555</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>VICE CHANCELLOR HEALTH SCIENCES</td>\n",
       "      <td>90563.0</td>\n",
       "      <td>STUDENT HEALTH &amp; WELL BEING</td>\n",
       "      <td>31302.0</td>\n",
       "      <td>STUDENT HEALTH SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prob Adequate Staffing</td>\n",
       "      <td>0.919443</td>\n",
       "      <td>ProbAdequateStaffing</td>\n",
       "      <td>Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>588649</td>\n",
       "      <td>1877</td>\n",
       "      <td>There have been a lot of retirements lately, but the department hasn't replaced any of these mis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>448111</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>700006.0</td>\n",
       "      <td>3833</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>VC-ADVANCEMENT</td>\n",
       "      <td>700006.0</td>\n",
       "      <td>UCSD FOUNDATION &amp; ADVANCEMENT SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prob Adequate Staffing</td>\n",
       "      <td>0.756393</td>\n",
       "      <td>ProbAdequateStaffing</td>\n",
       "      <td>There have been a lot of retirements lately, but the department hasn't replaced any of these mis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>588482</td>\n",
       "      <td>1877</td>\n",
       "      <td>WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>447391</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>3470</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>ACADEMIC AFFAIRS</td>\n",
       "      <td>10011.0</td>\n",
       "      <td>COLLEGES</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>MUIR COLLEGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prob Adequate Staffing</td>\n",
       "      <td>0.665860</td>\n",
       "      <td>ProbAdequateStaffing</td>\n",
       "      <td>WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>590654</td>\n",
       "      <td>9439</td>\n",
       "      <td>The lack of professionalism from different departments that are supposed to be working with you ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>451222</td>\n",
       "      <td>None</td>\n",
       "      <td>The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>201.0</td>\n",
       "      <td>IdeaWave Comments</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>90860.0</td>\n",
       "      <td>3659</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>VICE CHANCELLOR HEALTH SCIENCES</td>\n",
       "      <td>93000.0</td>\n",
       "      <td>SCHOOL OF MEDICINE</td>\n",
       "      <td>90800.0</td>\n",
       "      <td>MEDICINE</td>\n",
       "      <td>90860.0</td>\n",
       "      <td>CARDIOLOGY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prob Adequate Staffing</td>\n",
       "      <td>0.579821</td>\n",
       "      <td>ProbAdequateStaffing</td>\n",
       "      <td>The lack of professionalism from different departments that are supposed to be working with you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>588719</td>\n",
       "      <td>1877</td>\n",
       "      <td>ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>448383</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>3402</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>800.0</td>\n",
       "      <td>VICE CHANCELLOR CHIEF FINANCIAL OFFICER</td>\n",
       "      <td>808.0</td>\n",
       "      <td>INFORMATION TECHNOLOGY SERVICES</td>\n",
       "      <td>132.0</td>\n",
       "      <td>ARCHITECTURE &amp; INFRASTRUCTURE</td>\n",
       "      <td>171.0</td>\n",
       "      <td>DATACOM/NETWORK ARCHITECTS/NETWORK APPS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prob Adequate Staffing</td>\n",
       "      <td>0.436787</td>\n",
       "      <td>ProbAdequateStaffing</td>\n",
       "      <td>ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      Id  QuestionAnsID                                                                                           AnswerText AnswerText_NonEnglish Language  SurveyID  SurveyTypeID BenchmarkSurveyType ClientId   RspID QuestionCategoryAbbr                                                                                         QuestionText QuestionClass  QuestionCategoryID                    QuestionReportAbbr           QuestionCategoryLabel BenchmarkLevel1 BenchmarkLevel2 BenchmarkLevel3 ClientBenchmarkLevel  GroupCode GroupID  GroupLevel1Code GroupLevel1Name  GroupLevel2Code                          GroupLevel2Name  GroupLevel3Code                         GroupLevel3Name  GroupLevel4Code                GroupLevel4Name  GroupLevel5Code                          GroupLevel5Name  GroupLevel6Code GroupLevel6Name  GroupLevel7Code GroupLevel7Name  GroupLevel8Code GroupLevel8Name                   theme  theme_prob    url_friendly_theme  \\\n",
       "0      6  589177           1877  Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...                   NaN  English       212             9                 SAW     UCSD  450625                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1    31302.0    3555         999999.0    UC San Diego          90000.0          VICE CHANCELLOR HEALTH SCIENCES          90563.0             STUDENT HEALTH & WELL BEING          31302.0        STUDENT HEALTH SERVICES              NaN                                      NaN              NaN             NaN              NaN             NaN              NaN             NaN  Prob Adequate Staffing    0.919443  ProbAdequateStaffing   \n",
       "1     17  588649           1877  There have been a lot of retirements lately, but the department hasn't replaced any of these mis...                   NaN  English       212             9                 SAW     UCSD  448111                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1   700006.0    3833         999999.0    UC San Diego         700000.0                           VC-ADVANCEMENT         700006.0  UCSD FOUNDATION & ADVANCEMENT SERVICES              NaN                            NaN              NaN                                      NaN              NaN             NaN              NaN             NaN              NaN             NaN  Prob Adequate Staffing    0.756393  ProbAdequateStaffing   \n",
       "2     43  588482           1877  WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...                   NaN  English       212             9                 SAW     UCSD  447391                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1    11000.0    3470         999999.0    UC San Diego          10000.0                         ACADEMIC AFFAIRS          10011.0                                COLLEGES          11000.0                   MUIR COLLEGE              NaN                                      NaN              NaN             NaN              NaN             NaN              NaN             NaN  Prob Adequate Staffing    0.665860  ProbAdequateStaffing   \n",
       "3     49  590654           9439  The lack of professionalism from different departments that are supposed to be working with you ...                   NaN  English       212             9                 SAW     UCSD  451222                 None  The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...      Verbatim               201.0                     IdeaWave Comments                           Other            None            None            None                    1    90860.0    3659         999999.0    UC San Diego          90000.0          VICE CHANCELLOR HEALTH SCIENCES          93000.0                      SCHOOL OF MEDICINE          90800.0                       MEDICINE          90860.0                               CARDIOLOGY              NaN             NaN              NaN             NaN              NaN             NaN  Prob Adequate Staffing    0.579821  ProbAdequateStaffing   \n",
       "4     52  588719           1877  ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...                   NaN  English       212             9                 SAW     UCSD  448383                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1      171.0    3402         999999.0    UC San Diego            800.0  VICE CHANCELLOR CHIEF FINANCIAL OFFICER            808.0         INFORMATION TECHNOLOGY SERVICES            132.0  ARCHITECTURE & INFRASTRUCTURE            171.0  DATACOM/NETWORK ARCHITECTS/NETWORK APPS              NaN             NaN              NaN             NaN              NaN             NaN  Prob Adequate Staffing    0.436787  ProbAdequateStaffing   \n",
       "\n",
       "                                                                                           answer_text  \n",
       "0  Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...  \n",
       "1  There have been a lot of retirements lately, but the department hasn't replaced any of these mis...  \n",
       "2  WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...  \n",
       "3  The lack of professionalism from different departments that are supposed to be working with you ...  \n",
       "4  ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def build_meta_inf_df(themes_df, theme_prob_threshold= 0.5, fixed_cols=list(TASK_LM_DTYPES.keys())):\n",
    "    inf_df = themes_df.copy()\n",
    "    \n",
    "    prob_theme_cols = filter_col = [col for col in inf_df if col.startswith('prob_')]\n",
    "    \n",
    "    inf_df = inf_df.melt(id_vars=fixed_cols, value_vars=prob_theme_cols, var_name='theme', value_name='theme_prob')\n",
    "    inf_df = inf_df.loc[inf_df.theme_prob >= theme_prob_threshold]\n",
    "    \n",
    "    inf_df['url_friendly_theme'] = inf_df.theme.apply(\n",
    "        lambda s: re.sub(\"(.*?)_([a-zA-Z])\",\"\\g<1> \\g<2>\",s).replace('prob', '').strip().title().replace(' ',''))\n",
    "    \n",
    "    inf_df['theme'] = inf_df.url_friendly_theme.apply(lambda s: re.sub(\"([a-z])([A-Z])\",\"\\g<1> \\g<2>\",s))\n",
    "\n",
    "    inf_df.reset_index(inplace=True)\n",
    "    return inf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "0\n",
      "(3649, 56) torch.Size([3649, 1]) torch.Size([3649, 2]) 2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "preds_df, inf_probs_sent, inf_probs_is_example, inf_labels = get_standard_theme_meta_preds(inf_df, device=device)\n",
    "print(preds_df.shape, inf_probs_sent.shape, inf_probs_is_example.shape, len(inf_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>QuestionAnsID</th>\n",
       "      <th>AnswerText</th>\n",
       "      <th>AnswerText_NonEnglish</th>\n",
       "      <th>Language</th>\n",
       "      <th>SurveyID</th>\n",
       "      <th>SurveyTypeID</th>\n",
       "      <th>BenchmarkSurveyType</th>\n",
       "      <th>ClientId</th>\n",
       "      <th>RspID</th>\n",
       "      <th>QuestionCategoryAbbr</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>QuestionClass</th>\n",
       "      <th>QuestionCategoryID</th>\n",
       "      <th>QuestionReportAbbr</th>\n",
       "      <th>QuestionCategoryLabel</th>\n",
       "      <th>BenchmarkLevel1</th>\n",
       "      <th>BenchmarkLevel2</th>\n",
       "      <th>BenchmarkLevel3</th>\n",
       "      <th>ClientBenchmarkLevel</th>\n",
       "      <th>GroupCode</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>GroupLevel1Code</th>\n",
       "      <th>GroupLevel1Name</th>\n",
       "      <th>GroupLevel2Code</th>\n",
       "      <th>GroupLevel2Name</th>\n",
       "      <th>GroupLevel3Code</th>\n",
       "      <th>GroupLevel3Name</th>\n",
       "      <th>GroupLevel4Code</th>\n",
       "      <th>GroupLevel4Name</th>\n",
       "      <th>GroupLevel5Code</th>\n",
       "      <th>GroupLevel5Name</th>\n",
       "      <th>GroupLevel6Code</th>\n",
       "      <th>GroupLevel6Name</th>\n",
       "      <th>GroupLevel7Code</th>\n",
       "      <th>GroupLevel7Name</th>\n",
       "      <th>GroupLevel8Code</th>\n",
       "      <th>GroupLevel8Name</th>\n",
       "      <th>theme</th>\n",
       "      <th>theme_pred</th>\n",
       "      <th>url_friendly_theme</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>prob_avg_sentiment</th>\n",
       "      <th>prob_is_example</th>\n",
       "      <th>pred_is_example</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>sentiment_mae</th>\n",
       "      <th>sentiment_rmse</th>\n",
       "      <th>is_example_f05_threshold</th>\n",
       "      <th>is_example_f05_score</th>\n",
       "      <th>is_example_f1_threshold</th>\n",
       "      <th>is_example_f1_score</th>\n",
       "      <th>is_example_f2_threshold</th>\n",
       "      <th>is_example_f2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>589177</td>\n",
       "      <td>1877</td>\n",
       "      <td>Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>450625</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>31302.0</td>\n",
       "      <td>3555</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>VICE CHANCELLOR HEALTH SCIENCES</td>\n",
       "      <td>90563.0</td>\n",
       "      <td>STUDENT HEALTH &amp; WELL BEING</td>\n",
       "      <td>31302.0</td>\n",
       "      <td>STUDENT HEALTH SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...</td>\n",
       "      <td>2.100516</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450003</td>\n",
       "      <td>0.445856</td>\n",
       "      <td>0.501931</td>\n",
       "      <td>0.667725</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008369</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.013323</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.032656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>588649</td>\n",
       "      <td>1877</td>\n",
       "      <td>There have been a lot of retirements lately, but the department hasn't replaced any of these mis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>448111</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>700006.0</td>\n",
       "      <td>3833</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>VC-ADVANCEMENT</td>\n",
       "      <td>700006.0</td>\n",
       "      <td>UCSD FOUNDATION &amp; ADVANCEMENT SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>There have been a lot of retirements lately, but the department hasn't replaced any of these mis...</td>\n",
       "      <td>2.021485</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450003</td>\n",
       "      <td>0.445856</td>\n",
       "      <td>0.501931</td>\n",
       "      <td>0.667725</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008369</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.013323</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.032656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>588482</td>\n",
       "      <td>1877</td>\n",
       "      <td>WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>447391</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>3470</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>ACADEMIC AFFAIRS</td>\n",
       "      <td>10011.0</td>\n",
       "      <td>COLLEGES</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>MUIR COLLEGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...</td>\n",
       "      <td>2.242425</td>\n",
       "      <td>0.010107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450003</td>\n",
       "      <td>0.445856</td>\n",
       "      <td>0.501931</td>\n",
       "      <td>0.667725</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008369</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.013323</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.032656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>590654</td>\n",
       "      <td>9439</td>\n",
       "      <td>The lack of professionalism from different departments that are supposed to be working with you ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>451222</td>\n",
       "      <td>None</td>\n",
       "      <td>The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>201.0</td>\n",
       "      <td>IdeaWave Comments</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>90860.0</td>\n",
       "      <td>3659</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>VICE CHANCELLOR HEALTH SCIENCES</td>\n",
       "      <td>93000.0</td>\n",
       "      <td>SCHOOL OF MEDICINE</td>\n",
       "      <td>90800.0</td>\n",
       "      <td>MEDICINE</td>\n",
       "      <td>90860.0</td>\n",
       "      <td>CARDIOLOGY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>The lack of professionalism from different departments that are supposed to be working with you ...</td>\n",
       "      <td>2.035603</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450003</td>\n",
       "      <td>0.445856</td>\n",
       "      <td>0.501931</td>\n",
       "      <td>0.667725</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008369</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.013323</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.032656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>588719</td>\n",
       "      <td>1877</td>\n",
       "      <td>ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>448383</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>3402</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>800.0</td>\n",
       "      <td>VICE CHANCELLOR CHIEF FINANCIAL OFFICER</td>\n",
       "      <td>808.0</td>\n",
       "      <td>INFORMATION TECHNOLOGY SERVICES</td>\n",
       "      <td>132.0</td>\n",
       "      <td>ARCHITECTURE &amp; INFRASTRUCTURE</td>\n",
       "      <td>171.0</td>\n",
       "      <td>DATACOM/NETWORK ARCHITECTS/NETWORK APPS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...</td>\n",
       "      <td>1.962478</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450003</td>\n",
       "      <td>0.445856</td>\n",
       "      <td>0.501931</td>\n",
       "      <td>0.667725</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008369</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.013323</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.032656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      Id  QuestionAnsID                                                                                           AnswerText AnswerText_NonEnglish Language  SurveyID  SurveyTypeID BenchmarkSurveyType ClientId   RspID QuestionCategoryAbbr                                                                                         QuestionText QuestionClass  QuestionCategoryID                    QuestionReportAbbr           QuestionCategoryLabel BenchmarkLevel1 BenchmarkLevel2 BenchmarkLevel3 ClientBenchmarkLevel  GroupCode GroupID  GroupLevel1Code GroupLevel1Name  GroupLevel2Code                          GroupLevel2Name  GroupLevel3Code                         GroupLevel3Name  GroupLevel4Code                GroupLevel4Name  GroupLevel5Code                          GroupLevel5Name  GroupLevel6Code GroupLevel6Name  GroupLevel7Code GroupLevel7Name  GroupLevel8Code GroupLevel8Name              theme  theme_pred url_friendly_theme  \\\n",
       "0      6  589177           1877  Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...                   NaN  English       212             9                 SAW     UCSD  450625                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1    31302.0    3555         999999.0    UC San Diego          90000.0          VICE CHANCELLOR HEALTH SCIENCES          90563.0             STUDENT HEALTH & WELL BEING          31302.0        STUDENT HEALTH SERVICES              NaN                                      NaN              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "1     17  588649           1877  There have been a lot of retirements lately, but the department hasn't replaced any of these mis...                   NaN  English       212             9                 SAW     UCSD  448111                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1   700006.0    3833         999999.0    UC San Diego         700000.0                           VC-ADVANCEMENT         700006.0  UCSD FOUNDATION & ADVANCEMENT SERVICES              NaN                            NaN              NaN                                      NaN              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "2     43  588482           1877  WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...                   NaN  English       212             9                 SAW     UCSD  447391                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1    11000.0    3470         999999.0    UC San Diego          10000.0                         ACADEMIC AFFAIRS          10011.0                                COLLEGES          11000.0                   MUIR COLLEGE              NaN                                      NaN              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "3     49  590654           9439  The lack of professionalism from different departments that are supposed to be working with you ...                   NaN  English       212             9                 SAW     UCSD  451222                 None  The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...      Verbatim               201.0                     IdeaWave Comments                           Other            None            None            None                    1    90860.0    3659         999999.0    UC San Diego          90000.0          VICE CHANCELLOR HEALTH SCIENCES          93000.0                      SCHOOL OF MEDICINE          90800.0                       MEDICINE          90860.0                               CARDIOLOGY              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "4     52  588719           1877  ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...                   NaN  English       212             9                 SAW     UCSD  448383                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1      171.0    3402         999999.0    UC San Diego            800.0  VICE CHANCELLOR CHIEF FINANCIAL OFFICER            808.0         INFORMATION TECHNOLOGY SERVICES            132.0  ARCHITECTURE & INFRASTRUCTURE            171.0  DATACOM/NETWORK ARCHITECTS/NETWORK APPS              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "\n",
       "                                                                                           answer_text  prob_avg_sentiment  prob_is_example  pred_is_example  valid_loss  sentiment_mse  sentiment_mae  sentiment_rmse  is_example_f05_threshold  is_example_f05_score  is_example_f1_threshold  is_example_f1_score  is_example_f2_threshold  is_example_f2_score  \n",
       "0  Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...            2.100516         0.004653                0    0.450003       0.445856       0.501931        0.667725                      0.05              0.008369                     0.05             0.013323                     0.05             0.032656  \n",
       "1  There have been a lot of retirements lately, but the department hasn't replaced any of these mis...            2.021485         0.006528                0    0.450003       0.445856       0.501931        0.667725                      0.05              0.008369                     0.05             0.013323                     0.05             0.032656  \n",
       "2  WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...            2.242425         0.010107                0    0.450003       0.445856       0.501931        0.667725                      0.05              0.008369                     0.05             0.013323                     0.05             0.032656  \n",
       "3  The lack of professionalism from different departments that are supposed to be working with you ...            2.035603         0.011802                0    0.450003       0.445856       0.501931        0.667725                      0.05              0.008369                     0.05             0.013323                     0.05             0.032656  \n",
       "4  ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...            1.962478         0.006800                0    0.450003       0.445856       0.501931        0.667725                      0.05              0.008369                     0.05             0.013323                     0.05             0.032656  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If we were building results DataFrame by hand ...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the probabilities of each label to `inf_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3649, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_probs_is_example.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.100516  , 0.00465331],\n",
       "       [2.0214849 , 0.00652839],\n",
       "       [2.2424247 , 0.01010673],\n",
       "       ...,\n",
       "       [3.9447417 , 0.01542065],\n",
       "       [1.8345153 , 0.00923029],\n",
       "       [4.0441527 , 0.01412316]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((inf_probs_sent.numpy(), inf_probs_is_example.numpy()[:,1][:,None]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_probs = np.concatenate((inf_probs_sent.numpy(), inf_probs_is_example.numpy()[:,1][:,None]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_avg_sentiment</th>\n",
       "      <th>prob_is_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.100516</td>\n",
       "      <td>0.004653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.021485</td>\n",
       "      <td>0.006528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.242425</td>\n",
       "      <td>0.010107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.035603</td>\n",
       "      <td>0.011802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.962478</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prob_avg_sentiment  prob_is_example\n",
       "0            2.100516         0.004653\n",
       "1            2.021485         0.006528\n",
       "2            2.242425         0.010107\n",
       "3            2.035603         0.011802\n",
       "4            1.962478         0.006800"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_labels = ['prob_' + lbl for lbl in STANDARD_THEME_META_LABELS]\n",
    "probs_df = pd.DataFrame(combined_probs, columns=prob_labels)\n",
    "probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>QuestionAnsID</th>\n",
       "      <th>AnswerText</th>\n",
       "      <th>AnswerText_NonEnglish</th>\n",
       "      <th>Language</th>\n",
       "      <th>SurveyID</th>\n",
       "      <th>SurveyTypeID</th>\n",
       "      <th>BenchmarkSurveyType</th>\n",
       "      <th>ClientId</th>\n",
       "      <th>RspID</th>\n",
       "      <th>QuestionCategoryAbbr</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>QuestionClass</th>\n",
       "      <th>QuestionCategoryID</th>\n",
       "      <th>QuestionReportAbbr</th>\n",
       "      <th>QuestionCategoryLabel</th>\n",
       "      <th>BenchmarkLevel1</th>\n",
       "      <th>BenchmarkLevel2</th>\n",
       "      <th>BenchmarkLevel3</th>\n",
       "      <th>ClientBenchmarkLevel</th>\n",
       "      <th>GroupCode</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>GroupLevel1Code</th>\n",
       "      <th>GroupLevel1Name</th>\n",
       "      <th>GroupLevel2Code</th>\n",
       "      <th>GroupLevel2Name</th>\n",
       "      <th>GroupLevel3Code</th>\n",
       "      <th>GroupLevel3Name</th>\n",
       "      <th>GroupLevel4Code</th>\n",
       "      <th>GroupLevel4Name</th>\n",
       "      <th>GroupLevel5Code</th>\n",
       "      <th>GroupLevel5Name</th>\n",
       "      <th>GroupLevel6Code</th>\n",
       "      <th>GroupLevel6Name</th>\n",
       "      <th>GroupLevel7Code</th>\n",
       "      <th>GroupLevel7Name</th>\n",
       "      <th>GroupLevel8Code</th>\n",
       "      <th>GroupLevel8Name</th>\n",
       "      <th>theme</th>\n",
       "      <th>theme_pred</th>\n",
       "      <th>url_friendly_theme</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>prob_avg_sentiment</th>\n",
       "      <th>prob_is_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>589177</td>\n",
       "      <td>1877</td>\n",
       "      <td>Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>450625</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>31302.0</td>\n",
       "      <td>3555</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>VICE CHANCELLOR HEALTH SCIENCES</td>\n",
       "      <td>90563.0</td>\n",
       "      <td>STUDENT HEALTH &amp; WELL BEING</td>\n",
       "      <td>31302.0</td>\n",
       "      <td>STUDENT HEALTH SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...</td>\n",
       "      <td>2.100516</td>\n",
       "      <td>0.004653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>588649</td>\n",
       "      <td>1877</td>\n",
       "      <td>There have been a lot of retirements lately, but the department hasn't replaced any of these mis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>448111</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>700006.0</td>\n",
       "      <td>3833</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>VC-ADVANCEMENT</td>\n",
       "      <td>700006.0</td>\n",
       "      <td>UCSD FOUNDATION &amp; ADVANCEMENT SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>There have been a lot of retirements lately, but the department hasn't replaced any of these mis...</td>\n",
       "      <td>2.021485</td>\n",
       "      <td>0.006528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>588482</td>\n",
       "      <td>1877</td>\n",
       "      <td>WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>447391</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>3470</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>ACADEMIC AFFAIRS</td>\n",
       "      <td>10011.0</td>\n",
       "      <td>COLLEGES</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>MUIR COLLEGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...</td>\n",
       "      <td>2.242425</td>\n",
       "      <td>0.010107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>590654</td>\n",
       "      <td>9439</td>\n",
       "      <td>The lack of professionalism from different departments that are supposed to be working with you ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>451222</td>\n",
       "      <td>None</td>\n",
       "      <td>The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>201.0</td>\n",
       "      <td>IdeaWave Comments</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>90860.0</td>\n",
       "      <td>3659</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>VICE CHANCELLOR HEALTH SCIENCES</td>\n",
       "      <td>93000.0</td>\n",
       "      <td>SCHOOL OF MEDICINE</td>\n",
       "      <td>90800.0</td>\n",
       "      <td>MEDICINE</td>\n",
       "      <td>90860.0</td>\n",
       "      <td>CARDIOLOGY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>The lack of professionalism from different departments that are supposed to be working with you ...</td>\n",
       "      <td>2.035603</td>\n",
       "      <td>0.011802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>588719</td>\n",
       "      <td>1877</td>\n",
       "      <td>ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>448383</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>3402</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>800.0</td>\n",
       "      <td>VICE CHANCELLOR CHIEF FINANCIAL OFFICER</td>\n",
       "      <td>808.0</td>\n",
       "      <td>INFORMATION TECHNOLOGY SERVICES</td>\n",
       "      <td>132.0</td>\n",
       "      <td>ARCHITECTURE &amp; INFRASTRUCTURE</td>\n",
       "      <td>171.0</td>\n",
       "      <td>DATACOM/NETWORK ARCHITECTS/NETWORK APPS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...</td>\n",
       "      <td>1.962478</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      Id  QuestionAnsID                                                                                           AnswerText AnswerText_NonEnglish Language  SurveyID  SurveyTypeID BenchmarkSurveyType ClientId   RspID QuestionCategoryAbbr                                                                                         QuestionText QuestionClass  QuestionCategoryID                    QuestionReportAbbr           QuestionCategoryLabel BenchmarkLevel1 BenchmarkLevel2 BenchmarkLevel3 ClientBenchmarkLevel  GroupCode GroupID  GroupLevel1Code GroupLevel1Name  GroupLevel2Code                          GroupLevel2Name  GroupLevel3Code                         GroupLevel3Name  GroupLevel4Code                GroupLevel4Name  GroupLevel5Code                          GroupLevel5Name  GroupLevel6Code GroupLevel6Name  GroupLevel7Code GroupLevel7Name  GroupLevel8Code GroupLevel8Name              theme  theme_pred url_friendly_theme  \\\n",
       "0      6  589177           1877  Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...                   NaN  English       212             9                 SAW     UCSD  450625                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1    31302.0    3555         999999.0    UC San Diego          90000.0          VICE CHANCELLOR HEALTH SCIENCES          90563.0             STUDENT HEALTH & WELL BEING          31302.0        STUDENT HEALTH SERVICES              NaN                                      NaN              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "1     17  588649           1877  There have been a lot of retirements lately, but the department hasn't replaced any of these mis...                   NaN  English       212             9                 SAW     UCSD  448111                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1   700006.0    3833         999999.0    UC San Diego         700000.0                           VC-ADVANCEMENT         700006.0  UCSD FOUNDATION & ADVANCEMENT SERVICES              NaN                            NaN              NaN                                      NaN              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "2     43  588482           1877  WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...                   NaN  English       212             9                 SAW     UCSD  447391                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1    11000.0    3470         999999.0    UC San Diego          10000.0                         ACADEMIC AFFAIRS          10011.0                                COLLEGES          11000.0                   MUIR COLLEGE              NaN                                      NaN              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "3     49  590654           9439  The lack of professionalism from different departments that are supposed to be working with you ...                   NaN  English       212             9                 SAW     UCSD  451222                 None  The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...      Verbatim               201.0                     IdeaWave Comments                           Other            None            None            None                    1    90860.0    3659         999999.0    UC San Diego          90000.0          VICE CHANCELLOR HEALTH SCIENCES          93000.0                      SCHOOL OF MEDICINE          90800.0                       MEDICINE          90860.0                               CARDIOLOGY              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "4     52  588719           1877  ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...                   NaN  English       212             9                 SAW     UCSD  448383                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1      171.0    3402         999999.0    UC San Diego            800.0  VICE CHANCELLOR CHIEF FINANCIAL OFFICER            808.0         INFORMATION TECHNOLOGY SERVICES            132.0  ARCHITECTURE & INFRASTRUCTURE            171.0  DATACOM/NETWORK ARCHITECTS/NETWORK APPS              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "\n",
       "                                                                                           answer_text  prob_avg_sentiment  prob_is_example  \n",
       "0  Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...            2.100516         0.004653  \n",
       "1  There have been a lot of retirements lately, but the department hasn't replaced any of these mis...            2.021485         0.006528  \n",
       "2  WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...            2.242425         0.010107  \n",
       "3  The lack of professionalism from different departments that are supposed to be working with you ...            2.035603         0.011802  \n",
       "4  ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...            1.962478         0.006800  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df_filtered.update(probs_df)\n",
    "final_df = pd.concat([inf_df, probs_df], axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in predictions based on f05 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['is_example_f05']['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lbl in STANDARD_THEME_META_LABELS[1:]:\n",
    "    final_df[f'pred_{lbl}'] = (final_df[f'prob_{lbl}'] > scores['is_example_f05']['threshold']).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>QuestionAnsID</th>\n",
       "      <th>AnswerText</th>\n",
       "      <th>AnswerText_NonEnglish</th>\n",
       "      <th>Language</th>\n",
       "      <th>SurveyID</th>\n",
       "      <th>SurveyTypeID</th>\n",
       "      <th>BenchmarkSurveyType</th>\n",
       "      <th>ClientId</th>\n",
       "      <th>RspID</th>\n",
       "      <th>QuestionCategoryAbbr</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>QuestionClass</th>\n",
       "      <th>QuestionCategoryID</th>\n",
       "      <th>QuestionReportAbbr</th>\n",
       "      <th>QuestionCategoryLabel</th>\n",
       "      <th>BenchmarkLevel1</th>\n",
       "      <th>BenchmarkLevel2</th>\n",
       "      <th>BenchmarkLevel3</th>\n",
       "      <th>ClientBenchmarkLevel</th>\n",
       "      <th>GroupCode</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>GroupLevel1Code</th>\n",
       "      <th>GroupLevel1Name</th>\n",
       "      <th>GroupLevel2Code</th>\n",
       "      <th>GroupLevel2Name</th>\n",
       "      <th>GroupLevel3Code</th>\n",
       "      <th>GroupLevel3Name</th>\n",
       "      <th>GroupLevel4Code</th>\n",
       "      <th>GroupLevel4Name</th>\n",
       "      <th>GroupLevel5Code</th>\n",
       "      <th>GroupLevel5Name</th>\n",
       "      <th>GroupLevel6Code</th>\n",
       "      <th>GroupLevel6Name</th>\n",
       "      <th>GroupLevel7Code</th>\n",
       "      <th>GroupLevel7Name</th>\n",
       "      <th>GroupLevel8Code</th>\n",
       "      <th>GroupLevel8Name</th>\n",
       "      <th>theme</th>\n",
       "      <th>theme_pred</th>\n",
       "      <th>url_friendly_theme</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>prob_avg_sentiment</th>\n",
       "      <th>prob_is_example</th>\n",
       "      <th>pred_is_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>589177</td>\n",
       "      <td>1877</td>\n",
       "      <td>Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>450625</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>31302.0</td>\n",
       "      <td>3555</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>VICE CHANCELLOR HEALTH SCIENCES</td>\n",
       "      <td>90563.0</td>\n",
       "      <td>STUDENT HEALTH &amp; WELL BEING</td>\n",
       "      <td>31302.0</td>\n",
       "      <td>STUDENT HEALTH SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...</td>\n",
       "      <td>2.100516</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>588649</td>\n",
       "      <td>1877</td>\n",
       "      <td>There have been a lot of retirements lately, but the department hasn't replaced any of these mis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>448111</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>700006.0</td>\n",
       "      <td>3833</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>VC-ADVANCEMENT</td>\n",
       "      <td>700006.0</td>\n",
       "      <td>UCSD FOUNDATION &amp; ADVANCEMENT SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>There have been a lot of retirements lately, but the department hasn't replaced any of these mis...</td>\n",
       "      <td>2.021485</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>588482</td>\n",
       "      <td>1877</td>\n",
       "      <td>WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>447391</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>3470</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>ACADEMIC AFFAIRS</td>\n",
       "      <td>10011.0</td>\n",
       "      <td>COLLEGES</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>MUIR COLLEGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...</td>\n",
       "      <td>2.242425</td>\n",
       "      <td>0.010107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>590654</td>\n",
       "      <td>9439</td>\n",
       "      <td>The lack of professionalism from different departments that are supposed to be working with you ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>451222</td>\n",
       "      <td>None</td>\n",
       "      <td>The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>201.0</td>\n",
       "      <td>IdeaWave Comments</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>90860.0</td>\n",
       "      <td>3659</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>VICE CHANCELLOR HEALTH SCIENCES</td>\n",
       "      <td>93000.0</td>\n",
       "      <td>SCHOOL OF MEDICINE</td>\n",
       "      <td>90800.0</td>\n",
       "      <td>MEDICINE</td>\n",
       "      <td>90860.0</td>\n",
       "      <td>CARDIOLOGY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>The lack of professionalism from different departments that are supposed to be working with you ...</td>\n",
       "      <td>2.035603</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>588719</td>\n",
       "      <td>1877</td>\n",
       "      <td>ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>212</td>\n",
       "      <td>9</td>\n",
       "      <td>SAW</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>448383</td>\n",
       "      <td>SAT</td>\n",
       "      <td>If you would like to elaborate on your responses above, or if you have any additional feedback r...</td>\n",
       "      <td>Verbatim</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Comments re Work Environment at UCSD</td>\n",
       "      <td>Satisfaction with UC San Diego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>3402</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>800.0</td>\n",
       "      <td>VICE CHANCELLOR CHIEF FINANCIAL OFFICER</td>\n",
       "      <td>808.0</td>\n",
       "      <td>INFORMATION TECHNOLOGY SERVICES</td>\n",
       "      <td>132.0</td>\n",
       "      <td>ARCHITECTURE &amp; INFRASTRUCTURE</td>\n",
       "      <td>171.0</td>\n",
       "      <td>DATACOM/NETWORK ARCHITECTS/NETWORK APPS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adequate Staffing</td>\n",
       "      <td>1</td>\n",
       "      <td>AdequateStaffing</td>\n",
       "      <td>ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...</td>\n",
       "      <td>1.962478</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      Id  QuestionAnsID                                                                                           AnswerText AnswerText_NonEnglish Language  SurveyID  SurveyTypeID BenchmarkSurveyType ClientId   RspID QuestionCategoryAbbr                                                                                         QuestionText QuestionClass  QuestionCategoryID                    QuestionReportAbbr           QuestionCategoryLabel BenchmarkLevel1 BenchmarkLevel2 BenchmarkLevel3 ClientBenchmarkLevel  GroupCode GroupID  GroupLevel1Code GroupLevel1Name  GroupLevel2Code                          GroupLevel2Name  GroupLevel3Code                         GroupLevel3Name  GroupLevel4Code                GroupLevel4Name  GroupLevel5Code                          GroupLevel5Name  GroupLevel6Code GroupLevel6Name  GroupLevel7Code GroupLevel7Name  GroupLevel8Code GroupLevel8Name              theme  theme_pred url_friendly_theme  \\\n",
       "0      6  589177           1877  Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...                   NaN  English       212             9                 SAW     UCSD  450625                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1    31302.0    3555         999999.0    UC San Diego          90000.0          VICE CHANCELLOR HEALTH SCIENCES          90563.0             STUDENT HEALTH & WELL BEING          31302.0        STUDENT HEALTH SERVICES              NaN                                      NaN              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "1     17  588649           1877  There have been a lot of retirements lately, but the department hasn't replaced any of these mis...                   NaN  English       212             9                 SAW     UCSD  448111                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1   700006.0    3833         999999.0    UC San Diego         700000.0                           VC-ADVANCEMENT         700006.0  UCSD FOUNDATION & ADVANCEMENT SERVICES              NaN                            NaN              NaN                                      NaN              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "2     43  588482           1877  WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...                   NaN  English       212             9                 SAW     UCSD  447391                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1    11000.0    3470         999999.0    UC San Diego          10000.0                         ACADEMIC AFFAIRS          10011.0                                COLLEGES          11000.0                   MUIR COLLEGE              NaN                                      NaN              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "3     49  590654           9439  The lack of professionalism from different departments that are supposed to be working with you ...                   NaN  English       212             9                 SAW     UCSD  451222                 None  The Standing Committee on Service and People Oriented Culture (SC-SPOC) is interested in learnin...      Verbatim               201.0                     IdeaWave Comments                           Other            None            None            None                    1    90860.0    3659         999999.0    UC San Diego          90000.0          VICE CHANCELLOR HEALTH SCIENCES          93000.0                      SCHOOL OF MEDICINE          90800.0                       MEDICINE          90860.0                               CARDIOLOGY              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "4     52  588719           1877  ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...                   NaN  English       212             9                 SAW     UCSD  448383                  SAT  If you would like to elaborate on your responses above, or if you have any additional feedback r...      Verbatim               114.0  Comments re Work Environment at UCSD  Satisfaction with UC San Diego            None            None            None                    1      171.0    3402         999999.0    UC San Diego            800.0  VICE CHANCELLOR CHIEF FINANCIAL OFFICER            808.0         INFORMATION TECHNOLOGY SERVICES            132.0  ARCHITECTURE & INFRASTRUCTURE            171.0  DATACOM/NETWORK ARCHITECTS/NETWORK APPS              NaN             NaN              NaN             NaN              NaN             NaN  Adequate Staffing           1   AdequateStaffing   \n",
       "\n",
       "                                                                                           answer_text  prob_avg_sentiment  prob_is_example  pred_is_example  \n",
       "0  Inadequate staff within the walk in clinic as referred to as urgent care (where only RNs are ACL...            2.100516         0.004653                0  \n",
       "1  There have been a lot of retirements lately, but the department hasn't replaced any of these mis...            2.021485         0.006528                0  \n",
       "2  WIthin my immediate team unit, I enjoy working with my supervisor and colleagues. \\r\\n\\r\\nOutsid...            2.242425         0.010107                0  \n",
       "3  The lack of professionalism from different departments that are supposed to be working with you ...            2.035603         0.011802                0  \n",
       "4  ITS has significantly reduced effectiveness, productivity, and reliability, due, nearly in full,...            1.962478         0.006800                0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 02a_verbatims-core.ipynb.\n",
      "Converted 02b_verbatims-sentiment.ipynb.\n",
      "Converted 02c_verbatims-standard-themes-saw-training.ipynb.\n",
      "Converted 02d_verbatims-standard-themes-css-training.ipynb.\n",
      "Converted 02e_verbatims-standard-themes-meta-training.ipynb.\n",
      "Converted 99_verbatims-inference.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== text ===\n",
      "There are ongoing issues in our department that make for an often awkward and uncomfortable work environment. It takes more time and energy to dance around the egos, history, and bureaucracy of the situation, which can be exhausting and lead to dissatisfaction in the work place. \\r\\n\\r\\nThere are a number of people who do not seem to being pulling their weight in work load. It is frustrating to in strong effort regularly, while others coast by without doing much (responding to emails, following through on tasks, doing their job) or otherwise putting their work on other people to do while they don't do anything. This gets me, for one, very frustrated with my workplace.\n",
      "\n",
      "=== preds ===\n",
      "[2.0457377  0.00515723]\n"
     ]
    }
   ],
   "source": [
    "verbatim_id = 588956\n",
    "\n",
    "pred_lbls = [ f'prob_{lbl}' for lbl in STANDARD_THEME_META_LABELS ]\n",
    "prob_lbls = [ f'prob_{lbl}' for lbl in STANDARD_THEME_META_LABELS ]\n",
    "\n",
    "print(\"=== text ===\")\n",
    "print(preds_df.AnswerText[preds_df.Id == verbatim_id].values[0])\n",
    "print('\\n=== preds ===')\n",
    "preds = preds_df[pred_lbls][preds_df.Id == verbatim_id].values[0]\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>QuestionAnsID</th>\n",
       "      <th>AnswerText</th>\n",
       "      <th>AnswerText_NonEnglish</th>\n",
       "      <th>Language</th>\n",
       "      <th>SurveyID</th>\n",
       "      <th>SurveyTypeID</th>\n",
       "      <th>BenchmarkSurveyType</th>\n",
       "      <th>ClientId</th>\n",
       "      <th>RspID</th>\n",
       "      <th>QuestionCategoryAbbr</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>QuestionClass</th>\n",
       "      <th>QuestionCategoryID</th>\n",
       "      <th>QuestionReportAbbr</th>\n",
       "      <th>QuestionCategoryLabel</th>\n",
       "      <th>BenchmarkLevel1</th>\n",
       "      <th>BenchmarkLevel2</th>\n",
       "      <th>BenchmarkLevel3</th>\n",
       "      <th>ClientBenchmarkLevel</th>\n",
       "      <th>GroupCode</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>GroupLevel1Code</th>\n",
       "      <th>GroupLevel1Name</th>\n",
       "      <th>GroupLevel2Code</th>\n",
       "      <th>GroupLevel2Name</th>\n",
       "      <th>GroupLevel3Code</th>\n",
       "      <th>GroupLevel3Name</th>\n",
       "      <th>GroupLevel4Code</th>\n",
       "      <th>GroupLevel4Name</th>\n",
       "      <th>GroupLevel5Code</th>\n",
       "      <th>GroupLevel5Name</th>\n",
       "      <th>GroupLevel6Code</th>\n",
       "      <th>GroupLevel6Name</th>\n",
       "      <th>GroupLevel7Code</th>\n",
       "      <th>GroupLevel7Name</th>\n",
       "      <th>GroupLevel8Code</th>\n",
       "      <th>GroupLevel8Name</th>\n",
       "      <th>theme</th>\n",
       "      <th>theme_pred</th>\n",
       "      <th>url_friendly_theme</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>prob_avg_sentiment</th>\n",
       "      <th>prob_is_example</th>\n",
       "      <th>pred_is_example</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>sentiment_mse</th>\n",
       "      <th>sentiment_mae</th>\n",
       "      <th>sentiment_rmse</th>\n",
       "      <th>is_example_f05_threshold</th>\n",
       "      <th>is_example_f05_score</th>\n",
       "      <th>is_example_f1_threshold</th>\n",
       "      <th>is_example_f1_score</th>\n",
       "      <th>is_example_f2_threshold</th>\n",
       "      <th>is_example_f2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, Id, QuestionAnsID, AnswerText, AnswerText_NonEnglish, Language, SurveyID, SurveyTypeID, BenchmarkSurveyType, ClientId, RspID, QuestionCategoryAbbr, QuestionText, QuestionClass, QuestionCategoryID, QuestionReportAbbr, QuestionCategoryLabel, BenchmarkLevel1, BenchmarkLevel2, BenchmarkLevel3, ClientBenchmarkLevel, GroupCode, GroupID, GroupLevel1Code, GroupLevel1Name, GroupLevel2Code, GroupLevel2Name, GroupLevel3Code, GroupLevel3Name, GroupLevel4Code, GroupLevel4Name, GroupLevel5Code, GroupLevel5Name, GroupLevel6Code, GroupLevel6Name, GroupLevel7Code, GroupLevel7Name, GroupLevel8Code, GroupLevel8Name, theme, theme_pred, url_friendly_theme, answer_text, prob_avg_sentiment, prob_is_example, pred_is_example, valid_loss, sentiment_mse, sentiment_mae, sentiment_rmse, is_example_f05_threshold, is_example_f05_score, is_example_f1_threshold, is_example_f1_score, is_example_f2_threshold, is_example_f2_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df[preds_df.pred_is_example == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04920269"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.prob_is_example.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05, 0.05, 0.05)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['is_example_f05']['threshold'], scores['is_example_f1']['threshold'], scores['is_example_f2']['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "468px",
    "left": "1307px",
    "right": "20px",
    "top": "120px",
    "width": "353px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
