{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('bart-large-cnn')\n",
    "model = BartForConditionalGeneration.from_pretrained('bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "i like apples\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus(article, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = torch.cat([inputs['input_ids'][0][:1023], inputs['input_ids'][0][-1:]]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i like apples like apples. i.e. I like apples, I like to eat apples.']\n"
     ]
    }
   ],
   "source": [
    "summary_ids = model.generate(part1, num_beams=4, max_length=130, min_length=20, early_stopping=True)\n",
    "print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = 512\n",
    "end = 512 + 511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = torch.cat([inputs['input_ids'][0][:1], inputs['input_ids'][0][-511:]]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['26.  I think that 24 is ironic for UCSD because I dont know a single person that does not try and welcome people of all different backgrounds.28.  There is HORRIBLE cooperation in my department and in External Affairs in general.29.  The head of our human resources is perhaps one of the worst I have ever experienced in my work history.']\n"
     ]
    }
   ],
   "source": [
    "summary_ids = model.generate(part2, num_beams=4, max_length=130, min_length=30, early_stopping=True)\n",
    "print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BART - pretrained using `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282df1cafb7247dc9051fac2c8a37809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1300.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2251516db5743048737a94eba5b538d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1625270765.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\n",
    "    'The Finance Coordinator did not back brief his staff following formal EOC coordination meetings.',\n",
    "    'Finance Section personnel had not received any formal Finance Section training prior the exercise.',\n",
    "    'While not specific to the Finance Section, exercise evaluators stated that no guidance was provided pertaining to breaks and lunch.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [\n",
    "    'Exercise evaluators stated they did not observe the Finance Section Coordinator back brief his personnel following EOC coordination meetings. They attributed this deficiency to the understaffing of the Finance Section. Evaluators stated that when the Finance Section Coordinator would return to the Section following the coordination meetings, he would be inundated with questions and tasks that required his immediate attention.',\n",
    "    'Exercise evaluators stated that neither of three Finance Section personnel had been formally trained on how to function within the Finance Section. Evaluators noted that in the absence of training, Finance Section personnel were proactive in their problem solving, but were unsure if their approach was the right one.',\n",
    "    'Exercise evaluators indicated that they did not observe EOC staff provide any guidance on when to take breaks or how to maintain EOC operations while obtaining lunch. Evaluators indicated that when lunch finally arrived, everyone dropped what they were doing and went to lunch.'    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = summarizer(comments, max_length=30, min_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== predicted ===\n",
      "EOC evaluators did not observe the Finance Section Coordinator back brief his personnel following EOC coordination meetings.\n",
      "=== target ===\n",
      "The Finance Coordinator did not back brief his staff following formal EOC coordination meetings.\n",
      "\n",
      "=== predicted ===\n",
      "Evaluators found that neither of three Finance Section personnel had been formally trained on how to function within the Finance Section.\n",
      "=== target ===\n",
      "Finance Section personnel had not received any formal Finance Section training prior the exercise.\n",
      "\n",
      "=== predicted ===\n",
      "EOC staff did not provide guidance on when to take breaks or how to maintain EOC operations while obtaining lunch.\n",
      "=== target ===\n",
      "While not specific to the Finance Section, exercise evaluators stated that no guidance was provided pertaining to breaks and lunch.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, summary in enumerate(summaries):\n",
    "    txt = summary['summary_text']\n",
    "    sents = [sent.text for sent in spacy_en(txt).sents]\n",
    "    print(f\"=== predicted ===\\n{' '.join(sents[:-1])}\\n=== target ===\\n{targets[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 - pretrained using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise evaluators stated they did not observe the Finance Section Coordinator back brief his personnel following EOC coordination meetings \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "# T5 uses a max_length of 512 so we cut the article to 512 tokens.\n",
    "inputs = tokenizer.encode(\"summarize: \" + comments[0], return_tensors=\"pt\", max_length=512)\n",
    "outputs = model.generate(inputs, max_length=25, min_length=5, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.batch_encode_plus([\"summarize: \" + c for c in comments], \n",
    "                                     return_tensors=\"pt\", \n",
    "                                     max_length=512, \n",
    "                                     pad_to_max_length=True)\n",
    "\n",
    "outputs = model.generate(inputs['input_ids'], max_length=25, min_length=5, \n",
    "                         length_penalty=4.0, num_beams=4, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== predicted ===\n",
      "Exercise evaluators stated they did not observe the Finance Section Coordinator back brief his personnel following EOC coordination meetings \n",
      "=== target ===\n",
      "The Finance Coordinator did not back brief his staff following formal EOC coordination meetings.\n",
      "\n",
      "=== predicted ===\n",
      "exercise evaluators stated that neither of three Finance Section personnel had been formally trained on how to function within the\n",
      "=== target ===\n",
      "Finance Section personnel had not received any formal Finance Section training prior the exercise.\n",
      "\n",
      "=== predicted ===\n",
      "Exercise evaluators indicated that they did not observe EOC staff provide any guidance on when to take breaks or how\n",
      "=== target ===\n",
      "While not specific to the Finance Section, exercise evaluators stated that no guidance was provided pertaining to breaks and lunch.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, pred in enumerate(outputs):\n",
    "    txt = tokenizer.decode(pred)\n",
    "    print(f\"=== predicted ===\\n{txt}\\n=== target ===\\n{targets[i]}\\n\")\n",
    "    \n",
    "#     sents = [sent.text for sent in spacy_en(txt).sents]\n",
    "#     print(f\"=== predicted ===\\n{' '.join(sents[:-1])}\\n=== target ===\\n{targets[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
