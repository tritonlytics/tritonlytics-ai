{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp verbatims/sentiment/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment - Training\n",
    "\n",
    "> This module contains all the bits required to train and evaluate verbatim sentiment models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os, datetime, gc\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "import optuna\n",
    "\n",
    "from fastai.text.all import *\n",
    "from transformers import *\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from tritonlytics_ai.utils import *\n",
    "from tritonlytics_ai.verbatims.core import *\n",
    "\n",
    "from transformers import logging as hf_logging\n",
    "hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "# pandas and plotting config\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9,6)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.6.0\n",
      "Using fastai 2.0.16\n",
      "Using transformers 3.3.1\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "\n",
    "pretrained_model_name = \"facebook/bart-base\" #\"roberta-base\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = len(SENT_LABELS[1:])\n",
    "config.attention_probs_dropout_prob: 0.0\n",
    "config.hidden_dropout_prob: 0.3\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_sentiment_train_data()\n",
    "train_df, valid_df = df[df.is_valid == False], df[df.is_valid == True]\n",
    "\n",
    "set_seed(TL_RAND_SEED)\n",
    "dls = get_sentiment_train_dls(df, hf_arch, hf_tokenizer, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([8, 512]), torch.Size([8, 8]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pre = f'exp_{m_pre_sentiment}'\n",
    "m_suf = m_suf_sentiment\n",
    "base_model_name = base_model_name_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure our **metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metrics\n",
    "beta, start, end, average, sample_weight = 1, 0.08, 0.7, 'weighted', None\n",
    "\n",
    "# custom\n",
    "opt_th_metrics = OptimalMultiThresholdMetrics(beta=beta, start=start, end=end, \n",
    "                                              average=average, sample_weight=sample_weight)\n",
    "\n",
    "opt_th_metric = opt_th_metrics.best_thresh()\n",
    "opt_fscore_metric = opt_th_metrics.best_fscore()\n",
    "opt_acc_metric = opt_th_metrics.best_faccuracy()\n",
    "\n",
    "# standard\n",
    "fbeta_metric = FBetaMulti(beta=beta, average=average, sample_weight=sample_weight)\n",
    "prec_metric = PrecisionMulti(average=average, sample_weight=sample_weight)\n",
    "recall_metric = RecallMulti(average=average, sample_weight=sample_weight)\n",
    "roc_auc_metric = RocAucMulti(average=average, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_metrics(train_config={}):\n",
    "    config = {**sentiment_train_config, **train_config}\n",
    "\n",
    "    beta, average, sample_weight = config['opt_beta'], config['opt_beta_average'], config['opt_beta_sample_weight']\n",
    "    start, end = config['opt_start'], config['opt_end']\n",
    "    \n",
    "    # fbeta and roc-auc metrics\n",
    "    fbeta_metric = FBetaMulti(beta=beta, average=average, sample_weight=sample_weight)\n",
    "    prec_metric = PrecisionMulti(average=average, sample_weight=sample_weight)\n",
    "    recall_metric = RecallMulti(average=average, sample_weight=sample_weight)\n",
    "    roc_auc_metric = RocAucMulti(average=average, sample_weight=sample_weight)\n",
    "    \n",
    "    return [ accuracy_multi, fbeta_metric, prec_metric, recall_metric, roc_auc_metric ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure our **loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_counts = { col: train_df[col].value_counts().to_dict() for col in dls.tfms[1].vocab }\n",
    "most_common_label = max(label_counts.keys(), key=(lambda k: label_counts[k][1]))\n",
    "\n",
    "for lbl in label_counts: label_counts[lbl]['weight'] = label_counts[most_common_label][1] / label_counts[lbl][1]\n",
    "    \n",
    "pos_weight_vec = [v['weight'] * 1. if v['weight'] != 1.0 else v['weight'] for k,v in label_counts.items()]\n",
    "# pos_weight_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=tensor(pos_weight_vec).to('cuda:1'))\n",
    "# loss_func.thresh = 0.5\n",
    "# loss_func = BCEWithLogitsLossFlat(pos_weight=tensor(pos_weight_vec*bsz, device=torch.cuda.current_device()))\n",
    "loss_func = BCEWithLogitsLossFlat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_loss_func(dls, train_df=None, use_weighted=False):\n",
    "    if (use_weighted and train_df is not None):\n",
    "        label_counts = { col: train_df[col].value_counts().to_dict() for col in dls.tfms[1].vocab }\n",
    "        most_common_label = max(label_counts.keys(), key=(lambda k: label_counts[k][1]))\n",
    "\n",
    "        for lbl in label_counts: \n",
    "            label_counts[lbl]['weight'] = label_counts[most_common_label][1] / label_counts[lbl][1]\n",
    "\n",
    "        pos_weight_vec = [v['weight'] * 1. if v['weight'] != 1.0 else v['weight'] for k,v in label_counts.items()]\n",
    "        \n",
    "        loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=tensor(pos_weight_vec).to(dls.device))\n",
    "        loss_func.thresh = 0.5 # adding \"thresh\" since we want to optimize this for our target beta\n",
    "    else:\n",
    "        loss_func = BCEWithLogitsLossFlat()\n",
    "        \n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_loss_func = get_loss_func(dls, train_df, use_weighted=False)\n",
    "test_is(type(tst_loss_func), BCEWithLogitsLossFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_loss_func = get_loss_func(dls, train_df, use_weighted=True)\n",
    "test_is(type(tst_loss_func), torch.nn.BCEWithLogitsLoss)\n",
    "test_eq(len(tst_loss_func.pos_weight), dls.c)\n",
    "test_eq(dls.device, tst_loss_func.pos_weight.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure our **callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_cb = SaveModelCallback(monitor='fbeta_score', \n",
    "                                  comp=np.greater, \n",
    "                                  reset_on_fit=False,\n",
    "                                  fname=f'{m_pre}{base_model_name}{m_suf}_bestmodel')\n",
    "\n",
    "opt_thresh_cb = OptimizeFBetaThreshCallback(beta=beta, \n",
    "                                            average=average, \n",
    "                                            sample_weight=sample_weight,\n",
    "                                            start=start, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_cbs(train_config={}, add_save_model_cb=True):\n",
    "    config = {**sentiment_train_config, **train_config}\n",
    "    fit_cbs = []\n",
    "    \n",
    "    best_model_cb = SaveModelCallback(monitor=config['save_model_monitor'], \n",
    "                                      comp=config['save_model_comp'], \n",
    "                                      fname=config['save_model_filename'],\n",
    "                                      reset_on_fit=False)\n",
    "\n",
    "    opt_thresh_cb = OptimizeFBetaThreshCallback(beta=config['opt_beta'], \n",
    "                                                average=config['opt_beta_average'], \n",
    "                                                sample_weight=config['opt_beta_sample_weight'],\n",
    "                                                start=config['opt_start'], end=config['opt_end'])\n",
    "    \n",
    "    if (add_save_model_cb): fit_cbs.append(best_model_cb)\n",
    "    fit_cbs.append(opt_thresh_cb)\n",
    "    \n",
    "    return [HF_BaseModelCallback], fit_cbs # (learn_cbs, fit_cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure our **Learner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn\n",
    "except: pass\n",
    "finally: gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_metrics = [ accuracy_multi, fbeta_metric, prec_metric, recall_metric, roc_auc_metric ]\n",
    "\n",
    "learn_cbs = [HF_BaseModelCallback]\n",
    "fit_cbs = [best_model_cb, opt_thresh_cb]\n",
    "\n",
    "# build learner\n",
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "set_seed(TL_RAND_SEED)\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, mom=0.9, sqr_mom=0.98, eps=1e-6, weight_decay=0.1),\n",
    "                loss_func=loss_func,\n",
    "                metrics=learn_metrics,\n",
    "                cbs=learn_cbs,\n",
    "                splitter=hf_splitter,\n",
    "                path=SENTIMENT_CLS_PATH)\n",
    "\n",
    "learn = learn.to_fp16()\n",
    "learn.create_opt() # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Run this to test the model and comment out afterwards as it needlessly contributes to GPU RAM utilization :(\n",
    "# preds = model(b[0]); preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_learner(hf_model, dls, train_df=None, use_weighted_loss=False, use_fp16=True,\n",
    "                opt_func=partial(Adam, mom=0.9, sqr_mom=0.98, eps=1e-6, weight_decay=0.1),\n",
    "                add_save_model_cb=True, train_config={}):\n",
    "    config = {**sentiment_train_config, **train_config}\n",
    "    \n",
    "    # build learner\n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    loss_func = get_loss_func(dls, train_df, use_weighted_loss)\n",
    "    learn_cbs, fit_cbs = get_cbs(config, add_save_model_cb=add_save_model_cb)\n",
    "    learn_metrics = get_metrics(config)\n",
    "\n",
    "    set_seed(TL_RAND_SEED)\n",
    "    learn = Learner(dls, model, loss_func=loss_func, opt_func=opt_func, \n",
    "                    metrics=learn_metrics, cbs=learn_cbs, splitter=hf_splitter, path=config['learner_path'])\n",
    "    \n",
    "    if (use_fp16): learn = learn.to_fp16()\n",
    "    learn.create_opt() # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.freeze()\n",
    "    \n",
    "    return learn, fit_cbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.0015848932787775993, 0.0005754399462603033)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_min, lr_steep = learn.lr_find(); lr_min, lr_steep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015848932787775993"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = lr_min; lr_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>opt_th</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.182619</td>\n",
       "      <td>0.161129</td>\n",
       "      <td>0.932174</td>\n",
       "      <td>0.800629</td>\n",
       "      <td>0.760993</td>\n",
       "      <td>0.854455</td>\n",
       "      <td>0.876516</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.146114</td>\n",
       "      <td>0.146698</td>\n",
       "      <td>0.942513</td>\n",
       "      <td>0.819849</td>\n",
       "      <td>0.804443</td>\n",
       "      <td>0.856436</td>\n",
       "      <td>0.882332</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>02:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.129368</td>\n",
       "      <td>0.131877</td>\n",
       "      <td>0.947525</td>\n",
       "      <td>0.839787</td>\n",
       "      <td>0.815841</td>\n",
       "      <td>0.867327</td>\n",
       "      <td>0.897666</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>02:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with fbeta_score value: 0.8006285537632885.\n",
      "Better model found at epoch 1 with fbeta_score value: 0.8198489722868267.\n",
      "Better model found at epoch 2 with fbeta_score value: 0.8397873997624153.\n"
     ]
    }
   ],
   "source": [
    "set_seed(TL_RAND_SEED)\n",
    "learn.fit_one_cycle(3, lr_max=lr, cbs=fit_cbs)\n",
    "# learn.fit_flat_cos(10, lr_max=lr_min, cbs=fit_cbs, pct_start=0.72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2.0892961401841602e-06, 6.309573450380412e-07)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "lr_min, lr_steep = learn.lr_find(); lr_min, lr_steep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0892961401841602e-06"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = lr_min; lr_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>opt_th</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.101873</td>\n",
       "      <td>0.131474</td>\n",
       "      <td>0.946585</td>\n",
       "      <td>0.839103</td>\n",
       "      <td>0.806756</td>\n",
       "      <td>0.875743</td>\n",
       "      <td>0.898628</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>05:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.102771</td>\n",
       "      <td>0.131645</td>\n",
       "      <td>0.946507</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.808302</td>\n",
       "      <td>0.875248</td>\n",
       "      <td>0.899029</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>05:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.125921</td>\n",
       "      <td>0.130602</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.840735</td>\n",
       "      <td>0.812609</td>\n",
       "      <td>0.873267</td>\n",
       "      <td>0.899783</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>05:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.123912</td>\n",
       "      <td>0.130224</td>\n",
       "      <td>0.949170</td>\n",
       "      <td>0.840308</td>\n",
       "      <td>0.831314</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.893665</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>05:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.114420</td>\n",
       "      <td>0.130279</td>\n",
       "      <td>0.947838</td>\n",
       "      <td>0.840547</td>\n",
       "      <td>0.817258</td>\n",
       "      <td>0.867327</td>\n",
       "      <td>0.897903</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>05:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 2 with fbeta_score value: 0.8407351009974536.\n"
     ]
    }
   ],
   "source": [
    "set_seed(TL_RAND_SEED)\n",
    "learn.fit_one_cycle(5, lr_max=slice(lr/10, lr), cbs=fit_cbs)\n",
    "# learn.fit_one_cycle(5, lr_max=lr, cbs=fit_cbs)\n",
    "# learn.fit_flat_cos(5, lr_max=slice(lr_min/10, lr_min), cbs=fit_cbs, pct_start=0.72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.loss_func.thresh # => not part of pytorch BCE loss function (so added above as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'{m_pre}{base_model_name}{m_suf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname=f'{m_pre}{base_model_name}{m_suf}_export.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to add in the opthmize threshold cb since its used as *not* associated to the learner\n",
    "scores = dict(zip(learn.recorder.metric_names[2:], learn.validate(cbs=[fit_cbs[-1]]))); scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.show_results(learner=learn, max_n=2) \n",
    "# => ERROR:Only one class present in y_true. ROC AUC score is not defined in that case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use it for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_learn = load_learner(SENTIMENT_CLS_PATH/f'{m_pre}{base_model_name}{m_suf}_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_learn.loss_func.thresh = scores['opt_th']\n",
    "inf_learn.loss_func.thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_learn.blurr_predict('We are not paid enough and the benefits are horrible')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review final validation loss for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SENT_LABELS[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load(f'{m_pre}{base_model_name}{m_suf}_bestmodel')\n",
    "learn.loss_func.thresh = scores['opt_th']\n",
    "probs, targs, loss = learn.get_preds(dl=dls.valid, with_loss=True)\n",
    "\n",
    "print(f'Validation Loss: {loss.mean()}')\n",
    "# print(f'Validation Loss (per label): {loss.mean(dim=0)}') # ... no longer works (see forum comment from sylvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.blurr_predict(\"The faculty really support us well!!!  It's great working and I feel valued\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try: del learn\n",
    "except: pass\n",
    "finally: gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# predictions for a single model using the learner's model and data loaders\n",
    "set_seed(TL_RAND_SEED)\n",
    "learn, fit_cbs = get_learner(hf_model, \n",
    "                             dls, \n",
    "                             train_df=train_df, \n",
    "                             use_weighted_loss=False, \n",
    "                             use_fp16=True,\n",
    "                             train_config={})\n",
    "\n",
    "learn = learn.load(f'{m_pre}{base_model_name}{m_suf}_bestmodel')\n",
    "learn.loss_func.thresh = scores['opt_th']\n",
    "learn.model.cuda(1)\n",
    "probs, targs  = learn.get_preds()\n",
    "\n",
    "probs.shape, targs.shape, len(dls.valid_ds), dls.c, learn.loss_func.thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Lets look at validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "f05 = OptimalMultiThresholdMetrics(beta=0.5, start=0.05, end=.5, sigmoid=False, \n",
    "                                   average=average, sample_weight=sample_weight)\n",
    "f1 = OptimalMultiThresholdMetrics(beta=1, start=0.05, end=.5, sigmoid=False, \n",
    "                                   average=average, sample_weight=sample_weight)\n",
    "f2 = OptimalMultiThresholdMetrics(beta=2, start=0.05, end=.5, sigmoid=False, \n",
    "                                   average=average, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "threshold_f05 = f05.opt_th(probs, targs)\n",
    "threshold_f1 = f1.opt_th(probs, targs)\n",
    "threshold_f2 = f2.opt_th(probs, targs)\n",
    "\n",
    "threshold_f05, threshold_f1, threshold_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f05_score = f05.opt_fscore(probs, targs)\n",
    "f1_score = f1.opt_fscore(probs, targs)\n",
    "f2_score = f2.opt_fscore(probs, targs)\n",
    "\n",
    "f05_score, f1_score, f2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make sure we are getting the same f1 score as sklearn\n",
    "res = skm.fbeta_score(targs, (probs > threshold_f1), beta=1, \n",
    "                      average=average, sample_weight=sample_weight, zero_division=False)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# determine accuracy based on optimal threshold\n",
    "val_acc_f05 = accuracy_multi(probs, targs, threshold_f05, sigmoid=False).item()\n",
    "val_acc_f1 = accuracy_multi(probs, targs, threshold_f1, sigmoid=False).item()\n",
    "val_acc_f2 = accuracy_multi(probs, targs, threshold_f2, sigmoid=False).item()\n",
    "\n",
    "val_acc_f05, val_acc_f1, val_acc_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make sure we are getting the same f1 accuracy\n",
    "preds = ((probs > threshold_f1).byte() == targs.byte()).float().mean()\n",
    "preds.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Overall metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eval_targs = targs.flatten()\n",
    "eval_probs = probs.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Classification Accuracy\n",
    "\n",
    "The percentage of correct predictions.  Answers the question, *\"Overall, how often is the classifier correct?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# In multilabel classification, this function computes subset accuracy: \n",
    "# the set of labels predicted for a sample must exactly match ALL the corresponding set of labels in y_true.\n",
    "print(skm.accuracy_score(targs, (probs > threshold_f1), sample_weight=sample_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(skm.accuracy_score(eval_targs, (eval_probs > threshold_f1).float(), sample_weight=sample_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Null Accuracy\n",
    " \n",
    "The accuracy achieved by always predicting the most frequent class.  Answers the question, *\"What would the accuracy be by always predicting the most frequent case?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u_classes, u_counts = np.unique(eval_targs, return_counts=True)\n",
    "most_freq_class, most_freq_class_count = u_classes[np.argmax(u_counts)], np.max(u_counts)\n",
    "print(most_freq_class, most_freq_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "most_freq_class_count / len(eval_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Cohen's kappa\n",
    "\n",
    "This measure is intended to compare labelings by different human annotators (not a classifier vs. ground truth)\n",
    "\n",
    "Kappa socres are between -1 and 1 ( >= .8 is generally considered good agreement; <= 0 means no agreement ... e.g., practically random labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(skm.cohen_kappa_score(eval_targs, (eval_probs > threshold_f1).float(), \n",
    "                            weights=None, sample_weight=sample_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "Describes the performance of a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, \n",
    "                          title='Confusion matrix', cmap=plt.cm.Blues, print_info=False):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        if (print_info): print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        if (print_info): print('Confusion matrix, without normalization')\n",
    "\n",
    "    if (print_info): print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cm = skm.confusion_matrix(eval_targs, (eval_probs > threshold_f1).float(), sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_confusion_matrix(cm, classes=u_classes,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_confusion_matrix(cm, classes=u_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cm = skm.multilabel_confusion_matrix(targs, (probs > threshold_f1).float(), sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "f, axes = plt.subplots(2, 4, figsize=(25, 15))\n",
    "axes = axes.ravel()\n",
    "for i in range(8):\n",
    "    disp = ConfusionMatrixDisplay(cm[i], display_labels=[0, 1])\n",
    "    disp.plot(ax=axes[i], values_format='.4g', cmap=plt.cm.Blues)\n",
    "    disp.ax_.set_title(SENT_LABELS[1:][i][:30])\n",
    "    disp.ax_.grid(False)\n",
    "    if i<20:\n",
    "        disp.ax_.set_xlabel('')\n",
    "    if i%5!=0:\n",
    "        disp.ax_.set_ylabel('')\n",
    "    disp.im_.colorbar.remove()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.10, hspace=0.10)\n",
    "f.colorbar(disp.im_, ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(skm.classification_report(eval_targs, (eval_probs > threshold_f1).float(), \n",
    "                                labels=[0,1], \n",
    "                                sample_weight=sample_weight, \n",
    "                                zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classification_report = skm.classification_report(targs, (probs > threshold_f1).float(), \n",
    "                                target_names=SENT_LABELS[1:],\n",
    "                                sample_weight=sample_weight,\n",
    "                                zero_division=1,\n",
    "                                output_dict=True)\n",
    "\n",
    "pd.DataFrame(classification_report).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Raw probability distribution\n",
    "\n",
    "Useful to see how the threshold can be adjusted to increase sensitivity or specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(eval_probs, bins=10)\n",
    "# plt.xlim(0,1)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability of Labels')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### ROC curves and Area Under the Curve (AUC)\n",
    "\n",
    "***ROC Curve*** answers the question, *\"How would sensitivity and specificity be affected by various thresholds without changing the threshold?\"*  It is a way **to visualize the performance of a binary classifier.**\n",
    "\n",
    "The ROC curve can help you **choose a threshold** that balances sensitivity and specificity based on your particular business case.\n",
    "\n",
    "ROC curves visualize all possible classification thresholds whereas misclassification rate only represents your error rate for a single threshold.\n",
    "\n",
    "A classifier that does a good job at separating the classes will have a ROC curve that hugs the upper left corner of the plot.  Converseley, a classifier the does a poor job separating the classes will have a ROC curve that is close to the diagonal line (0,0 -> 1,1).  That diagonal line represents a classifier that does no better than random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = skm.roc_curve(eval_targs, eval_probs, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.xlim = ([0.0, 1.0])\n",
    "plt.ylim = ([0.0, 1.0])\n",
    "plt.title('ROC curve for all labels')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity/Recall)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***AUC*** = the percentage of the ROC plot that is underneath the curve.  \n",
    "\n",
    "AUC summarizes the performance of a classifier in a **single number**.  It says, *\"If you randomly chose one positive and one negative observation, what is the likelihood that your classifier will assign a higher predicted probability to the positive observation.\"*\n",
    "\n",
    "**An AUC of ~ 0.8 is very good while an AUC of ~ 0.5 represents a poor classifier.**\n",
    "\n",
    "The ROC curve and AUC are insensitive to whether your predicted probabilities are properly calibrated to actually represent probabilities of class membership (e.g., it works if predicted probs range from 0.9 to 1 instead of 0 to 1).  All the AUC metric cares about is how well your classifier separated the two classes\n",
    "\n",
    "Notes:\n",
    "1.  AUC is useful even when there is **high class imbalance** (unlike classification accuracy)\n",
    "2.  AUC is useful even when predicted probabilities are not properly calibrated (e.g., not between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(skm.roc_auc_score(eval_targs, eval_probs, average=average, sample_weight=sample_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Let's look at things by label by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label_metrics = {\n",
    "    'thresholds': { 'f-beta05': threshold_f05, 'f-beta1': threshold_f1, 'f-beta2': threshold_f2 }\n",
    "}\n",
    "\n",
    "for idx, lbl in enumerate(SENT_LABELS[1:]):\n",
    "    lbl_name, lbl_idx, lbl_targs, lbl_probs = lbl, idx, targs[:,idx], probs[:, idx]\n",
    "    \n",
    "    label_metrics[lbl_name] = {}\n",
    "    label_metrics[lbl_name]['accuracies'] = {}\n",
    "    label_metrics[lbl_name]['cohen_kappas'] = {}\n",
    "    label_metrics[lbl_name]['confusion_matrices'] = {}\n",
    "    label_metrics[lbl_name]['roc'] = {}\n",
    "    label_metrics[lbl_name]['report'] = {}\n",
    "    \n",
    "    # get null accuracy (accuracy we'd get if we simply predicted the most common class)\n",
    "    u_classes, u_counts = np.unique(lbl_targs, return_counts=True)\n",
    "    most_freq_class, most_freq_class_count = u_classes[np.argmax(u_counts)], np.max(u_counts)\n",
    "    label_metrics[lbl_name]['null_accuracy'] = most_freq_class_count / len(lbl_targs)\n",
    "    \n",
    "    # get raw probability distribution\n",
    "    label_metrics[lbl_name]['probability_distribution'] = np.histogram(lbl_probs)\n",
    "    \n",
    "    # roc/auc curve metrics\n",
    "    label_metrics[lbl_name]['roc_auc'] = skm.roc_auc_score(lbl_targs, lbl_probs, \n",
    "                                                           average=average, sample_weight=sample_weight)\n",
    "    \n",
    "    fpr, tpr, thresholds = skm.roc_curve(lbl_targs, lbl_probs, sample_weight=sample_weight)\n",
    "    label_metrics[lbl_name]['roc']['fpr'] = fpr\n",
    "    label_metrics[lbl_name]['roc']['tpr'] = tpr\n",
    "    label_metrics[lbl_name]['roc']['thresholds'] = thresholds\n",
    "    \n",
    "    for k,v in label_metrics['thresholds'].items():\n",
    "        label_metrics[lbl_name]['accuracies'][k] = skm.accuracy_score(lbl_targs, (lbl_probs > v), \n",
    "                                                                      sample_weight=sample_weight)\n",
    "        \n",
    "        label_metrics[lbl_name]['cohen_kappas'][k] = skm.cohen_kappa_score(lbl_targs, (lbl_probs > v), \n",
    "                                                                           sample_weight=sample_weight)\n",
    "        \n",
    "        label_metrics[lbl_name]['confusion_matrices'][k] = skm.confusion_matrix(lbl_targs, (lbl_probs > v), \n",
    "                                                                                sample_weight=sample_weight)\n",
    "        \n",
    "        precision, recall, fbeta_score, support = skm.precision_recall_fscore_support(lbl_targs, \n",
    "                                                                                      (lbl_probs > v), \n",
    "                                                                                      average=None, \n",
    "                                                                                      sample_weight=sample_weight)\n",
    "        label_metrics[lbl_name]['report'][k] = {}\n",
    "        label_metrics[lbl_name]['report'][k]['precision'] = precision\n",
    "        label_metrics[lbl_name]['report'][k]['recall'] = recall\n",
    "        label_metrics[lbl_name]['report'][k]['fbeta_score'] = fbeta_score\n",
    "        label_metrics[lbl_name]['report'][k]['support'] = support\n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# label_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for lbl in label_metrics.keys():\n",
    "    if (lbl == 'thresholds'): continue\n",
    "    \n",
    "    print(f'{lbl.upper()}\\n')\n",
    "    \n",
    "    print(f'Null Accuracy:\\t{label_metrics[lbl][\"null_accuracy\"]}')\n",
    "    print(f'AUC Score:\\t{label_metrics[lbl][\"roc_auc\"]}')\n",
    "    print('')\n",
    "    \n",
    "    print(''.join([ f'\\t\\t{threshold}({np.round(v, 4)})' for threshold, v in label_metrics['thresholds'].items() ]))\n",
    "    \n",
    "    print('Accuracy:\\t', end='')\n",
    "    for threshold, v in label_metrics['thresholds'].items():\n",
    "        print(f'{label_metrics[lbl][\"accuracies\"][threshold]}\\t', end='')\n",
    "    print('')\n",
    "    \n",
    "    print('Cohen\\'s Kappa:\\t', end='')\n",
    "    for threshold, v in label_metrics['thresholds'].items():\n",
    "        print(f'{label_metrics[lbl][\"cohen_kappas\"][threshold]}\\t', end='')\n",
    "    print('\\n')\n",
    "    \n",
    "    print('Classification Reports:')\n",
    "    for k in label_metrics[lbl]['report'].keys():\n",
    "        print(f'{k}')\n",
    "        print(f'{\"\":<20}' + ''.join([ f'{sub_key:<20}' for sub_key in label_metrics[lbl]['report'][k].keys() ]))\n",
    "        \n",
    "        for i in range(2):\n",
    "            print(f'{i:<20}' + ''.join([ f'{np.round(v[i],4):<20}' \n",
    "                                      for v in label_metrics[lbl]['report'][k].values() ]))\n",
    "        \n",
    "        print(f'{\"avg/total\":<20}' + ''.join([ f'{ np.round(v.mean(),4) if (sub_key != \"support\") else np.round(v.sum(),4):<20}' \n",
    "                                     for sub_key, v in label_metrics[lbl]['report'][k].items() ]))\n",
    "        print('')\n",
    "    print('\\n')\n",
    "    \n",
    "    print('Confusion Matrices:')\n",
    "    for threshold, v in label_metrics['thresholds'].items():\n",
    "        cm = label_metrics[lbl]['confusion_matrices'][threshold]\n",
    "        \n",
    "        # Plot non-normalized confusion matrix\n",
    "        fig = plt.figure(figsize=(12,8))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_confusion_matrix(cm, classes=[0,1], \n",
    "                              title=f'Confusion matrix, without normalization ({threshold}: {np.round(v,4)})')\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_confusion_matrix(cm, classes=[0,1], normalize=True, \n",
    "                              title=f'Normalized confusion matrix ({threshold}: {np.round(v,4)})')\n",
    "\n",
    "        fig.subplots_adjust(wspace=0.5)\n",
    "        plt.show()\n",
    "    print('\\n')\n",
    "    \n",
    "    print('ROC Curve:')\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(label_metrics[lbl]['roc']['fpr'], label_metrics[lbl]['roc']['tpr'])\n",
    "    plt.xlim = ([0.0, 1.0])\n",
    "    plt.ylim = ([0.0, 1.0])\n",
    "    plt.title(f'ROC curve for {lbl}')\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity/Recall)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    print('Predicted Probability Distribution:')\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.xlim = ([0.0, 1.0])\n",
    "    plt.bar(label_metrics[lbl]['probability_distribution'][1][:-1], \n",
    "            label_metrics[lbl]['probability_distribution'][0], width=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n')\n",
    "    print('-'*100)\n",
    "    print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del inf_learn\n",
    "except: pass\n",
    "finally: gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "inf_learn = load_learner(fname=SENTIMENT_CLS_PATH/f'{m_pre}{base_model_name}{m_suf}_export.pkl')\n",
    "inf_learn.loss_func.thresh = scores['opt_th']\n",
    "dls = get_sentiment_train_dls(df, hf_arch, hf_tokenizer)\n",
    "inf_learn.dls = dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inf_learn.loss_func = inf_learn.loss_func.to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, targs, loss = inf_learn.get_preds(with_loss=True, reorder=True)\n",
    "probs.shape, targs.shape, loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "f05 = OptimalMultiThresholdMetrics(beta=0.5, start=0.05, end=.5, sigmoid=False, \n",
    "                                   average=average, sample_weight=sample_weight)\n",
    "f1 = OptimalMultiThresholdMetrics(beta=1, start=0.05, end=.5, sigmoid=False, \n",
    "                                   average=average, sample_weight=sample_weight)\n",
    "f2 = OptimalMultiThresholdMetrics(beta=2, start=0.05, end=.5, sigmoid=False, \n",
    "                                   average=average, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine optimal threshold based on desired f-score\n",
    "threshold_f05 = f05.opt_th(probs, targs)\n",
    "threshold_f1 = f1.opt_th(probs, targs)\n",
    "threshold_f2 = f2.opt_th(probs, targs)\n",
    "\n",
    "print(threshold_f05, threshold_f1, threshold_f2)\n",
    "\n",
    "# determine accuracy based on optimal threshold\n",
    "val_acc_f05 = accuracy_multi(probs, targs, threshold_f05, sigmoid=False).item()\n",
    "val_acc_f1 = accuracy_multi(probs, targs, threshold_f1, sigmoid=False).item()\n",
    "val_acc_f2 = accuracy_multi(probs, targs, threshold_f2, sigmoid=False).item()\n",
    "\n",
    "print('Fowards Only\\n-------------')\n",
    "print(f'f05:\\tOptimal threshold = {threshold_f05}\\t(Accuracy = {val_acc_f05})')\n",
    "print(f'f1:\\tOptimal threshold = {threshold_f1}\\t(Accuracy = {val_acc_f1})')\n",
    "print(f'f2:\\tOptimal threshold = {threshold_f2}\\t(Accuracy = {val_acc_f2})')\n",
    "\n",
    "print(f'\\nAccuracy: {accuracy_multi(probs, targs, sigmoid=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_valid_loss = loss.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build our training loop for hyperparam optimization and final training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; del dls\n",
    "except: pass\n",
    "finally: gc.collect(); torch.cuda.empty_cache()\n",
    "    \n",
    "yyyymmdd = datetime.today().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastAIPruningCallbackv2(TrackerCallback):\n",
    "    def __init__(self, trial, monitor='valid_loss', **kwargs) -> None:\n",
    "        super().__init__(monitor=monitor, **kwargs)\n",
    "        self._trial = trial\n",
    "\n",
    "    def after_epoch(self) -> None:\n",
    "        super().after_epoch()\n",
    "        \n",
    "        value = self.recorder.values[-1][self.idx]\n",
    "        if value is None: return\n",
    "\n",
    "        self._trial.report(float(value), step=self.epoch)\n",
    "        if self._trial.should_prune():\n",
    "            message = \"Trial was pruned at epoch {}.\".format(self.epoch)\n",
    "            raise optuna.TrialPruned(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train(params, trial=None, train_config={}):\n",
    "    \n",
    "    config = {**sentiment_train_config, **train_config}    \n",
    "    m_pre, m_suf, base_model_name = config['m_pre'], config['m_suf'], config['base_model_name']\n",
    "    full_model_name = f'{m_pre}{base_model_name}{m_suf}'\n",
    "\n",
    "    # 1. grab our huggingface objects\n",
    "    task = HF_TASKS_AUTO.SequenceClassification\n",
    "    hf_config = AutoConfig.from_pretrained(params[\"pretrained_model_name\"])\n",
    "    hf_config.num_labels = len(SENT_LABELS[1:])\n",
    "    \n",
    "    if (f'{params[\"pretrained_model_name\"]}_config_overrides' in params):\n",
    "        hf_config.update(params[f'{params[\"pretrained_model_name\"]}_config_overrides'])\n",
    "    else:\n",
    "        config_overrides = { k:v for k,v in params.items() if (k in hf_config.to_dict()) }\n",
    "        hf_config.update(config_overrides)\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(params[\"pretrained_model_name\"], \n",
    "                                                                                   task=task, \n",
    "                                                                                   config=hf_config)\n",
    "\n",
    "    # 2. build our dls and learner\n",
    "    df = get_sentiment_train_data(train_config=config)\n",
    "    train_df, valid_df = df[df.is_valid == False], df[df.is_valid == True]\n",
    "    \n",
    "    set_seed(TL_RAND_SEED)\n",
    "    dls = get_sentiment_train_dls(df, hf_arch, hf_tokenizer, train_config=config, use_cache=False)\n",
    "    \n",
    "    set_seed(TL_RAND_SEED)\n",
    "    learn, fit_cbs = get_learner(hf_model, \n",
    "                                 dls, \n",
    "                                 train_df=None, \n",
    "                                 use_weighted_loss=params[\"use_weighted_loss\"], \n",
    "                                 use_fp16=params[\"use_fp16\"],\n",
    "                                 add_save_model_cb=params['save_model'],\n",
    "                                 train_config=config)\n",
    "    \n",
    "    if (trial is not None): learn.add_cb(FastAIPruningCallbackv2(trial=trial, monitor=params['optimize_for']))\n",
    "    \n",
    "    # 3. train\n",
    "    with learn.no_logging(): \n",
    "        set_seed(TL_RAND_SEED)\n",
    "        learn.fit_one_cycle(params[\"n_frozen_epochs\"], lr_max=params[\"frozen_lr\"], cbs=fit_cbs)\n",
    "        \n",
    "        learn.unfreeze()\n",
    "        set_seed(TL_RAND_SEED)\n",
    "        learn.fit_one_cycle(params[\"n_unfrozen_epochs\"], \n",
    "                            lr_max=slice(params[\"unfrozen_lr_min\"], params[\"unfrozen_lr_max\"]), \n",
    "                            cbs=fit_cbs)\n",
    "        \n",
    "        # export model for inference (SavedModelCallback already saves the best model if save_mode=True)\n",
    "        if (trial is None): learn.export(fname=f\"{yyyymmdd}_{config['export_filename']}\")\n",
    "        \n",
    "    # 4. evaluate\n",
    "    scores = dict(zip(learn.recorder.metric_names[2:], learn.validate(cbs=[fit_cbs[-1]])))\n",
    "    \n",
    "    try:\n",
    "        if (trial is not None): return scores[params['optimize_for']]\n",
    "        \n",
    "        learn.loss_func.thresh = scores['opt_th']\n",
    "        probs, targs, losses = learn.get_preds(dl=dls.valid, with_loss=True)\n",
    "\n",
    "        # determine optimal threshold based on desired f-score\n",
    "        average, sample_weight = config['opt_beta_average'], config['opt_beta_sample_weight']\n",
    "\n",
    "        f05 = OptimalMultiThresholdMetrics(beta=0.5, start=0.05, end=.5, sigmoid=False, \n",
    "                                           average=average, sample_weight=sample_weight)\n",
    "        f1 = OptimalMultiThresholdMetrics(beta=1, start=0.05, end=.5, sigmoid=False, \n",
    "                                           average=average, sample_weight=sample_weight)\n",
    "        f2 = OptimalMultiThresholdMetrics(beta=2, start=0.05, end=.5, sigmoid=False, \n",
    "                                           average=average, sample_weight=sample_weight)\n",
    "\n",
    "        scores['f05'], scores['f1'], scores['f2'] = {}, {}, {}\n",
    "\n",
    "        scores['f05']['threshold'] = f05.opt_th(probs, targs)\n",
    "        scores['f1']['threshold'] = f1.opt_th(probs, targs)\n",
    "        scores['f2']['threshold'] = f2.opt_th(probs, targs)\n",
    "\n",
    "        scores['f05']['score'] = f05.opt_fscore(probs, targs)\n",
    "        scores['f1']['score'] = f1.opt_fscore(probs, targs)\n",
    "        scores['f2']['score'] = f2.opt_fscore(probs, targs)\n",
    "\n",
    "        # save scores from validation set if mode == training\n",
    "        with open(f\"{config['learner_path']}/{yyyymmdd}_{full_model_name}_train_scores.json\", 'w') as f:\n",
    "            json.dump(scores, f, indent=4)\n",
    "\n",
    "        # save train/validation probs, targs, losses for review\n",
    "        test_dl = dls.test_dl(df, with_labels=True)\n",
    "        probs, targs, losses = learn.get_preds(dl=test_dl, with_loss=True)\n",
    "\n",
    "        probs_df = pd.DataFrame(probs.numpy(), columns=['prob_' + lbl for lbl in SENT_LABELS[1:]])\n",
    "        targs_df = pd.DataFrame(targs.numpy(), columns= ['targ_' + lbl for lbl in SENT_LABELS[1:]])\n",
    "        losses_df = pd.DataFrame(losses.numpy(), columns=['loss'])\n",
    "        final_df = pd.concat([df.reset_index(), probs_df, targs_df, losses_df], axis=1)\n",
    "\n",
    "        final_df.to_csv(f\"{config['learner_path']}/{yyyymmdd}_{full_model_name}_train_results.csv\", index=False)\n",
    "        return scores, final_df\n",
    "    \n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; del dls \n",
    "        del hf_arch; del hf_config; del hf_tokenizer; del hf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_trial_cleanup(study, trial):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def objective(trial, train_config={}):\n",
    "    opt_params = {\n",
    "        'pretrained_model_name': trial.suggest_categorical(\"pretrained_model_name\", [\"facebook/bart-base\"]),\n",
    "        \n",
    "        'save_model': trial.suggest_categorical(\"save_model\", [True, False]), \n",
    "        'use_weighted_loss': trial.suggest_categorical(\"use_weighted_loss\", [False]),\n",
    "        'use_fp16': trial.suggest_categorical(\"use_fp16\", [True]),\n",
    "        'n_frozen_epochs': trial.suggest_int(\"n_frozen_epochs\", 1, 3),\n",
    "        'n_unfrozen_epochs': trial.suggest_int(\"n_unfrozen_epochs\", 0, 5),\n",
    "        'frozen_lr': trial.suggest_loguniform(\"frozen_lr\", 3e-4, 3e-2),\n",
    "        'unfrozen_lr_max': trial.suggest_loguniform(\"unfrozen_lr_max\", 5e-6, 5e-5),\n",
    "        'unfrozen_lr_min': trial.suggest_loguniform(\"unfrozen_lr_min\", 5e-8, 5e-6),\n",
    "        'optimize_for': 'fbeta_score',\n",
    "        \n",
    "        'facebook/bart-base_config_overrides': {\n",
    "            'activation_dropout': trial.suggest_discrete_uniform('activation_dropout', 0.0, 0.3, 0.05),\n",
    "            'attention_dropout': trial.suggest_discrete_uniform('attention_dropout', 0.0, 0.3, 0.05),\n",
    "            'classif_dropout': trial.suggest_discrete_uniform('classif_dropout', 0.0, 0.3, 0.05),\n",
    "            'dropout': trial.suggest_discrete_uniform('dropout', 0.0, 0.3, 0.05)\n",
    "        },\n",
    "        'roberta-base_config_overrides': {\n",
    "            'attention_probs_dropout_prob': trial.suggest_discrete_uniform('attention_probs_dropout_prob', 0.0, 0.3, 0.05),\n",
    "            'hidden_dropout_prob': trial.suggest_discrete_uniform('hidden_dropout_prob', 0.0, 0.3, 0.05)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    score = train(opt_params, trial=trial, train_config=train_config)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner() if True else optuna.pruners.NopPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "\n",
    "train_config = {}\n",
    "study.optimize(partial(objective, train_config=train_config), \n",
    "               n_trials=30, \n",
    "               callbacks=[after_trial_cleanup])#, timeout=600)\n",
    "\n",
    "end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pre, m_suf = sentiment_train_config['m_pre'], sentiment_train_config['m_suf']\n",
    "full_model_name = f\"{m_pre}{sentiment_train_config['base_model_name']}{m_suf}\"\n",
    "   \n",
    "pruned_trials = [ t for t in study.trials if t.state == optuna.structs.TrialState.PRUNED ]\n",
    "complete_trials = [ t for t in study.trials if t.state == optuna.structs.TrialState.COMPLETE ]\n",
    "\n",
    "print('Study statistics: ')\n",
    "print('  Number of finished trials: ', len(study.trials))\n",
    "print('  Number of pruned trials: ', len(pruned_trials))\n",
    "print('  Number of complete trials: ', len(complete_trials))\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print('  Value: ', trial.value)\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items(): print('    {}: {}'.format(key, value))\n",
    "print('  User attrs:')\n",
    "for key, value in trial.user_attrs.items(): print('    {}: {}'.format(key, value))\n",
    "    \n",
    "best_params = study.best_params\n",
    "best_params['fbeta_score'] = study.best_value\n",
    "\n",
    "with open(f\"{sentiment_train_config['learner_path']}/{yyyymmdd}_{full_model_name}_best_trial_params.json\", 'w') as f:\n",
    "    json.dump(best_params, f, indent=4)\n",
    "\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_df.to_csv(f\"{sentiment_train_config['learner_path']}/{yyyymmdd}_{full_model_name}_trial_results.csv\", \n",
    "                 index=False)\n",
    "\n",
    "print(f'total time is {(end - start).total_seconds()} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(f\"{sentiment_train_config['learner_path']}/{yyyymmdd}_{full_model_name}_best_trial_params.json\") as f: \n",
    "    best_params = json.load(f)\n",
    "    \n",
    "scores, train_res_df = train(params=best_params, train_config={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scores\n",
    "with open(SENTIMENT_CLS_PATH/f'{yyyymmdd}_{full_model_name}_train_scores.json') as f: \n",
    "    training_results = json.load(f)\n",
    "    \n",
    "training_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_learn = load_learner(SENTIMENT_CLS_PATH/f'{yyyymmdd}_{full_model_name}_export.pkl')\n",
    "inf_learn.loss_func.thresh = scores['opt_th']\n",
    "\n",
    "print(inf_learn.loss_func.thresh)\n",
    "print(inf_learn.blurr_predict('We are not paid enough and the benefits are horrible'))\n",
    "print(inf_learn.blurr_predict(\"The faculty really support us well!!!  It's great working and I feel valued\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference (ad-hoc documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SENT_LABELS[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comments = [\n",
    "    'Not paid enough.',\n",
    "    'I am satisfied with my benefits and we have enough people in my department. The faculty is mean to me.',\n",
    "    'I love cats',\n",
    "    \"I can never find a parking spot. The shuttles are not on time. Help\",\n",
    "    \"I was really uncomfortable to express my opinion!!!\",\n",
    "    \"Jeff Wadell is an exceptional leader.  He has gone above and beyond to create a positive working environment and provide growth opportunities.  His commitment to his team is unrivaled and commendable.\\\\r\\\\n\\\\r\\\\nNikki Panza is a model of authentic leadership for Building and Custodial Services.  She has earned the respect of those she leads through honest communication, empathy, and ethical consultation.\"\n",
    "]\n",
    "\n",
    "for c in test_comments: print(inf_learn.blurr_predict(c, with_input=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference (batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_sentiment_preds(inf_df, learner_export_path=None, train_scores_path=None, yyyymmdd=None,\n",
    "                        device=torch.device('cpu'), train_config={}):\n",
    "    \n",
    "    config = {**sentiment_train_config, **train_config}    \n",
    "    m_pre, m_suf, base_model_name = config['m_pre'], config['m_suf'], config['base_model_name']\n",
    "    full_model_name = f'{m_pre}{base_model_name}{m_suf}'\n",
    "    \n",
    "    if (yyyymmdd is None): yyyymmdd = datetime.today().strftime(\"%Y%m%d\")\n",
    "    \n",
    "    # 1. grab learner, procs, and data\n",
    "    cpu = device.type == 'cpu'\n",
    "    if (learner_export_path is None): \n",
    "        learner_export_path = f\"{config['learner_path']}/{yyyymmdd}_{config['export_filename']}\"\n",
    "    if (train_scores_path is None): \n",
    "        train_scores_path = f\"{config['learner_path']}/{yyyymmdd}_{full_model_name}_train_scores.json\"\n",
    "        \n",
    "    with open(train_scores_path) as f: training_results = json.load(f)\n",
    "        \n",
    "    inf_learn = load_learner(fname=learner_export_path, cpu=cpu)\n",
    "    inf_learn.loss_func.thresh = training_results['opt_th']\n",
    "    inf_learn.model = inf_learn.model.to(device)\n",
    "    inf_learn.model = inf_learn.model.eval()\n",
    "    \n",
    "    # 2. define a suitable dataloader\n",
    "    inf_df = inf_df.copy()\n",
    "    inf_df.dropna(subset=config['corpus_cols'], inplace=True)\n",
    "    inf_df.reset_index(drop=True, inplace=True)\n",
    "    inf_dl = inf_learn.dls.test_dl(inf_df, rm_type_tfms=None, bs=16)\n",
    "\n",
    "    # 3. get probs and document vectors\n",
    "    test_probs = []\n",
    "    with torch.no_grad():\n",
    "        for index, b in enumerate(inf_dl):\n",
    "            if index % 1000 == 0:  print(index)\n",
    "\n",
    "            # note: even though there is no targets, each batch is a tuple!\n",
    "            probs = torch.sigmoid(inf_learn.model(b[0])[0])\n",
    "            \n",
    "            # why \"detach\"? the computation of gradients wrt the weights of netG can be fully \n",
    "            # avoided in the backward pass if the graph is detached where it is.\n",
    "            test_probs.append(to_detach(probs))\n",
    "\n",
    "    all_probs = L(torch.cat(test_probs))\n",
    "\n",
    "    # 4. ensure results are returned in order\n",
    "    # test_dl.get_idxs() => unsorted/original order items\n",
    "    all_probs = all_probs[0][np.argsort(inf_dl.get_idxs())]\n",
    "        \n",
    "    # 5. return results with scores in a df, probs, and labels\n",
    "    prob_labels = ['prob_' + lbl for lbl in  SENT_LABELS[1:]]\n",
    "    probs_df = pd.DataFrame(all_probs.numpy(), columns=prob_labels)\n",
    "        \n",
    "    final_df = pd.concat([inf_df, probs_df], axis=1)\n",
    "    \n",
    "    for lbl in  SENT_LABELS[1:]:\n",
    "        final_df[f'pred_{lbl}'] = (final_df[f'prob_{lbl}'] > training_results['opt_th']).astype(np.int64)\n",
    "        \n",
    "    final_df['valid_loss'] = training_results['valid_loss']\n",
    "    final_df['accuracy_multi'] = training_results['accuracy_multi']\n",
    "    final_df['fbeta_score'] = training_results['fbeta_score']\n",
    "    final_df['precision_score'] = training_results['precision_score']\n",
    "    final_df['recall_score'] = training_results['recall_score']\n",
    "    final_df['roc_auc_score'] = training_results['roc_auc_score']\n",
    "    final_df['opt_th'] = training_results['opt_th']\n",
    "    final_df['f05_threshold'] = training_results['f05']['threshold']\n",
    "    final_df['f05_score'] = training_results['f05']['score']\n",
    "    final_df['f1_threshold'] = training_results['f1']['threshold']\n",
    "    final_df['f1_score'] = training_results['f1']['score']\n",
    "    final_df['f2_threshold'] = training_results['f2']['threshold']\n",
    "    final_df['f2_score'] = training_results['f2']['score']\n",
    "\n",
    "    # cleanup\n",
    "    try: del inf_learn; del inf_dl\n",
    "    except: pass\n",
    "    finally: gc.collect(); torch.cuda.empty_cache()\n",
    "    \n",
    "    return final_df, all_probs, SENT_LABELS[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbatims_df = pd.read_csv(LM_PATH/'all.csv', dtype={**TASK_LM_DTYPES}, parse_dates=[])\n",
    "\n",
    "inf_df = verbatims_df[verbatims_df.SurveyID == 212].copy() #verbatims_df.copy() #verbatims_df[verbatims_df.SurveyID == 130].copy()\n",
    "inf_df.reset_index(drop=True, inplace=True)\n",
    "print(len(verbatims_df), len(inf_df))\n",
    "\n",
    "inf_df['answer_text'] = inf_df['AnswerText']  # ['question_text', 'answer_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "preds_df, inf_probs, inf_labels = get_sentiment_preds(inf_df, device=device)\n",
    "print(preds_df.shape, inf_probs.shape, len(inf_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If we were building results DataFrame by hand ...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the probabilities of each label to `inf_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_labels = ['prob_' + lbl for lbl in SENT_LABELS[1:]]\n",
    "probs_df = pd.DataFrame(inf_probs.numpy(), columns=prob_labels)\n",
    "probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([inf_df, probs_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in predictions based on f05 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lbl in SENT_LABELS[1:]:\n",
    "    final_df[f'pred_{lbl}'] = (final_df[f'prob_{lbl}'] > scores['opt_th']).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbatim_id = 590946\n",
    "\n",
    "pred_lbls = [ f'pred_{lbl}' for lbl in SENT_LABELS[1:] ]\n",
    "prob_lbls = [ f'prob_{lbl}' for lbl in SENT_LABELS[1:] ]\n",
    "\n",
    "print(\"=== text ===\")\n",
    "print(preds_df.AnswerText[preds_df.Id == verbatim_id].values[0])\n",
    "print('\\n=== preds ===')\n",
    "preds = preds_df[pred_lbls][preds_df.Id == verbatim_id].values[0]\n",
    "print([ pred_lbls[idx] for idx in np.where(preds == 1)[0] ])\n",
    "print('\\n=== probs ===')\n",
    "probs = preds_df[prob_lbls][preds_df.Id == verbatim_id].values[0]\n",
    "print([ probs[idx] for idx in np.where(preds == 1)[0] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "468px",
    "left": "1307px",
    "right": "20px",
    "top": "120px",
    "width": "353px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
